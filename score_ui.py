# -*- coding: utf-8 -*-
"""
Score UI â€” æ— ä¾§æ ç‰ˆï¼ˆä¸­æ–‡ï¼‰
- å‚æ•°åœ¨â€œæ’åï¼ˆè¿è¡Œ+æµè§ˆï¼‰â€é¡µç­¾ä¸­ç¼–è¾‘ï¼ˆä¸åŸç‰ˆä¸€è‡´çš„äº¤äº’æ€è·¯ï¼‰
- ç»Ÿè®¡ä½œä¸ºæ™®é€šé¡µç­¾ï¼ˆTracking / Surge / Commonality / Portfolioç»Ÿè®¡ï¼‰
- ä¸ªè‚¡è¯¦æƒ…å«â€œå‘½ä¸­ä¿¡å·æ—¥æœŸæŸ¥è¯¢â€
- å¯¼å‡ºç»Ÿä¸€æ”¯æŒ TXTï¼ˆç©ºæ ¼åˆ†éš”/ä¸€è¡Œä¸€ä¸ªï¼Œæ˜¯å¦å¸¦äº¤æ˜“æ‰€åç¼€ï¼‰
- ç»„åˆæ¨¡æ‹Ÿ/æŒä»“ï¼šåŸºäº Top æ–‡ä»¶ç”Ÿæˆå½“æœŸæŒä»“ä¸ç›¸å¯¹ä¸ŠæœŸè°ƒä»“åˆ—è¡¨ï¼ˆå¯å¯¼å‡ºï¼‰
"""

from __future__ import annotations
import os, io, json, re
from pathlib import Path
from datetime import datetime, timedelta, date
from typing import List, Optional, Dict

import logging

class _DropMissingCtx(logging.Filter):
    def filter(self, record):
        msg = record.getMessage()
        return "missing ScriptRunContext" not in msg and "bare mode" not in msg

# æ ¹ logger è¿‡æ»¤ï¼ˆè¦†ç›–ä¸€åˆ‡å‘ä¸Šå†’æ³¡çš„è®°å½•ï¼‰
logging.getLogger().addFilter(_DropMissingCtx())
# å†å¯¹ streamlit ç³»åˆ— logger åŠ ä¸€å±‚
for name in (
    "streamlit",
    "streamlit.runtime.scriptrunner",
    "streamlit.runtime.scriptrunner.script_run_context",
):
    logging.getLogger(name).addFilter(_DropMissingCtx())

import pandas as pd
import numpy as np
import streamlit as st
import streamlit.components.v1 as components
from contextlib import contextmanager
import shutil
import uuid
import time

import download as dl
import app_pv as apv

import scoring_core as se

import config as cfg
try:
    import stats_core as stats
except Exception:
    stats = None
from utils import normalize_ts, ensure_datetime_index, normalize_trade_date, market_label
from parquet_viewer import read_range, asset_root, list_trade_dates
from config import PARQUET_BASE, PARQUET_ADJ
import tdx_compat as tdx
from stats_core import _pick_trade_dates, _prev_trade_date

st.set_page_config(page_title="ScoreApp", layout="wide")
# ===== å¸¸é‡è·¯å¾„ =====
SC_OUTPUT_DIR = Path(getattr(cfg, "SC_OUTPUT_DIR", "output/score"))
TOP_DIR  = SC_OUTPUT_DIR / "top"
ALL_DIR  = SC_OUTPUT_DIR / "all"
DET_DIR  = SC_OUTPUT_DIR / "details"
ATTN_DIR = SC_OUTPUT_DIR / "attention"
LOG_DIR  = Path("./log")


for p in [TOP_DIR, ALL_DIR, DET_DIR, ATTN_DIR, LOG_DIR]:
    p.mkdir(parents=True, exist_ok=True)

def _apply_overrides(
    base: str,
    assets: List[str],
    start: str,
    end: str,
    api_adj: str,
    fast_threads: int,
    inc_threads: int,
    inc_ind_workers: int | None,
):
    """æŠŠ UI è¾“å…¥åŒæ­¥åˆ° download.py çš„å…¨å±€ï¼Œä»¥ä¾¿å…¶å‡½æ•°è¯»å–ã€‚"""
    # download.py å†…éƒ¨å¤šæ•°ç›´æ¥ä½¿ç”¨æ¨¡å—çº§å¸¸é‡ï¼Œè¿™é‡ŒåŸåœ°è¦†å†™å®ƒä»¬
    dl.DATA_ROOT = base
    dl.ASSETS = [a.lower() for a in assets]
    dl.START_DATE = start
    dl.END_DATE = end
    dl.API_ADJ = api_adj.lower()
    dl.FAST_INIT_THREADS = int(max(1, fast_threads))
    dl.STOCK_INC_THREADS = int(max(1, inc_threads))
    if inc_ind_workers is not None and int(inc_ind_workers) > 0:
        dl.INC_RECALC_WORKERS = int(inc_ind_workers)

    # åŒæ­¥åˆ° configï¼Œä»¥ä¾¿å…¶ä»–æ¨¡å—ï¼ˆå¦‚ parquet_viewerï¼‰çœ‹åˆ°ä¸€è‡´çš„ base/adj
    try:
        cfg.PARQUET_BASE = base
        cfg.DATA_ROOT = base
        cfg.PARQUET_ADJ = api_adj.lower() if api_adj.lower() in {"daily","raw","qfq","hfq"} else getattr(cfg, "PARQUET_ADJ", "qfq")
    except Exception:
        pass

@st.cache_data(show_spinner=False, ttl=300)
def _latest_trade_date(base: str, adj: str) -> str | None:
    try:

        root = asset_root(base, "stock", adj)
        ds = list_trade_dates(root)
        return ds[-1] if ds else None
    except Exception:
        return None

# -------------------- æ‰§è¡ŒåŠ¨ä½œï¼ˆå°è£… download.pyï¼‰ --------------------
def _run_fast_init(end_use: str):
    dl.fast_init_download(end_use)                       # é¦–æ¬¡å…¨é‡ï¼ˆå•è‚¡ç¼“å­˜ï¼‰
    if getattr(dl, "DUCK_MERGE_DAY_LAG", 5) >= 0:
        dl.duckdb_partition_merge()                     # åˆå¹¶åˆ° daily_*
    if getattr(dl, "WRITE_SYMBOL_INDICATORS", True):
        dl.duckdb_merge_symbol_products_to_daily()      # åˆå¹¶æŒ‡æ ‡åˆ° daily_*_indicators

def _run_increment(start_use: str, end_use: str, do_stock: bool, do_index: bool, do_indicators: bool):
    # è‹¥ fast_init çš„ç¼“å­˜å­˜åœ¨ï¼Œå…ˆåˆå¹¶ä¸€æ¬¡ï¼ˆä¸ main() é€»è¾‘ä¸€è‡´ï¼‰
    try:
        if any(
            os.path.isdir(os.path.join(dl.FAST_INIT_STOCK_DIR, d))
            and any(f.endswith(".parquet") for f in os.listdir(os.path.join(dl.FAST_INIT_STOCK_DIR, d)))
            for d in ("raw","qfq","hfq")
        ):
            dl.duckdb_partition_merge()
    except Exception:
        pass

    if do_stock and ("stock" in set(dl.ASSETS)):
        dl.sync_stock_daily_fast(start_use, end_use, threads=dl.STOCK_INC_THREADS)
    if do_index and ("index" in set(dl.ASSETS)):
        dl.sync_index_daily_fast(start_use, end_use, dl.INDEX_WHITELIST)
    if do_indicators:
        workers = getattr(dl, "INC_RECALC_WORKERS", None) or ((os.cpu_count() or 4) * 2)
        dl.recalc_symbol_products_for_increment(start_use, end_use, threads=workers)

# ===== å°å·¥å…· =====
def _path_top(ref: str) -> Path: return TOP_DIR / f"score_top_{ref}.csv"
def _path_all(ref: str) -> Path: return ALL_DIR / f"score_all_{ref}.csv"
def _path_detail(ref: str, ts: str) -> Path: return DET_DIR / ref / f"{normalize_ts(ts)}_{ref}.json"
def _today_str() -> str:
    return date.today().strftime("%Y%m%d")

@st.cache_data(show_spinner=False, hash_funcs={Path: lambda p: p.stat().st_mtime_ns})
def _read_df(path: Path, usecols=None, dtype=None, encoding: str = "utf-8-sig") -> pd.DataFrame:
    try:
        return pd.read_csv(path, usecols=usecols, dtype=dtype, encoding=encoding, engine="c")
    except Exception:
        return pd.DataFrame()

@st.cache_data(show_spinner=False, ttl=600)
def _cached_trade_dates(base: str, adj: str):
    root = asset_root(base, "stock", adj)
    return list_trade_dates(root) or []

@contextmanager
def se_progress_to_streamlit():
    status = st.status("å‡†å¤‡ä¸­â€¦", expanded=True)
    bar = st.progress(0, text="å°±ç»ª")
    info = st.empty()
    total = 0
    current = 0

    def _cb(phase, current=None, total=None, message=None, **kw):
        nonlocal status, bar, info
        # æ›´æ–°æ–‡å­—
        tag = {
            "select_ref_date": "é€‰æ‹©å‚è€ƒæ—¥",
            "compute_read_window": "è®¡ç®—è¯»å–åŒºé—´",
            "build_universe_done": "æ„å»ºè¯„åˆ†æ¸…å•",
            "score_start": "å¹¶è¡Œè¯„åˆ†å¯åŠ¨",
            "score_progress": "è¯„åˆ†è¿›è¡Œä¸­",
            "write_cache_lists": "å†™å…¥é»‘ç™½åå•",
            "write_top_all_start": "å†™å‡º Top/All",
            "write_top_all_done": "Top/All å®Œæˆ",
            "hooks_start": "ç»Ÿè®¡/å›çœ‹",
            "hooks_done": "ç»Ÿè®¡å®Œæˆ",
        }.get(phase, phase)
        txt = f"{tag}"
        if message:
            txt += f" Â· {message}"

        # è¿›åº¦æ¡
        if total is not None and total > 0 and current is not None:
            pct = int(current * 100 / max(total, 1))
            bar.progress(pct, text=txt)
        else:
            info.write(txt)

    se.set_progress_handler(_cb)
    try:
        yield
        status.update(label="å·²å®Œæˆ", state="complete")
    finally:
        se.set_progress_handler(None)

def _pick_latest_ref_date() -> Optional[str]:
    files = sorted(TOP_DIR.glob("score_top_*.csv"))
    dates = []
    for p in files:
        m = re.search(r"(\d{8})", p.name)
        if m: dates.append(m.group(1))
    return max(dates) if dates else None

def _prev_ref_date(cur: str) -> Optional[str]:
    files = sorted(TOP_DIR.glob("score_top_*.csv"))
    dates = []
    for p in files:
        m = re.search(r"(\d{8})", p.name)
        if m and m.group(1) < cur:
            dates.append(m.group(1))
    return dates[-1] if dates else None

def _from_last_hints(days: list[int] | None = None,
                     base: str = PARQUET_BASE, adj: str = PARQUET_ADJ,
                     last: str | None = None):
    """
    åŸºäºâ€œæœ€æ–°äº¤æ˜“æ—¥ lastï¼ˆç¼ºçœ=æœ¬åœ°æ•°æ®çš„æœ€åä¸€å¤©ï¼‰â€ï¼Œè¿”å›ï¼š
      - æ–‡æœ¬æç¤ºä¸²ï¼ˆå«æ˜ŸæœŸï¼‰ï¼Œç”¨äºå±•ç¤ºï¼›
      - æ˜ å°„ dict: {n: d8}ï¼Œn ä¸ªäº¤æ˜“æ—¥å‰å¯¹åº”çš„ yyyymmdd å­—ç¬¦ä¸²ã€‚
    """
    try:
        root = asset_root(base, "stock", adj)
        ds = list_trade_dates(root) or []
        if not ds:
            return "", {}
        last = last or ds[-1]
        if last not in ds:
            return "", {}

        idx = ds.index(last)
        days = sorted({int(x) for x in (days or []) if int(x) >= 1})

        from datetime import date as _d
        def _fmt(d8: str) -> str:
            y, m, d = int(d8[:4]), int(d8[4:6]), int(d8[6:])
            wk = "ä¸€äºŒä¸‰å››äº”å…­æ—¥"[_d(y, m, d).weekday()]
            return f"{y:04d}-{m:02d}-{d:02d}(å‘¨{wk})"

        parts = [f"æœ€æ–°={_fmt(last)}"]
        mapping = {}
        for n in days:
            j = idx - n
            if j >= 0:
                mapping[n] = ds[j]
                parts.append(f"{n}ä¸ªäº¤æ˜“æ—¥å‰={_fmt(ds[j])}")
            else:
                parts.append(f"{n}ä¸ªäº¤æ˜“æ—¥å‰=--ï¼ˆæ•°æ®ä¸è¶³ï¼‰")
        return " Â· ".join(parts), mapping
    except Exception:
        return "", {}

def _rule_to_screen_args(rule: dict):
    """è¿”å› (when_expr, timeframe, window, scope)"""
    if rule.get("clauses"):
        tfs = {str(c.get("timeframe","D")).upper() for c in rule["clauses"]}
        wins = {int(c.get("window", 60)) for c in rule["clauses"]}
        scopes = {str(c.get("scope","ANY")).upper() for c in rule["clauses"]}
        whens = [f"({c.get('when','').strip()})" for c in rule["clauses"] if c.get("when","").strip()]
        if not whens:
            raise ValueError("å¤åˆè§„åˆ™ç¼ºå°‘ when")
        # ç›®å‰ä»…æ”¯æŒâ€œç›¸åŒ tf/window/scopeâ€çš„å¤åˆè§„åˆ™ï¼›å¦åˆ™å°±æ— æ³•ä¸€æ¬¡æ€§å±å…¨å¸‚åœº
        if len(tfs)==len(wins)==len(scopes)==1:
            return " AND ".join(whens), list(tfs)[0], list(wins)[0], list(scopes)[0]
        else:
            raise ValueError("å…¨å¸‚åœºè·‘ç›®å‰ä»…æ”¯æŒå„å­å¥ tf/window/scope å®Œå…¨ä¸€è‡´çš„å¤åˆè§„åˆ™")
    else:
        when = (rule.get("when") or "").strip()
        if not when:
            raise ValueError("when ä¸èƒ½ä¸ºç©º")
        tf = str(rule.get("timeframe","D")).upper()
        win = int(rule.get("window", 60))
        scope = str(rule.get("scope","ANY")).upper()
        return when, tf, win, scope

def _load_detail_json(ref: str, ts: str) -> Optional[Dict]:
    p = _path_detail(ref, ts)
    if not p.exists(): return None
    try:
        return json.loads(p.read_text(encoding="utf-8-sig"))
    except Exception:
        return None

def _codes_to_txt(codes: List[str], style: str="space", with_suffix: bool=True) -> str:
    def fmt(c):
        c = normalize_ts(c)
        return c if with_suffix else c.split(".")[0]
    arr = [fmt(c) for c in codes]
    return (" ".join(arr)) if style == "space" else ("\n".join(arr))

def _download_txt(label: str, text: str, filename: str, key: Optional[str]=None):
    st.download_button(label, data=text.encode("utf-8-sig"),
                       file_name=filename, mime="text/plain",
                       use_container_width=True, key=key)

def copy_txt_button(text: str, label: str = "ä¸€é”®å¤åˆ¶ï¼ˆTXTï¼‰", key: str = "copy0"):
    st.code(text or "", language="text")
    components.html(f"""
    <button id="{key}" style="padding:6px 10px;border:1px solid #444;border-radius:8px;cursor:pointer">{label}</button>
    <script>
      const btn = document.getElementById("{key}");
      const payload = {json.dumps(text or "")};
      btn.addEventListener("click", async () => {{
        try {{
          await navigator.clipboard.writeText(payload);
          btn.innerText = "å·²å¤åˆ¶";
        }} catch (e) {{
          btn.innerText = "å¤åˆ¶å¤±è´¥ï¼ˆè¯·æ‰‹åŠ¨ Ctrl+Cï¼‰";
        }}
      }});
    </script>
    """, height=50)

def _tail(path: Path, n: int=400) -> str:
    try:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return "".join(f.readlines()[-n:])
    except Exception:
        return ""

def _scan_date_range(start_yyyymmdd: str, end_yyyymmdd: str) -> List[str]:
    s = datetime.strptime(start_yyyymmdd, "%Y%m%d")
    e = datetime.strptime(end_yyyymmdd, "%Y%m%d")
    out = []
    while s <= e:
        out.append(s.strftime("%Y%m%d"))
        s += timedelta(days=1)
    return out

def _fmt_retcols_percent(df):
    try:
        import pandas as _pd
        import numpy as _np
    except Exception:
        return df
    df = df.copy()
    cols = [c for c in df.columns if str(c).startswith("ret_fwd_")]
    if not cols:
        return df
    for c in cols:
        # è½¬æˆæ•°å€¼
        s = _pd.to_numeric(df[c], errors="coerce")
        finite = s[_np.isfinite(s)]
        if finite.shape[0] == 0:
            continue
        q95 = finite.abs().quantile(0.95)
        # å°äºç­‰äº 0.5 è¯´æ˜æ˜¯å°æ•°ï¼ˆä¾‹å¦‚ 0.034ï¼‰ï¼Œéœ€è¦Ã—100
        if _pd.notna(q95) and q95 <= 0.5:
            s = s * 100.0
        # ç»Ÿä¸€ä¸¤ä½å°æ•° + ç™¾åˆ†å·
        df[c] = s.map(lambda x: (f"{x:.2f}%" if _pd.notna(x) else None))
    return df

def _apply_runtime_overrides(rules_obj: dict,
                             topk: int, tie_break: str, max_workers: int,
                             attn_on: bool, universe: str|List[str]):
    # è§„åˆ™ä¸´æ—¶è¦†ç›–ï¼ˆä»…å½“å‰è¿›ç¨‹ï¼‰
    if rules_obj:
        pres = rules_obj.get("prescreen")
        rules = rules_obj.get("rules")
        if pres is not None: setattr(se, "SC_PRESCREEN_RULES", pres)
        if rules is not None: setattr(se, "SC_RULES", rules)
    setattr(se, "SC_TOP_K", int(topk))
    setattr(se, "SC_TIE_BREAK", str(tie_break))
    setattr(se, "SC_MAX_WORKERS", int(max_workers))
    # setattr(se, "SC_ATTENTION_ENABLE", bool(attn_on))
    setattr(se, "SC_UNIVERSE", universe)

# ==== å¼ºåº¦æ¦œæ–‡ä»¶å®šä½====
def _pick_latest_attn_date() -> Optional[str]:
    """
    æ‰«æ attention ç›®å½•æ‰€æœ‰ CSVã€‚
    è§„åˆ™ï¼šæŠŠâ€œæ–‡ä»¶åé‡Œæœ€åä¸€æ¬¡å‡ºç°çš„ 8 ä½æ•°å­—â€è§†ä¸ºè¯¥æ–‡ä»¶çš„ç»“æŸæ—¥ï¼›
         è‹¥åŒä¸€ç»“æŸæ—¥æœ‰å¤šä»½ï¼Œåˆ™æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´(mtime)å–æœ€æ–°é‚£ä»½çš„ç»“æŸæ—¥ã€‚
    """
    best_key = None
    best_ref = None
    for p in ATTN_DIR.glob("*.csv"):
        ms = re.findall(r"(\d{8})", p.name)
        if not ms:
            continue
        end = ms[-1]  # è§†ä¸ºç»“æŸæ—¥ï¼ˆæœ€å 8 ä½ï¼‰
        key = (end, p.stat().st_mtime)  # å…ˆæ¯”æ—¥æœŸï¼Œå†æ¯”ä¿®æ”¹æ—¶é—´
        if best_key is None or key > best_key:
            best_key, best_ref = key, end
    return best_ref

def _find_attn_file_by_date(ref: str) -> Optional[Path]:
    """
    æ ¹æ®ç»“æŸæ—¥ ref å®šä½æ–‡ä»¶ï¼š
    - å…ˆæ”¶é›†æ‰€æœ‰åŒ…å«è¯¥ ref çš„ attention CSVï¼›
    - ä¼˜å…ˆâ€œè§„èŒƒåŒ–å‘½åâ€çš„æ–‡ä»¶ï¼ˆä»¥ attention_ å¼€å¤´ä¸”åŒ…å« _win/_topM/_topN è¿™äº›å…³é”®å­—ï¼‰ï¼›
    - å…¶ä½™åˆ™æŒ‰ä¿®æ”¹æ—¶é—´å€’åºä½œä¸ºæ¬¡åºã€‚
    """
    cands = list(ATTN_DIR.glob(f"*attention*{ref}*.csv"))
    if not cands:
        return None

    def _score(p: Path):
        nm = p.name
        normalized = nm.startswith("attention_") and ("_win" in nm or nm == f"attention_{ref}.csv")
        return (1 if normalized else 0, p.stat().st_mtime)

    return sorted(cands, key=_score, reverse=True)[0]

# ---- è¯»å– config çš„ç¨³å¥å·¥å…· ----
def cfg_int(name: str, default: int) -> int:
    val = getattr(cfg, name, default)
    try:
        # è¿‡æ»¤ None / "" ç­‰å¼‚å¸¸å–å€¼
        if val is None or (isinstance(val, str) and val.strip() == ""):
            return int(default)
        return int(val)
    except Exception:
        return int(default)

def cfg_str(name: str, default: str) -> str:
    val = getattr(cfg, name, default)
    if val is None:
        return str(default)
    s = str(val).strip()
    return s if s else str(default)

def cfg_bool(name: str, default: bool) -> bool:
    val = getattr(cfg, name, default)
    if isinstance(val, bool):
        return val
    if val is None:
        return bool(default)
    s = str(val).strip().lower()
    if s in {"1","true","yes","y","on","t"}:
        return True
    if s in {"0","false","no","n","off","f"}:
        return False
    return bool(default)

# é€šç”¨å¤šé˜¶æ®µè¿›åº¦å™¨ï¼ˆç»Ÿä¸€ç®¡ç†å•æ¬¡ä»»åŠ¡çš„è¿›åº¦æ¡+çŠ¶æ€æ—¥å¿—ï¼‰
class Stepper:
    """
    ç”¨æ³•ï¼š
        steps = ["å‡†å¤‡ç¯å¢ƒ", "ä¸‹è½½æºæ•°æ®", "åˆå¹¶å¢é‡", "å†™å‡ºå¯¼å‡º", "è‡ªåŠ¨æ’å"]
        sp = Stepper("ä¸‹è½½/åŒæ­¥", steps, key_prefix="dl_sync")  # æ¯æ¬¡ç‚¹å‡»éƒ½ä¼šç”Ÿæˆç‹¬ç«‹ run_id
        sp.start()

        sp.step("å‡†å¤‡ç¯å¢ƒ")     # åšå‡†å¤‡...
        sp.tick(0.3, "æ ¡éªŒç›®æ ‡ç›®å½•")
        sp.tick(1.0)           # æœ¬æ­¥éª¤æ”¶å°¾

        sp.step("ä¸‹è½½æºæ•°æ®")   # å…·ä½“ä¸‹è½½...
        sp.step("åˆå¹¶å¢é‡")
        sp.step("å†™å‡ºå¯¼å‡º")
        sp.step("è‡ªåŠ¨æ’å", visible=auto_rank)  # æ”¯æŒæŒ‰æ¡ä»¶æ˜¾ç¤º/è·³è¿‡
        sp.finish(success=True, note="å…¨éƒ¨å®Œæˆ")
    """
    def __init__(self, title, steps, key_prefix="stepper"):
        self.title = title
        self.steps_all = steps[:]  # æ–‡æ¡ˆåˆ—è¡¨ï¼ˆå¯å« Noneï¼‰
        self.steps = [s for s in steps if s]  # å®é™…å‚ä¸ç»Ÿè®¡çš„æ­¥éª¤
        self.total = len(self.steps)
        self.key = f"{key_prefix}_{uuid.uuid4().hex[:8]}"
        self._init_state()

    def _init_state(self):
        st.session_state[self.key] = {
            "idx": 0,        # å·²å®Œæˆåˆ°ç¬¬å‡ ä¸ªï¼ˆä» 0 å¼€å§‹ï¼‰
            "run_id": self.key,
        }

    def start(self):
        self.status = st.status(
            label=f"{self.title}ï¼šå¼€å§‹ï¼ˆ0/{self.total}ï¼‰",
            state="running",
        )
        self.prog = st.progress(0, text="å‡†å¤‡ä¸­â€¦")
        with self.status:
            st.write("ğŸŸ¡ å¼€å§‹ä»»åŠ¡â€¦")

    def _update_prog(self, idx, label):
        pct = 0 if self.total == 0 else int(idx / self.total * 100)
        self.prog.progress(pct, text=f"{idx}/{self.total}ï¼š{label}")

    def step(self, label, visible=True, info=None):
        """è¿›å…¥ä¸‹ä¸€ä¸»æ­¥éª¤ï¼›visible=False æ—¶ï¼Œä»…è®°å½•æ—¥å¿—ï¼Œä¸çº³å…¥è¿›åº¦æ¯”ä¾‹"""
        if not visible:
            # ä»…è¿½åŠ æ—¥å¿—æç¤º
            with self.status:
                st.write(f"â­ï¸ è·³è¿‡ï¼š{label}")
            return

        state = st.session_state[self.key]
        state["idx"] += 1
        idx = min(state["idx"], self.total)
        text = label if not info else f"{label}ï½œ{info}"

        with self.status:
            st.write(f"â–¶ï¸ {text}")
        self._update_prog(idx, text)

    def tick(self, delta_ratio, info=None):
        """åœ¨å½“å‰æ­¥éª¤ä¸­æ˜¾ç¤ºç»†ç²’åº¦æ¨è¿›ï¼ˆä¾‹å¦‚å¾ªç¯/åˆ†æ‰¹å¤„ç†ï¼‰"""
        state = st.session_state[self.key]
        # æŒ‰å½“å‰ä¸»æ­¥éª¤ä½ç½® + ç»†åˆ†æ¯”ä¾‹ åˆæˆä¸€ä¸ªæ›´å¹³æ»‘çš„ç™¾åˆ†æ¯”å±•ç¤º
        base = min(state["idx"], self.total - 1)
        now = min(1.0, max(0.0, float(delta_ratio)))
        overall = int(((base + now) / self.total) * 100) if self.total else 0
        self.prog.progress(overall, text=info or "å¤„ç†ä¸­â€¦")
        # åœ¨æ—¥å¿—é‡Œä¹Ÿå¯æ‰“ç‚¹
        if info:
            with self.status:
                st.write(f"â€¦ {info}")

    def finish(self, success=True, note=None):
        if success:
            self.status.update(
                label=f"{self.title}ï¼šå®Œæˆï¼ˆ{self.total}/{self.total}ï¼‰",
                state="complete",
            )
            self.prog.progress(100, text=note or "å®Œæˆ")
        else:
            self.status.update(
                label=f"{self.title}ï¼šå¤±è´¥",
                state="error",
            )

# ===== ä¼šè¯çŠ¶æ€ =====
if "rules_obj" not in st.session_state:
    st.session_state["rules_obj"] = {
        "prescreen": getattr(cfg, "SC_PRESCREEN_RULES", []),
        "rules": getattr(cfg, "SC_RULES", []),
    }
if "export_pref" not in st.session_state:
    st.session_state["export_pref"] = {"style": "space", "with_suffix": True}

# ===== é¡µçœ‰ =====
st.title("ScoreApp")

# ===== é¡¶å±‚é¡µç­¾ =====
tab_rank, tab_detail, tab_position, tab_rules, tab_attn, tab_data, tab_screen, tab_tools, tab_port, tab_stats, tab_logs = st.tabs(
    ["æ’å", "ä¸ªè‚¡è¯¦æƒ…", "æŒä»“å»ºè®®", "è§„åˆ™ç¼–è¾‘", "å¼ºåº¦æ¦œ", "æ•°æ®ä¸‹è½½/æµè§ˆ", "æ™®é€šé€‰è‚¡", "å·¥å…·ç®±", "ç»„åˆæ¨¡æ‹Ÿ/æŒä»“", "ç»Ÿè®¡", "æ—¥å¿—"]
)

# ================== æ’å ==================
with tab_rank:
    st.subheader("æ’å")
    with st.expander("å‚æ•°è®¾ç½®ï¼ˆè¿è¡Œå‰è¯·ç¡®è®¤ï¼‰", expanded=True):
        c1, c2, c3, c4 = st.columns([1,1,1,1])
        with c1:
            ref_inp = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°ï¼‰", value="", key="rank_ref_input")
            topk = st.number_input("Top-K", min_value=1, max_value=2000, value=cfg_int("SC_TOP_K", 50))
        with c2:
            tie_default = cfg_str("SC_TIE_BREAK", "none").lower()
            tie = st.selectbox("åŒåˆ†æ’åºï¼ˆTie-breakï¼‰", ["none", "kdj_j_asc"], index=0 if tie_default=="none" else 1)
            maxw = st.number_input("æœ€å¤§å¹¶è¡Œæ•°", min_value=1, max_value=64, value=cfg_int("SC_MAX_WORKERS", 8))
        with c3:
            universe = st.selectbox("è¯„åˆ†èŒƒå›´", ["å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•"], index=0)
            style = st.selectbox("TXT å¯¼å‡ºæ ¼å¼", ["ç©ºæ ¼åˆ†éš”", "ä¸€è¡Œä¸€ä¸ª"], index=0)
        with c4:
            attn_on = False
            with_suffix = st.checkbox("å¯¼å‡ºå¸¦äº¤æ˜“æ‰€åç¼€ï¼ˆ.SZ/.SHï¼‰", value=False)
        st.session_state["export_pref"] = {"style": "space" if style=="ç©ºæ ¼åˆ†éš”" else "lines",
                                           "with_suffix": with_suffix}
        run_col1, run_col2 = st.columns([1,1])
        with run_col1:
            run_btn = st.button("ğŸš€ è¿è¡Œè¯„åˆ†ï¼ˆå†™å…¥ Top/All/Detailsï¼‰", use_container_width=True)
        with run_col2:
            latest_btn = st.button("ğŸ“… è¯»å–æœ€è¿‘ä¸€æ¬¡ç»“æœï¼ˆä¸é‡æ–°è®¡ç®—ï¼‰", use_container_width=True)

    # è¿è¡Œ
    ref_to_use = ref_inp.strip() or _pick_latest_ref_date()
    if run_btn:
        _apply_runtime_overrides(st.session_state["rules_obj"], topk, tie, maxw, attn_on,
                                 {"å…¨å¸‚åœº":"all","ä»…ç™½åå•":"white","ä»…é»‘åå•":"black","ä»…ç‰¹åˆ«å…³æ³¨æ¦œ":"attention"}[universe])
        try:
            with se_progress_to_streamlit():
                top_path = se.run_for_date(ref_inp.strip() or None)
            st.success(f"è¯„åˆ†å®Œæˆï¼š{top_path}")
        # è§£æå‚è€ƒæ—¥
            m = re.search(r"(\d{8})", str(top_path))
            if m:
                ref_to_use = m.group(1)
                if latest_btn and not ref_to_use:
                    ref_to_use = _pick_latest_ref_date()
        except Exception as e:
            st.error(f"è¯„åˆ†å¤±è´¥ï¼š{e}")
            ref_to_use = None

    # â€œè¯»å–æœ€è¿‘ä¸€æ¬¡ç»“æœâ€æŒ‰é’®ï¼šä»…è¯»å–ï¼Œä¸è®¡ç®—
    if latest_btn and not run_btn:
        ref_to_use = _pick_latest_ref_date()

    # ---- ç»Ÿä¸€çš„ Top é¢„è§ˆåŒºå—ï¼ˆæ— è®º run æˆ– è¯»å–æœ€è¿‘ä¸€æ¬¡ï¼‰ ----
    if ref_to_use:
        st.markdown(f"**å½“å‰æœ€æ–°æ’åï¼š{ref_to_use}**")
        df_all = _read_df(_path_all(ref_to_use))
    else:
        st.info("æœªæ‰¾åˆ°ä»»ä½• Top æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè¯„åˆ†æˆ–æ£€æŸ¥è¾“å‡ºç›®å½•ã€‚")

    st.divider()
    with st.container(border=True):
        st.markdown("**Top-K é¢„è§ˆ(è¾ƒå¤§çš„è¡¨å¯èƒ½æ¸²æŸ“è¾ƒæ…¢ã€‚**")
        show_mode = st.radio("å±•ç¤ºæ–¹å¼", ["é™åˆ¶æ¡æ•°", "æ˜¾ç¤ºå…¨éƒ¨"], horizontal=True, key="topk_show_mode")
        rows_to_show = None
        if show_mode == "é™åˆ¶æ¡æ•°":
            rows_to_show = st.number_input("Top-K æ˜¾ç¤ºè¡Œæ•°", min_value=5, max_value=1000, value=cfg_int("SC_TOPK_ROWS", 30), key="topk_rows_cfg")
        if ref_to_use and df_all is not None and not df_all.empty:
            if show_mode == "æ˜¾ç¤ºå…¨éƒ¨":
                rows_eff = len(df_all)
                st.caption(f"å·²é€‰æ‹©æ˜¾ç¤ºå…¨éƒ¨ï¼ˆå…± {rows_eff} è¡Œï¼‰ã€‚")
            else:
                rows_eff = int(rows_to_show)
            st.dataframe(df_all.head(rows_eff), use_container_width=True, height=420)
            if "ts_code" in df_all.columns:
                codes = df_all["ts_code"].astype(str).head(rows_eff).tolist()
                txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"], st.session_state["export_pref"]["with_suffix"])
                copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶ä»¥ä¸Šï¼ˆæŒ‰å½“å‰é¢„è§ˆï¼‰", key=f"copy_top_{ref_to_use}")
        else:
            st.caption("æš‚æ—  Top-K æ•°æ®")

# ================== ä¸ªè‚¡è¯¦æƒ… ==================
with tab_detail:
    st.subheader("ä¸ªè‚¡è¯¦æƒ…")

    # â€”â€” é€‰æ‹©å‚è€ƒæ—¥ + ä»£ç ï¼ˆæ”¯æŒä» Top-K ä¸‹æ‹‰é€‰æ‹©ï¼‰ â€”â€”
    c0, c1 = st.columns([1,2])
    with c0:
        ref_d = st.text_input("å‚è€ƒæ—¥ï¼ˆç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="", key="detail_ref_input")
    ref_real = (ref_d or "").strip() or _pick_latest_ref_date() or ""
    # è¯»å–è¯¥å‚è€ƒæ—¥ Top æ–‡ä»¶ä»¥ä¾¿ä¸‹æ‹‰é€‰æ‹©
    try:
        df_top_ref = _read_df(_path_top(ref_real)) if ref_real else pd.DataFrame()
        options_codes = df_top_ref["ts_code"].astype(str).tolist() if ("ts_code" in df_top_ref.columns and not df_top_ref.empty) else []
    except Exception:
        options_codes = []
    with c1:
        code_from_list = st.selectbox("ä» Top-K é€‰æ‹©ï¼ˆå¯é€‰ï¼‰", options=options_codes or [], index=0 if options_codes else None, placeholder="ä¹Ÿå¯æ‰‹åŠ¨è¾“å…¥ â†“")
    code_typed = st.text_input("æˆ–æ‰‹åŠ¨è¾“å…¥è‚¡ç¥¨ä»£ç ", value=(code_from_list or ""), key="detail_code_input")
    code_norm = normalize_ts(code_typed) if code_typed else ""

    # â€”â€” æ¸²æŸ“è¯¦æƒ…ï¼ˆå« old ç‰ˆåŠŸèƒ½ï¼‰ â€”â€”
    if code_norm and ref_real:
        obj = _load_detail_json(ref_real, code_norm)
        if not obj:
            st.warning("æœªæ‰¾åˆ°è¯¥ç¥¨çš„è¯¦æƒ… JSONï¼ˆå¯èƒ½å½“æ—¥æœªåœ¨æ ·æœ¬å†…æˆ–æœªäº§å‡º Detailsï¼‰ã€‚")
        else:
            data = obj
            summary = data.get("summary", {}) or {}
            ts = data.get("ts_code", code_norm)
            score = float(summary.get("score", 0))
            # è®¡ç®—å½“æ—¥æ’åï¼ˆä¼˜å…ˆ JSON â†’ å…¨é‡CSV â†’ Top-K å›é€€ï¼‰
            rank_display = "â€”"
            r_json = summary.get("rank")
            t_json = summary.get("total")
            if isinstance(r_json, (int, float)) and int(r_json) > 0:
                rank_display = f"{int(r_json)}" + (f" / {int(t_json)}" if isinstance(t_json, (int, float)) and int(t_json) > 0 else "")
            else:
                all_path = _path_all(ref_real)
                if all_path.exists():
                    try:
                        df_allx = _read_df(all_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                        if not df_allx.empty:
                            row = df_allx.loc[df_allx["ts_code"].astype(str) == str(ts)]
                            if not row.empty and "rank" in row.columns:
                                rank_display = f"{int(row['rank'].iloc[0])} / {len(df_allx)}"
                    except Exception:
                        pass
                # 2) è‹¥å…¨é‡æ— æœï¼Œå›é€€åˆ° Top æ–‡ä»¶ï¼šæŒ‰è¡Œå·è¿‘ä¼¼åæ¬¡
                if rank_display == "â€”":
                    top_path = _path_top(ref_real)
                    if top_path.exists():
                        try:
                            df_topx = _read_df(top_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                            if not df_topx.empty:
                                if "rank" not in df_topx.columns:
                                    df_topx = df_topx.reset_index(drop=True)
                                    df_topx["rank"] = np.arange(1, len(df_topx) + 1)
                                row = df_topx.loc[df_topx["ts_code"].astype(str) == str(ts)]
                                if not row.empty and "rank" in row.columns:
                                    rank_display = f"{int(row['rank'].iloc[0])} / {len(df_topx)}"
                        except Exception:
                            pass
                        try:
                            df_topx = pd.read_csv(top_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                            pos = df_topx.index[df_topx["ts_code"].astype(str) == str(ts)]
                            if len(pos) > 0:
                                rank_display = str(int(pos[0]) + 1)
                        except Exception:
                            pass

            cols = st.columns(5)
            cols[0].metric("ä»£ç ", ts)
            cols[1].metric("åˆ†æ•°", f"{score:.2f}")
            cols[2].metric("æ’å", rank_display)
            cols[3].metric("å¸‚åœº", market_label(ts))
            cols[4].metric("å‚è€ƒæ—¥", ref_real)

            st.divider()

            # æ€»è§ˆ + é«˜äº®/ç¼ºç‚¹
            colA, colB = st.columns([1,1])
            with colA:
                st.markdown("**æ€»è§ˆ**")
                st.json(summary)
            with colB:
                st.markdown("**é«˜äº® / ç¼ºç‚¹**")
                st.write({"highlights": summary.get("highlights", []), "drawbacks": summary.get("drawbacks", [])})

            # äº¤æ˜“æ€§æœºä¼š
            ops = (summary.get("opportunities") or [])
            with st.expander("äº¤æ˜“æ€§æœºä¼š", expanded=True):
                if ops:
                    for t in ops:
                        st.write("â€¢ " + str(t))
                else:
                    st.caption("æš‚æ— ")

            # é€è§„åˆ™æ˜ç»†ï¼ˆå¯é€‰æ˜¾ç¤º whenï¼‰
            rules = pd.DataFrame(data.get("rules", []))
            name_to_when = {}
            
            from datetime import datetime
            import re as _re

            if not rules.empty:
                
                def _days_from_ref(d: str | None) -> int | None:
                    if isinstance(d, str) and re.fullmatch(r"\d{8}", d):
                        return (datetime.strptime(ref_real, "%Y%m%d") - datetime.strptime(d, "%Y%m%d")).days
                    return None

                if not rules.empty:
                    def _pick_last_hit_days(row):
                        # å…ˆçœ‹ lag æ˜¯å¦æœ‰å€¼ï¼ˆä»… RECENT/DIST/NEARï¼‰
                        lag = row.get("lag")
                        if pd.notna(lag):
                            try:
                                return int(lag)
                            except Exception:
                                pass
                        # å¦åˆ™å›è½åˆ° hit_date â†’ å¤©æ•°
                        return _days_from_ref(row.get("hit_date"))

                    rules["last_hit_days"] = rules.apply(_pick_last_hit_days, axis=1)
                    # å¯é€‰ï¼šæ˜¾ç¤ºæ›´å¹²å‡€ï¼ˆæ”¯æŒç©ºå€¼ï¼‰
                    rules["last_hit_days"] = rules["last_hit_days"].astype("Int64")
            try:
                for r in (getattr(se, "SC_RULES", []) or []):
                    if "clauses" in r and r["clauses"]:
                        ws = [c.get("when","") for c in r["clauses"] if c.get("when")]
                        name_to_when[str(r.get("name","<unnamed>"))] = " AND ".join(ws)
                    else:
                        name_to_when[str(r.get("name","<unnamed>"))] = str(r.get("when",""))
            except Exception:
                name_to_when = {}
            show_when = st.checkbox("æ˜¾ç¤ºè§„åˆ™ when è¡¨è¾¾å¼", value=False, key="detail_show_when")
            if not rules.empty:
                if show_when:
                    rules["when"] = rules["name"].map(name_to_when).fillna("")
                st.markdown("**è§„åˆ™æ˜ç»†**")
                st.dataframe(rules, use_container_width=True, height=420)
            else:
                st.info("æ— è§„åˆ™æ˜ç»†ã€‚")

            with st.expander("æŒ‰è§¦å‘æŸè§„åˆ™ç­›é€‰ï¼ˆå½“æ—¥å…¨å¸‚åœºï¼‰", expanded=True):
                st.caption("è¯´æ˜ï¼šåŸºäºå½“æ—¥ details JSONï¼Œç­›å‡ºâ€˜å‘½ä¸­è¯¥è§„åˆ™â€™çš„è‚¡ç¥¨ï¼›æŒ‰ Score é™åºï¼ˆå¾—åˆ†ç›¸åŒåˆ™æŒ‰ä»£ç å‡åºï¼‰ã€‚")
                # è§„åˆ™åä¸‹æ‹‰ï¼šé»˜è®¤åˆ—å‡ºå½“å‰ç¥¨å½“æ—¥è¯¦æƒ…é‡Œçš„è§„åˆ™åï¼Œæ–¹ä¾¿é€‰æ‹©
                rule_names = [r.get("name") for r in (data.get("rules") or []) if r.get("name")]
                chosen_rule_name = st.selectbox("é€‰æ‹©è§„åˆ™ï¼ˆæŒ‡æ ‡ï¼‰", options=sorted(set(rule_names)) if rule_names else [], 
                                                index=0 if rule_names else None, placeholder="è¯·é€‰æ‹©ä¸€ä¸ªè§„åˆ™å")
                colL, colR = st.columns([1,1])
                with colL:
                    only_topk = st.checkbox("ä»…é™å½“æ—¥ Top-K èŒƒå›´", value=True)
                with colR:
                    run_filter = st.button("ç­›é€‰å½“æ—¥å‘½ä¸­æ ‡çš„", use_container_width=True)

                if run_filter:
                    if not ref_real:
                        st.error("æœªèƒ½ç¡®å®šå‚è€ƒæ—¥ã€‚")
                    elif not chosen_rule_name:
                        st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§„åˆ™åã€‚")
                    else:
                        # è¯»å–å½“æ—¥å…¨å¸‚åœº detailsï¼ŒæŒ‘å‡ºå‘½ä¸­ chosen_rule_name çš„è‚¡ç¥¨
                        rows = []
                        ddir = DET_DIR / ref_real
                        try:
                            # å¯é€‰ï¼šç”¨ All æ–‡ä»¶é™åˆ¶ universeï¼ˆTop-Kï¼‰
                            allow_set = None
                            if only_topk:
                                df_allx = _read_df(_path_all(ref_real), dtype={"ts_code": str}, encoding="utf-8-sig")
                                if not df_allx.empty:
                                    # è‹¥æœ‰ rank åˆ—ï¼Œé»˜è®¤ All å³å…¨å¸‚åœºï¼›è‹¥ä½ å¸Œæœ›ä¸¥æ ¼ Top-Kï¼Œå¯åœ¨è¿™é‡Œè¿›ä¸€æ­¥ head(K)
                                    allow_set = set(df_allx["ts_code"].astype(str))
                            if ddir.exists():
                                for p in ddir.glob("*.json"):
                                    try:
                                        j = json.loads(p.read_text(encoding="utf-8-sig"))
                                    except Exception:
                                        continue
                                    ts2 = str(j.get("ts_code", "")).strip()
                                    if not ts2:
                                        continue
                                    if (allow_set is not None) and (ts2 not in allow_set):
                                        continue
                                    sm = j.get("summary") or {}
                                    sc = float(sm.get("score", 0.0))
                                    hit = False
                                    for rr in j.get("rules", []) or []:
                                        # å‘½ä¸­æ ‡å‡†ï¼šè¯¥è§„åˆ™åç›¸ç­‰ï¼Œä¸”å½“æ—¥åŠ åˆ†>0 æˆ– ok=True
                                        if rr.get("name") == chosen_rule_name and (float(rr.get("add", 0.0)) > 0.0 or bool(rr.get("ok"))):
                                            hit = True
                                            break
                                    if hit:
                                        rows.append({"ts_code": ts2, "score": sc})
                            df_hit = pd.DataFrame(rows)
                            if df_hit.empty:
                                st.info("å½“æ—¥æ— æ ‡çš„å‘½ä¸­è¯¥è§„åˆ™ã€‚")
                            else:
                                # æ’åºï¼šscore é™åºï¼›åˆ†æ•°ç›¸åŒæŒ‰ä»£ç å‡åºï¼ˆä½œä¸ºæœ€ç»ˆ tiebreakï¼‰
                                df_hit = df_hit.sort_values(["score", "ts_code"], ascending=[False, True]).reset_index(drop=True)
                                st.dataframe(df_hit, use_container_width=True, height=420)
                                # å¯¼å‡º & å¤åˆ¶
                                codes = df_hit["ts_code"].astype(str).tolist()
                                txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"], st.session_state["export_pref"]["with_suffix"])
                                copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶ç­›é€‰ç»“æœï¼ˆæŒ‰å½“å‰é¢„è§ˆï¼‰", key=f"copy_rulehits_{ref_real}_{chosen_rule_name}")
                                _download_txt("å¯¼å‡ºç­›é€‰ç»“æœ TXT", txt, f"rulehits_{normalize_ts(chosen_rule_name)}_{ref_real}.txt", key="dl_rule_hits")
                        except Exception as e:
                            st.error(f"ç­›é€‰å¤±è´¥ï¼š{e}")

# ================== æŒä»“å»ºè®® ==================
with tab_position:
    st.subheader("æŒä»“å»ºè®®")

# ================== è§„åˆ™ç¼–è¾‘ ==================
with tab_rules:
    st.subheader("è§„åˆ™ç¼–è¾‘ï¼ˆä»…å½“å‰è¿›ç¨‹ä¸´æ—¶ç”Ÿæ•ˆï¼Œä¿å­˜ä¸ä¼šæ”¹ config.pyï¼‰")
    colL, colR = st.columns([2,1])
    default_text = json.dumps(st.session_state["rules_obj"], ensure_ascii=False, indent=2)
    with colL:
        text = st.text_area("è§„åˆ™ JSONï¼ˆå« prescreen / rulesï¼‰", value=default_text, height=300)
    with colR:
        up = st.file_uploader("ä»æ–‡ä»¶è½½å…¥ JSON", type=["json"])
        if up:
            try:
                st.session_state["rules_obj"] = json.loads(up.read().decode("utf-8-sig"))
                st.success("å·²è½½å…¥è‡³ç¼–è¾‘å™¨ï¼ˆæœªåº”ç”¨ï¼‰ã€‚")
            except Exception as e:
                st.error(f"è½½å…¥å¤±è´¥ï¼š{e}")
        if st.button("âœ… æ ¡éªŒå¹¶åº”ç”¨ï¼ˆä»…å½“å‰è¿›ç¨‹ï¼‰", use_container_width=True):
            try:
                st.session_state["rules_obj"] = json.loads(text)
                st.success("æ ¡éªŒé€šè¿‡ï¼Œå·²åº”ç”¨ã€‚è¿è¡Œè¯„åˆ†æ—¶å°†ä½¿ç”¨è¯¥ä¸´æ—¶è§„åˆ™ã€‚")
            except Exception as e:
                st.error(f"JSON è§£æå¤±è´¥ï¼š{e}")
        RULES_JSON = Path("./rules.json")
        if st.button("ğŸ’¾ å¯¼å‡ºåˆ° rules.json", use_container_width=True):
            try:
                RULES_JSON.write_text(text, encoding="utf-8-sig")
                st.success(f"å·²å†™å…¥ {RULES_JSON}")
            except Exception as e:
                st.error(f"å†™å…¥å¤±è´¥ï¼š{e}")

        if st.button("ğŸ“¥ ä» rules.json è½½å…¥", use_container_width=True):
            try:
                t = RULES_JSON.read_text(encoding="utf-8-sig")
                st.session_state["rules_obj"] = json.loads(t)
                st.success("å·²åŠ è½½åˆ°ç¼–è¾‘å™¨ï¼ˆåˆ«å¿˜äº†å†ç‚¹â€œæ ¡éªŒå¹¶åº”ç”¨â€ï¼‰")
            except Exception as e:
                st.error(f"è¯»å–å¤±è´¥ï¼š{e}")

        if st.button("â†©ï¸ è¿˜åŸä¸º config é»˜è®¤", use_container_width=True):
            st.session_state["rules_obj"] = {
                "prescreen": getattr(cfg, "SC_PRESCREEN_RULES", []),
                "rules": getattr(cfg, "SC_RULES", []),
            }
            st.experimental_rerun()
    st.divider()
    with st.container(border=True):
        st.markdown("### ğŸ§ª ç­–ç•¥æµ‹è¯•å™¨ï¼ˆå•æ¡è§„åˆ™ï¼‰")
        with st.expander("ä½¿ç”¨æ–¹æ³• / å­—æ®µè¯´æ˜", expanded=False):
            st.markdown(r"""###è§„åˆ™ç³»ç»Ÿä¸è¡¨è¾¾å¼
- **å¿…å¡«**
- `name`ï¼šè§„åˆ™åç§°
- `when`ï¼šé€šè¾¾ä¿¡é£æ ¼å¸ƒå°”è¡¨è¾¾å¼ï¼ˆè§ä¸‹ç¬¬ 4 èŠ‚ï¼‰
- `timeframe`ï¼š`D` / `W` / `M`ï¼ˆå‘¨çº¿æŒ‰ `W-FRI` èšåˆï¼›æœˆçº¿æŒ‰è‡ªç„¶æœˆèšåˆï¼‰
- `window`ï¼šå›çœ‹çª—å£ï¼ˆæ•´æ•°ï¼ŒæŒ‰ `timeframe` è®¡ï¼‰
- `scope`ï¼šå‘½ä¸­å£å¾„ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰
- **å¯é€‰**
- `points`ï¼šå‘½ä¸­åŠ åˆ†ã€‚`EACH/PERBAR` ä¸ºâ€œ**æ¯æ ¹Kçº¿** * pointsâ€ã€‚
- `explain`ï¼šå‘½ä¸­ç†ç”±æ–‡æ¡ˆï¼›`show_reason`ï¼ˆé»˜è®¤ `true`ï¼‰æ§åˆ¶æ˜¯å¦åœ¨æ±‡æ€»ä¸­å±•ç¤ºï¼›`as` å¯é€‰ `opportunity` / `highlight` / `drawback` / `auto`ï¼ˆæŒ‰æ­£è´Ÿåˆ†è‡ªåŠ¨å½’ç±»ï¼‰ã€‚
- `clauses`ï¼šå¤åˆå­å¥æ•°ç»„ï¼Œ**ä¸é€»è¾‘**ã€‚æ¯ä¸ªå­å¥å¯å•ç‹¬è®¾ç½® `timeframe/window/scope/when`ã€‚
- `gate` / `require` / `trigger`ï¼šå¯é€‰çš„â€œé—¸é—¨/å¿…è¦æ¡ä»¶/è§¦å‘æ¡ä»¶â€ï¼ˆå¸ƒå°”è¡¨è¾¾å¼æˆ–å­å¥é›†ï¼‰ï¼Œç”¨äºæ”¾/æ‹¦åŠ åˆ†ï¼ˆå¸¸ç”¨äº `EACH` æˆ– `RECENT` ç±»è§„åˆ™çš„äºŒæ¬¡è¿‡æ»¤ï¼‰ã€‚
- `dist_points`ï¼ˆæˆ– `distance_points`ï¼‰ï¼š**`RECENT`/`DIST`/`NEAR`** çš„â€œè·ç¦»è®¡åˆ†è¡¨â€ã€‚ä¸¤ç§ç­‰ä»·å†™æ³•ï¼š
    - åˆ—è¡¨ï¼š`[[min, max, points], ...]`  
    - å­—å…¸ï¼š`[{"min":0,"max":0,"points":3}, {"min":1,"max":2,"points":2}]`
- å…¶å®ƒï¼š`universe`ï¼ˆ"all"/"white"/"black"/"attention"/æˆ–è‡ªå®šä¹‰ä»£ç åˆ—è¡¨ï¼‰ç­‰ï¼ˆåœ¨æ™®é€šç­›é€‰å™¨ä¸ç­–ç•¥æµ‹è¯•å™¨ä¸­å¯é€‰ï¼‰ã€‚

#### 4) `scope` å£å¾„ï¼ˆå‘½ä¸­åˆ¤å®šï¼‰
- åŸºæœ¬ï¼š`LAST` / `ANY` / `ALL` / `COUNT>=k` / `CONSEC>=m`ã€‚
- æ‰©å±•ï¼š`ANY_n` / `ALL_n`ï¼ˆé•¿åº¦ä¸º n çš„**è¿ç»­å­çª—å£**ä¸Šï¼Œä»»ä¸€/å…¨éƒ¨ä¸ºçœŸï¼‰ã€‚
- é€Kè®¡æ•°ï¼š`EACH` / `PERBAR` / `EACH_TRUE`ï¼ˆçª—å£å†…æ¯ä¸€æ ¹ K çº¿æ»¡è¶³æ—¶æŒ‰æ¬¡è®¡åˆ†ï¼‰ã€‚
- æœ€è¿‘è·ç¦»ï¼š`RECENT` / `DIST` / `NEAR`ï¼ˆå…ˆæ±‚æœ€è¿‘ä¸€æ¬¡ `when` ä¸ºçœŸè·ä»Šå¤©æ•° `lag`ï¼Œå†æŸ¥è¡¨è®¡åˆ†ï¼›æ”¯æŒ `hit_date` / `hit_dates` å–æ•°ï¼‰ã€‚

**å‘½ä¸­æ—¥æœŸä¸å±•ç¤ºå£å¾„ï¼ˆé‡è¦ï¼‰ï¼š**
- `EACH/PERBAR`ï¼šé€Kè®¡æ•°ï¼›`hit_date` ä¸ºçª—å£å†…**æœ€åä¸€æ¬¡ä¸ºçœŸ**ï¼›`hit_dates` æ˜¯**çª—å£å†…æ‰€æœ‰ä¸ºçœŸ**ã€‚  
- `RECENT/DIST/NEAR`ï¼šå…ˆç®— `lag`ï¼Œç”±ç´¢å¼•å›æ¨ `hit_date`ï¼›åŒæ—¶åˆ—å‡º `hit_dates`ã€‚  
- å…¶å®ƒï¼ˆ`ANY/ALL/LAST/COUNT/CONSEC/ANY_n/ALL_n`ï¼‰ï¼šæŒ‰å¸ƒå°”å‘½ä¸­ï¼›`hit_dates` ä¸ºçª—å£å†…æ‰€æœ‰ä¸ºçœŸã€‚

#### 5) `when` è¡¨è¾¾å¼ï¼ˆTDX å…¼å®¹ï¼‰
**å¯ç”¨å˜é‡ï¼ˆéƒ¨åˆ†ï¼‰**ï¼š`C/CLOSE`ã€`O/OPEN`ã€`H/HIGH`ã€`L/LOW`ã€`V/VOL`ã€`AMOUNT`ã€`REFDATE`ï¼ˆå‚è€ƒæ—¥ï¼‰ã€`J`ï¼ˆKDJÂ·Jï¼‰ã€`VR`ã€ä»¥åŠæ•°æ®åˆ—è‡ªåŠ¨åˆ«åï¼ˆåŸåä¸å…¨å¤§å†™ï¼Œå¦‚ `z_score` / `Z_SCORE`ï¼‰ã€‚  
**å¯ç”¨å‡½æ•°ï¼ˆéƒ¨åˆ†ï¼‰**ï¼š`REF/MA/EMA/SMA/SUM/HHV/LLV/STD/ABS/MAX/MIN/IF/COUNT/CROSS/BARSLAST/SAFE_DIV/RSV`ï¼Œä»¥åŠåºåˆ—å·¥å…· `TS_PCT/TS_RANK`ã€‚  
**æ ‡ç­¾å·¥å…·**ï¼š`ANY_TAG("å…³é”®è¯|æ­£åˆ™", shift)`ã€`TAG_HITS(...)`ã€`ANY_TAG_AT_LEAST(...)`ã€`YDAY_TAG_HITS(...)`ã€`YDAY_ANY_TAG_AT_LEAST(...)`ã€‚  
**æ³¨å…¥å‡½æ•°**ï¼š`RANK_VOL(ts, n)`ã€`RANK_RET(ts, n)`ã€`RANK_MATCH_COEF(ts, n)` å¯ç”±ç³»ç»Ÿæ³¨å…¥åˆ°è¡¨è¾¾å¼ç¯å¢ƒï¼ˆè§â€œç­–ç•¥æµ‹è¯•å™¨â€ä¸æ˜ç»†è®¡ç®—ï¼‰ã€‚

ç¤ºä¾‹ï¼š
```text
VOL>MA(VOL,5) AND CLOSE>MA(CLOSE,20)                {æ”¾é‡å¹¶ç«™ä¸ŠMA20}
CROSS(CLOSE, MA(CLOSE, 60))                          {æ”¶ç›˜ä¸Šç©¿MA60}
COUNT(C>O, 5) >= 3 AND CONSEC>=2                     {è¿‘5æ—¥è‡³å°‘3å¤©æ”¶é˜³ä¸”å‡ºç°2è¿é˜³}
TS_PCT(Z_SCORE, 120) >= 0.95                         {120æ—¥åˆ†ä½ >= 95%}
```

#### 6) å‘¨/æœˆçº¿ä¸çª—å£
- å‘¨çº¿ `W` ä¸æœˆçº¿ `M` ç”±æ—¥çº¿**é‡é‡‡æ ·**ï¼š`open/close/high/low/vol/amount` åˆ†åˆ«æŒ‰â€œé¦–/æœ«/æå€¼/æ±‚å’Œâ€èšåˆï¼Œæ‰©å±•åˆ—ï¼ˆå¦‚ `j/vr`ï¼‰é»˜è®¤å–**æœ€åå€¼**ï¼›çª—å£åœ¨é‡‡æ ·åçš„ç´¢å¼•ä¸Šæˆªå–ã€‚

#### 7) ç­–ç•¥æµ‹è¯•å™¨ï¼ˆå•æ¡è§„åˆ™ï¼‰
- è¾“å…¥ä¸€æ¡è§„åˆ™ï¼ˆJSONï¼‰ï¼Œå¯åœ¨**ä¸ªè‚¡**æˆ–**åå•**ä¸Šå¿«é€Ÿè¯•è·‘ï¼›å¹¶å¯¹å‘½ä¸­ç»†èŠ‚ç»™å‡ºä¸â€œè¯¦æƒ…é¡µä¸€è‡´â€çš„å£å¾„ï¼ˆå« `lag/hit_date/hit_dates` çš„å¤„ç†ï¼‰ã€‚
- æ”¯æŒé€‰æ‹©åå•ï¼šå…¨å¸‚åœº/ç™½åå•/é»‘åå•/ç‰¹åˆ«å…³æ³¨ï¼ˆæ¦œå•ä» `output/attention` ä¸‹è‡ªåŠ¨é€‰æ‹©å‚è€ƒæœŸ â‰¤ å‚è€ƒæ—¥çš„**æœ€æ–°ä¸€ä»½**ï¼‰ã€‚
- å‚è€ƒæ—¥ç•™ç©ºå°†è‡ªåŠ¨æ¨æ–­ä¸º**åˆ†åŒºæœ€æ–°äº¤æ˜“æ—¥**ï¼ˆè‹¥ç¯å¢ƒå˜é‡è®¾ç½®äº† `SC_REF_DATE` ä¹Ÿä¼šå°Šé‡ï¼‰ã€‚

#### 8) `RECENT/DIST/NEAR` çš„è®¡åˆ†è¡¨å†™æ³•
- åˆ—è¡¨ï¼š`[[0,0,3], [1,2,2], [3,5,1]]`
- å­—å…¸ï¼š`[{"min":0,"max":0,"points":3}, {"min":1,"max":2,"points":2}, {"min":3,"max":5,"points":1}]`

#### 9) å¯¼å‡ºä¸æ–‡ä»¶
- **æ˜ç»†**ï¼š`output/score/details/<YYYYMMDD>/<ts_code>_<YYYYMMDD>.json`ï¼ˆå« `summary` ä¸ per-rule æ˜ç»†ï¼‰ã€‚
- **å…¨é‡æ’å**ï¼š`output/score/all/score_all_<YYYYMMDD>.csv`ï¼ˆæŒ‰åˆ†æ•°é™åº â†’ tiebreak(J) é™åº â†’ ä»£ç å‡åºï¼‰ã€‚
- **ç‰¹åˆ«å…³æ³¨**ï¼š`output/attention/attention_{source}_{start}_{end}.csv`ï¼ˆè‡ªåŠ¨æ‹©æœ€æ–°ä¸” `end <= å‚è€ƒæ—¥` çš„ä¸€ä»½ï¼‰ã€‚

> å°è´´å£«ï¼šè¡¨è¾¾å¼æ‰«æä¼š**æŒ‰éœ€è£åˆ—**ï¼ˆè‹¥ `when` ç”¨åˆ° `j/vr` ç­‰æ‰©å±•åˆ—ä¼šè‡ªåŠ¨è¡¥è¯»ï¼‰ï¼›`COUNT` åœ¨æ ·æœ¬ä¸è¶³æ—¶æŒ‰â€œå·²æœ‰æ ·æœ¬â€è®¡æ•°ï¼Œ`NaN` ç»Ÿä¸€æŒ‰ False å¤„ç†ï¼Œé¿å…è¯¯åˆ¤ã€‚""")


        # 1) é¦–æ¬¡è¿›å…¥æ—¶ç»™ä¸€ä¸ªé»˜è®¤æ¨¡æ¿
        if "tester_rule_json" not in st.session_state:
            st.session_state["tester_rule_json"] = json.dumps({
                "name": "æµ‹è¯•ï¼šè¿‘3æ—¥æ”¾é‡å¹¶ç«™ä¸ŠMA20",
                "timeframe": "D",
                "window": 60,
                "scope": "RECENT",
                "when": "VOL>MA(VOL,5) AND CLOSE>MA(CLOSE,20)",
                "points": 3,
                "dist_points": [{"min":0,"max":0,"points":3},{"min":1,"max":2,"points":2},{"min":3,"max":5,"points":1}],
                "explain": "è¿‘Næ—¥æ”¾é‡ä¸”ç«™ä¸ŠMA20"
            }, ensure_ascii=False, indent=2)

        colleft, colright = st.columns([2,1])
        with colright:
            def _clear_tester_rule():
                # empty_rule = None
                # st.session_state["tester_rule_json"] = json.dumps(empty_rule, ensure_ascii=False, indent=2)
                st.session_state["tester_rule_json"] = ""
            st.button("ğŸ§¹ ä¸€é”®æ¸…ç©º", use_container_width=True, on_click=_clear_tester_rule)
            ref_in = st.text_input("å‚è€ƒæ—¥ï¼ˆç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="")
            ts_in = st.text_input("ä¸ªè‚¡ä»£ç ", value="")
            uni_choice = st.selectbox("åå•", ["å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•"], index=0, key="tester_uni")
            _uni_map = {"å…¨å¸‚åœº":"all", "ä»…ç™½åå•":"white", "ä»…é»‘åå•":"black", "ä»…ç‰¹åˆ«å…³æ³¨æ¦œ":"attention"}

        with colleft:
            # 2) ä¸è¦å†ä¼  value=â€¦â€¦ï¼Œåªä¿ç•™ key
            rule_raw = st.text_area("ä¸´æ—¶è§„åˆ™ï¼ˆJSONï¼‰", height=260, key="tester_rule_json")

        colD, colE = st.columns([1,1])
        with colD:
            run_btn = st.button("åœ¨ä¸ªè‚¡ä¸­è¿è¡Œ", use_container_width=True)
        with colE:
            run_all_btn = st.button("åœ¨åå•ä¸­è¿è¡Œ", use_container_width=True, key="tester_run_all")

        refD_all = ref_in.strip() or _pick_latest_ref_date() or ""
        if run_all_btn:
            try:
                raw = st.session_state.get("tester_rule_json", "")
                if raw.strip():
                    rule = json.loads(raw)
                else:
                    rule = None   # ç”¨æˆ·å½“å‰æ²¡å¡«

                rule = json.loads(rule_raw)
                when_expr, tf, win, scope = _rule_to_screen_args(rule)

                # 2) è°ƒ tdx_screenï¼Œæ³¨æ„ä¸å†™é»‘ç™½åå•ï¼Œä»…é¢„è§ˆ
                df_sel = se.tdx_screen(
                    when_expr,
                    ref_date=refD_all.strip() or None,
                    timeframe=tf,
                    window=int(win),
                    scope=scope,                              # æ”¯æŒ LAST/ANY/ALL/COUNT>=k/CONSEC>=m/ANY_n/ALL_n:contentReference[oaicite:7]{index=7}
                    universe=_uni_map.get(uni_choice,"all"),  # all/white/black/attention
                    write_white=False,
                    write_black_rest=False,
                    return_df=True
                )
                # 3) å‹å¥½åˆ—
                if not df_sel.empty:
                    df_sel["board"] = df_sel["ts_code"].map(market_label)
                    st.success(f"å‘½ä¸­ {len(df_sel)} åªï¼›å‚è€ƒæ—¥ï¼š{df_sel['ref_date'].iloc[0] if 'ref_date' in df_sel.columns and len(df_sel)>0 else (refD_all or 'è‡ªåŠ¨')}")
                    st.dataframe(df_sel, use_container_width=True, height=480)
                    # å¯¼å‡º
                    csv_bytes = df_sel.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("å¯¼å‡ºç»“æœ CSV", data=csv_bytes, file_name="tester_screen_all.csv", mime="text/csv", use_container_width=True)
                else:
                    st.info("æœªå‘½ä¸­ã€‚")

                # 4) ï¼ˆå¯é€‰ï¼‰ç‚¹åçœ‹â€œå•ç¥¨æ˜ç»†â€ â€”â€” å’Œä¸Šé¢æ˜ç»†é¡µåŒå£å¾„
                st.markdown("###### æŸ¥çœ‹æŸåªè‚¡ç¥¨çš„æ˜ç»†ï¼ˆä¸å•ç¥¨æµ‹è¯•ç›¸åŒå£å¾„ï¼‰")
                ts_pick_ori = st.text_input("è¾“å…¥ ts_code æŸ¥çœ‹ï¼ˆå¦‚ 000001.SZï¼‰", value="")
                ts_pick = normalize_ts((ts_pick_ori or "").strip())
                if ts_pick:
                    # æ ¹æ®è§„åˆ™çª—å£ä¼°ç®—æœ€å°è¯»å–åŒºé—´ï¼Œç„¶åè¯»å•ç¥¨æ•°æ®
                    ref = (df_sel["ref_date"].iloc[0] if (not df_sel.empty and "ref_date" in df_sel.columns) else (refD_all or None)) or se._pick_ref_date()
                    start = se._compute_read_start(ref)  # ä¿è¯çª—å£è¶³å¤Ÿ:contentReference[oaicite:9]{index=9}:contentReference[oaicite:10]{index=10}
                    dfD = se._read_stock_df(ts_pick.strip(), start, ref, columns=["trade_date","open","high","low","close","vol","amount"])
                    per_rows = se._build_per_rule_detail(dfD, ref)  # è¿”å›å« ok/add/cnt/lag/hit_date/hit_dates ç­‰å­—æ®µ:contentReference[oaicite:11]{index=11}
                    df_detail = pd.DataFrame(per_rows)
                    # åªæ˜¾ç¤ºå½“å‰è¿™æ¡è§„åˆ™ï¼ˆæŒ‰ name æˆ– when å…³é”®å­—éƒ½å¯ä»¥ï¼‰
                    name_key = str(rule.get("name","")).strip()
                    if name_key:
                        df_detail = df_detail[df_detail["name"] == name_key]
                    st.dataframe(df_detail, use_container_width=True)
            except Exception as e:
                st.error(f"è¿è¡Œå¤±è´¥ï¼š{e}")

        if run_btn:
            try:
                raw = st.session_state.get("tester_rule_json", "")
                if raw.strip():
                    rule = json.loads(raw)
                else:
                    rule = None   # ç”¨æˆ·å½“å‰æ²¡å¡«
                rule = json.loads(rule_raw or "{}")
            except Exception as e:
                st.error(f"è§„åˆ™ JSON è§£æå¤±è´¥ï¼š{e}")
                st.stop()

            ts_code = normalize_ts((ts_in or "").strip())
            if not ts_code:
                st.error("è¯·å¡«å†™æµ‹è¯•ä»£ç ")
                st.stop()

            # æš‚å­˜å¹¶ä¸´æ—¶æ›¿æ¢å…¨å±€è§„åˆ™é›†ï¼Œåªè·‘è¿™ä¸€æ¡
            bak_rules = getattr(se, "SC_RULES", None)
            setattr(se, "SC_RULES", [rule])
            bak_pres  = getattr(se, "SC_PRESCREEN_RULES", None)
            try:
                setattr(se, "SC_RULES", [rule])
                setattr(se, "SC_PRESCREEN_RULES", [])

                # å‚è€ƒæ—¥ & è¯»å–çª—å£ / åˆ—è£å‰ª
                ref_use = (ref_in or "").strip() or (_pick_latest_ref_date() or "")
                if not ref_use:
                    st.error("æœªæ‰¾åˆ°å‚è€ƒæ—¥ï¼šè¯·å…ˆåœ¨â€œæ’åâ€é¡µç­¾è·‘ä¸€æ¬¡æˆ–æ‰‹å¡«ã€‚")
                    st.stop()

                # ä¼°ç®—è¯»å–èµ·ç‚¹ï¼ˆæŒ‰æœ¬æ¡è§„åˆ™çš„ timeframe+windowï¼‰
                start = se._start_for_tf_window(ref_use, str(rule.get("timeframe", "D")), int(rule.get("window", getattr(se, "SC_LOOKBACK_D", 60))))

                # 1) å½“å‰æµ‹è¯•è§„åˆ™æ‰€éœ€çš„èµ·å§‹æ—¥ä¸åˆ—
                tf_curr = str(rule.get("timeframe","D"))
                win_curr = int(rule.get("window", getattr(se, "SC_LOOKBACK_D", 60)))
                start_curr = se._start_for_tf_window(ref_use, tf_curr, win_curr)
                cols_curr = set(se._select_columns_for_rules())

                # 2) æ‰«æ•´ä»½ configï¼ˆå°¤å…¶æ˜¯ as=... çš„æ ‡ç­¾è§„åˆ™ï¼‰æ‰€éœ€çš„â€œæœ€æ—©èµ·å§‹æ—¥ + åˆ—â€
                cfg_cols = set()
                cfg_start = start_curr
                if bak_rules:
                    se.SC_RULES = bak_rules
                    try:
                        cfg_cols = set(se._select_columns_for_rules())
                        # ä»…è€ƒè™‘å¸¦ as çš„è§„åˆ™ï¼ˆæœºä¼š/äº®ç‚¹/ç‘•ç–µæ ‡ç­¾ï¼‰ï¼Œä¼°ç®—å®ƒä»¬å„è‡ªæ‰€éœ€çš„èµ·å§‹æ—¥ï¼Œå–æœ€æ—©
                        cfg_starts = []
                        for r in (bak_rules or []):
                            if str(r.get("as") or "").strip():
                                tf_r = str(r.get("timeframe","D"))
                                win_r = int(r.get("window", getattr(se, "SC_LOOKBACK_D", 60)))
                                cfg_starts.append(se._start_for_tf_window(ref_use, tf_r, win_r))
                        if cfg_starts:
                            cfg_start = min([start_curr] + cfg_starts)
                    finally:
                        # å¤ä½å›å•æ¡æµ‹è¯•
                        se.SC_RULES = [rule]
                        se.SC_PRESCREEN_RULES = []

                # å¹¶é›†åˆå¹¶ï¼šè¯»æ›´æ—©çš„èµ·å§‹æ—¥ + æ›´å…¨çš„åˆ—
                start = cfg_start
                columns = sorted(cols_curr | cfg_cols)

                # è¯»å–å•ç¥¨æ•°æ®
                df = se._read_stock_df(ts_code, start, ref_use, columns)
                if df is None or df.empty:
                    st.warning("æ•°æ®ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ã€‚")
                    st.stop()

                # ä¿æŒä¸æ­£å¼è¯„åˆ†ä¸€è‡´çš„è¡¨è¾¾å¼ä¸Šä¸‹æ–‡
                # 3) å…œåº•è¡¥é½æ ‡ç­¾è§„åˆ™å¸¸ç”¨æŒ‡æ ‡ï¼ˆå¦‚ j/vrï¼‰ï¼Œä»¥å…æ³¨å…¥å¤±è´¥
                try:
                    need_j = False
                    need_vr = False
                    if bak_rules:
                        for r in bak_rules:
                            if not str(r.get("as") or "").strip():
                                continue
                            texts = [str(r.get("when") or "")]
                            texts += [str(c.get("when") or "") for c in r.get("clauses",[])]
                            s = " ".join(texts).lower()
                            need_j = need_j or (" j" in f" {s}")  # ç²—ç•¥åŒ…å«åˆ¤æ–­
                            need_vr = need_vr or (" vr" in f" {s}")
                    if need_j and ("j" not in df.columns):
                        try:
                            from indicators import kdj
                            df = df.copy()
                            df["j"] = kdj(df)
                        except Exception:
                            pass
                    if need_vr and ("vr" not in df.columns) and ("vol" in df.columns):
                        try:
                            import pandas as pd
                            v = pd.to_numeric(df["vol"], errors="coerce")
                            n = 26
                            df = df.copy()
                            df["vr"] = (v / v.rolling(n).mean()).values
                        except Exception:
                            pass
                except Exception:
                    pass

                # 4) æ˜ç¡®æ³¨å…¥ config æ ‡ç­¾åˆ° CUSTOM_TAGSï¼ˆä¸æ­£å¼é“¾è·¯å¯¹é½ï¼‰
                try:
                    if tdx is not None:
                        # tdx.EXTRA_CONTEXT.clear()
                        tdx.EXTRA_CONTEXT.update(se.get_eval_env(ts_code, ref_use))
                        if bak_rules:
                            se.SC_RULES = bak_rules
                            try:
                                se._inject_config_tags(df, ref_use)  # è¿™é‡Œç”¨æ—¥çº¿ df æ³¨å…¥æ ‡ç­¾
                            finally:
                                se.SC_RULES = [rule]
                        else:
                            se._inject_config_tags(df, ref_use)
                except Exception:
                    pass

                # ç›´æ¥ç”¨ä¸â€œè¯¦æƒ…é¡µâ€ä¸€è‡´çš„æ„é€ å‡½æ•°å¾—åˆ°é€è§„åˆ™æ˜ç»†
                rows = se._build_per_rule_detail(df, ref_use)
                if not rows:
                    st.info("æœªäº§ç”Ÿä»»ä½•å‘½ä¸­/ç»†èŠ‚ã€‚")
                    st.stop()

                import pandas as pd, numpy as np
                df_rules = pd.DataFrame(rows).copy()

                # â€”â€” â€œæœ€åå‘½ä¸­è·ä»Šå¤©æ•°â€ ä¸è¯¦æƒ…é¡µä¸€è‡´çš„å£å¾„ï¼šä¼˜å…ˆç”¨ lagï¼Œå…¶æ¬¡ hit_dateï¼Œå†é€€ hit_dates æœ€æœ« â€”â€” 
                ref_dt = pd.to_datetime(ref_use)
                def _last_days(row: dict):
                    lag = row.get("lag")
                    if isinstance(lag, (int, float)) and not pd.isna(lag):
                        return int(lag)
                    hd = row.get("hit_date")
                    if isinstance(hd, str) and hd:
                        try: return int((ref_dt - pd.to_datetime(hd)).days)
                        except Exception: return None
                    hds = row.get("hit_dates") or []
                    if isinstance(hds, list) and hds:
                        try: return int((ref_dt - pd.to_datetime(hds[-1])).days)
                        except Exception: return None
                    return None

                df_rules["last_hit_days"] = [ _last_days(r) for r in df_rules.to_dict("records") ]

                # å±•ç¤ºåˆ—ï¼ˆå­˜åœ¨æ‰å±•ç¤ºï¼‰
                show_cols = [c for c in [
                    "name","scope","timeframe","window","period","ok","points","add","cnt","lag",
                    "hit_date","hit_count","hit_dates","last_hit_days","gate_ok","gate_when","explain"
                ] if c in df_rules.columns]

                st.markdown(f"**æµ‹è¯•ä»£ç ï¼š{ts_code} Â· å‚è€ƒæ—¥ï¼š{ref_use}**")
                st.dataframe(df_rules[show_cols], use_container_width=True, height=420)

            except Exception as e:
                st.error(f"æµ‹è¯•å¤±è´¥ï¼š{e}")
            finally:
                # è¿˜åŸå…¨å±€
                if bak_rules is not None: setattr(se, "SC_RULES", bak_rules)
                if bak_pres  is not None: setattr(se, "SC_PRESCREEN_RULES", bak_pres)

# ================== å¼ºåº¦æ¦œ ==================
with tab_attn:
    st.subheader("å¼ºåº¦æ¦œ")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        src = st.selectbox("æ¥æº", ["top","white","black","attention"], index=0)
        method = st.selectbox("æ–¹æ³•", ["å¼ºåº¦ï¼ˆå¸¦æƒï¼‰","æ¬¡æ•°ï¼ˆä¸å¸¦æƒï¼‰"], index=0)
    with c2:
        win_n = st.number_input("çª—å£å¤©æ•° N", min_value=1, max_value=365, value=60)
        top_m = st.number_input("Top-M è¿‡æ»¤ï¼ˆä»…ç»Ÿè®¡å‰ M åï¼‰", min_value=1, max_value=5000, value=3000)
    with c3:
        weight = st.selectbox("æ—¶é—´æƒé‡", ["ä¸åŠ æƒ","æŒ‡æ•°åŠè¡°","çº¿æ€§æœ€å°å€¼"], index=1)
        out_n = st.number_input("è¾“å‡º Top-N", min_value=1, max_value=1000, value=100)
    with c4:
        # date_end = st.text_input("ç»“æŸæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="")
        date_end = st.text_input("ç»“æŸæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="", key="attn_end_date")
        gen_btn = st.button("ç”Ÿæˆå¹¶é¢„è§ˆ", use_container_width=True)

    if gen_btn:
        try:
            # 1) è®¡ç®— start/endï¼ˆæŒ‰äº¤æ˜“æ—¥ï¼‰
            root = asset_root(PARQUET_BASE, "stock", PARQUET_ADJ)
            days = _cached_trade_dates(PARQUET_BASE, PARQUET_ADJ)
            end = (date_end or (days[-1] if days else None))
            if not end:
                st.error("æœªèƒ½ç¡®å®šç»“æŸæ—¥"); st.stop()
            if end in days:
                j = days.index(end)
                start = days[max(0, j - int(win_n))]
            else:
                start = days[-int(win_n)] if days else end

            # 2) å‚æ•°æ˜ å°„
            mode_map = {"å¼ºåº¦ï¼ˆå¸¦æƒï¼‰": "strength", "æ¬¡æ•°ï¼ˆä¸å¸¦æƒï¼‰": "hits"}
            w_map    = {"ä¸åŠ æƒ": "none", "æŒ‡æ•°åŠè¡°": "exp", "çº¿æ€§æœ€å°å€¼": "linear"}

            # 3) æ­£ç¡®è°ƒç”¨ scoring_core æ¥å£
            csv_path = se.build_attention_rank(
                start=start, end=end, source=src,
                min_hits=None, topN=int(out_n), write=True,
                mode=mode_map[method], weight_mode=w_map[weight],
                topM=int(top_m)
            )
            st.success(f"å¼ºåº¦æ¦œå·²ç”Ÿæˆï¼š{csv_path}")
            df_a = pd.read_csv(csv_path)
            st.dataframe(df_a, use_container_width=True, height=480)
            try:
                if df_a is not None and not df_a.empty:
                    # è¯†åˆ«ä»£ç åˆ—ï¼ˆä¼˜å…ˆ ts_codeï¼‰
                    code_col = None
                    for cand in ["ts_code", "code", "ts", "symbol"]:
                        if cand in df_a.columns:
                            code_col = cand
                            break

                    if code_col:
                        codes = df_a[code_col].astype(str).tolist()
                        txt = _codes_to_txt(
                            codes,
                            st.session_state["export_pref"]["style"],
                            st.session_state["export_pref"]["with_suffix"]
                        )
                        # å¤åˆ¶æŒ‰é’®ï¼ˆä½¿ç”¨å·²æœ‰çš„ copy_txt_buttonï¼‰
                        copy_txt_button(
                            txt,
                            label="ğŸ“‹ å¤åˆ¶å¼ºåº¦æ¦œï¼ˆæŒ‰å½“å‰è¾“å‡ºï¼‰",
                            key=f"copy_attn_{end}_{src}"
                        )
                        # TXT å¯¼å‡ºï¼ˆæ–‡ä»¶åå«å‚æ•°ï¼Œä¾¿äºè¿½æº¯ï¼‰
                        _download_txt(
                            "å¯¼å‡ºå¼ºåº¦æ¦œ TXT",
                            txt,
                            f"attention_{src}_{mode_map[method]}_{w_map[weight]}_{start}_{end}.txt",
                            key="dl_attention_txt"
                        )
                    else:
                        st.caption("æœªæ‰¾åˆ°ä»£ç åˆ—ï¼ˆæœŸæœ›åˆ—åï¼šts_codeï¼‰ã€‚")
            except Exception as e:
                st.warning(f"å¯¼å‡º/å¤åˆ¶å¤±è´¥ï¼š{e}")
                
            # â€”â€” ä»¥ä¸‹ä¸ºâ€œå¼ºåº¦æ¦œè½ç›˜ï¼ˆCSV/TXTï¼Œå«æ¸…æ™°æ–‡ä»¶åï¼‰â€ 
            save_extra = cfg_bool("SC_ATTENTION_SAVE_EXTRA", False)
            if save_extra:
                try:
                    fname_base = f"attention_{src}_{mode_map[method]}_{w_map[weight]}_win{int(win_n)}_topM{int(top_m)}_{start}_{end}_topN{int(out_n)}"
                    dest_csv = ATTN_DIR / f"{fname_base}.csv"
                    dest_txt = ATTN_DIR / f"{fname_base}.txt"

                    # 1) å¤åˆ¶ CSVï¼ˆè‹¥åå­—ä¸åŒï¼‰
                    try:
                        if str(csv_path) != str(dest_csv):
                            shutil.copyfile(csv_path, dest_csv)
                    except Exception as _e:
                        st.warning(f"CSV è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“é¡µé¢é¢„è§ˆï¼‰ï¼š{_e}")

                    # 2) å†™ TXTï¼ˆåªæœ‰å‰é¢ç”Ÿæˆè¿‡ txt æ‰å†™ï¼‰
                    if 'txt' in locals():
                        try:
                            dest_txt.write_text(txt, encoding="utf-8-sig")
                        except Exception as _e:
                            st.warning(f"TXT è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“é¡µé¢é¢„è§ˆï¼‰ï¼š{_e}")

                    st.caption(f"å·²è½ç›˜ï¼š{dest_csv.name} / {dest_txt.name}ï¼ˆç›®å½•ï¼š{ATTN_DIR}ï¼‰")
                except Exception as _e:
                    st.warning(f"å¼ºåº¦æ¦œè½ç›˜å‡ºç°å¼‚å¸¸ï¼š{_e}")

        except Exception as e:
            st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
            
    st.subheader("æœ¬åœ°è¯»å–")

    c1, c2 = st.columns([1,1])
    with c1:
        ref_inp_attn = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°ï¼‰", value="", key="attn_ref_input")
    with c2:
        sort_key = st.selectbox("æ’åºä¾æ®", ["score â†“", "rank â†‘", "ä¿æŒåŸæ–‡ä»¶é¡ºåº"], index=0, key="attn_sort_key")
    topn_attn = st.number_input("Top-K æ˜¾ç¤ºè¡Œæ•°", min_value=5, max_value=1000, value=cfg_int("SC_ATTENTION_TOP_K", 50), key="attn_topn")
    # å†³å®šå‚è€ƒæ—¥ä¸æ–‡ä»¶è·¯å¾„
    ref_attn = (ref_inp_attn.strip() or _pick_latest_attn_date())
    if not ref_attn:
        st.info("æœªåœ¨ attention ç›®å½•å‘ç°ä»»ä½• CSVï¼Œè¯·å…ˆäº§å‡ºå¼ºåº¦æ¦œæˆ–æ£€æŸ¥è¾“å‡ºè·¯å¾„ã€‚")

    attn_path = _find_attn_file_by_date(ref_attn)
    st.caption(f"å‚è€ƒæ—¥ï¼š{ref_attn}")
    if not attn_path or (not attn_path.exists()):
        st.warning("æœªæ‰¾åˆ°è¯¥æ—¥çš„å¼ºåº¦æ¦œæ–‡ä»¶ï¼ˆè¯·ç¡®è®¤ attention ç›®å½•ä¸å‘½åï¼‰ã€‚")

    # è¯»å–å¼ºåº¦æ¦œ
    df_attn = _read_df(attn_path)
    if df_attn is None or df_attn.empty:
        st.warning("å¼ºåº¦æ¦œæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")

    # ç»Ÿä¸€/å®¹é”™æ’åºï¼šé»˜è®¤ä¼˜å…ˆæŒ‰ score é™åºï¼›æ²¡æœ‰ score åˆ™æŒ‰ rank å‡åºï¼›å¦åˆ™ä¿æŒåŸé¡ºåº
    def _auto_sort(df: pd.DataFrame) -> pd.DataFrame:
        if "score" in df.columns:
            return df.sort_values(["score", "ts_code"], ascending=[False, True])
        if "rank" in df.columns:
            return df.sort_values(["rank", "ts_code"], ascending=[True, True])
        return df

    if sort_key == "score â†“" and "score" in df_attn.columns:
        df_attn = df_attn.sort_values(["score", "ts_code"], ascending=[False, True])
    elif sort_key == "rank â†‘" and "rank" in df_attn.columns:
        df_attn = df_attn.sort_values(["rank", "ts_code"], ascending=[True, True])
    # â€œä¿æŒåŸæ–‡ä»¶é¡ºåºâ€ å°±ä¸åŠ¨

    # é¢„è§ˆ + å¯¼å‡º/å¤åˆ¶ï¼Œè¡Œä¸ºä¸â€œæ’åâ€é¡µå°½é‡ä¸€è‡´
    st.divider()
    with st.container(border=True):
        rows_eff = int(topn_attn)
        st.markdown("**å¼ºåº¦æ¦œ Top-N é¢„è§ˆ**")
        st.dataframe(df_attn.head(rows_eff), use_container_width=True, height=420)

        # TXT å¤åˆ¶ï¼ˆæŒ‰ä½ çš„å¯¼å‡ºåå¥½ï¼‰
        if "ts_code" in df_attn.columns:
            codes = df_attn["ts_code"].astype(str).head(rows_eff).tolist()
            txt = _codes_to_txt(
                codes,
                st.session_state["export_pref"]["style"],
                st.session_state["export_pref"]["with_suffix"]
            )
            copy_txt_button(txt, label="å¤åˆ¶ä»¥ä¸Š", key=f"copy_attn_{ref_attn}")

        # # CSV ä¸‹è½½ï¼ˆTop-Nï¼‰
        # st.download_button(
        #     "â¬‡ï¸ å¯¼å‡º Top-Nï¼ˆCSVï¼‰",
        #     data=df_attn.head(rows_eff).to_csv(index=False).encode("utf-8-sig"),
        #     file_name=f"attention_top{rows_eff}_{ref_attn}.csv",
        #     use_container_width=True,
        #     key=f"dl_attn_{ref_attn}"
        # )

# ================= æ•°æ®ä¸‹è½½ ==================
with tab_data:
    st.subheader("æ•°æ®ä¸‹è½½ / æµè§ˆæ£€æŸ¥")
    # â€”â€” å‚æ•°åŒº â€”â€”
    with st.expander("å‚æ•°è®¾ç½®", expanded=True):
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            base = st.text_input("æ•°æ®æ ¹ç›®å½• DATA_ROOT", value=str(getattr(cfg, "DATA_ROOT", getattr(cfg, "PARQUET_BASE", "./data"))))
            assets = st.multiselect("èµ„äº§ ASSETS", ["stock","index"], default=list(getattr(dl, "ASSETS", ["stock","index"])) or ["stock","index"])            
        with c2:
            start_in = st.text_input("èµ·å§‹æ—¥ START_DATE (YYYYMMDD)", value=str(getattr(dl, "START_DATE", "20200101")))
            end_default = str(getattr(dl, "END_DATE", "today"))
            end_in = st.text_input("ç»“æŸæ—¥ END_DATE ('today' æˆ– YYYYMMDD)", value=end_default)
        with c3:
            api_adj = st.selectbox("å¤æƒ API_ADJ", ["qfq","hfq","raw"], index={"qfq":0,"hfq":1,"raw":2}.get(str(getattr(dl,"API_ADJ","qfq")).lower(),0))
            latest = _latest_trade_date(base, api_adj)
            do_plain = st.checkbox("å†™å…¥å•è‚¡(ä¸å¸¦æŒ‡æ ‡)", value=bool(getattr(dl, "WRITE_SYMBOL_PLAIN", True)))
            do_ind   = st.checkbox("å†™å…¥å•è‚¡(å«æŒ‡æ ‡)", value=bool(getattr(dl, "WRITE_SYMBOL_INDICATORS", True)))
            auto_rank = st.checkbox("å®Œæˆåè‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰", value=True)  # NEW
        with c4:
            fast_threads = st.number_input("FAST_INIT å¹¶å‘", min_value=1, max_value=64, value=int(getattr(dl,"FAST_INIT_THREADS",16)))
            inc_threads  = st.number_input("å¢é‡ä¸‹è½½çº¿ç¨‹", min_value=1, max_value=64, value=int(getattr(dl,"STOCK_INC_THREADS",16)))
            ind_workers  = st.number_input("æŒ‡æ ‡é‡ç®—çº¿ç¨‹(å¯é€‰)", min_value=0, max_value=128, value=int(getattr(dl,"INC_RECALC_WORKERS", 32)))
        if latest:
            st.caption(f"å½“å‰ {api_adj} æœ€è¿‘äº¤æ˜“æ—¥ï¼š{latest}")

    # å°†å‚æ•°è½åˆ°æ¨¡å—
    end_use = _today_str() if str(end_in).strip().lower() == "today" else str(end_in).strip()
    start_use = str(start_in).strip()
    _apply_overrides(base, assets, start_use, end_use, api_adj, int(fast_threads), int(inc_threads), int(ind_workers) if ind_workers else None)
    dl.WRITE_SYMBOL_PLAIN = bool(do_plain)
    dl.WRITE_SYMBOL_INDICATORS = bool(do_ind)

    # â€”â€” æŒ‰é’®åŒº â€”â€”
    tab_dl, tab_view = st.tabs(["ä¸‹è½½/åŒæ­¥", "æµè§ˆ/æ£€æŸ¥(app_pv)"])

    # === ä¸‹è½½/åŒæ­¥ ===
    with tab_dl:
        mode = st.radio("è¿è¡Œæ¨¡å¼", ["é¦–æ¬¡å»ºåº“(FAST_INIT)", "æ—¥å¸¸å¢é‡(NORMAL)"], index=0 if not _latest_trade_date(base, api_adj) else 1, horizontal=True)
        st.markdown(
            """
            - **FAST_INIT**ï¼šæŒ‰è‚¡ç¥¨å¹¶å‘å…¨å†å²æŠ“å– â†’ åˆå¹¶åˆ° `stock/daily/*` â†’ï¼ˆå¯é€‰ï¼‰åˆå¹¶æŒ‡æ ‡ç›®å½• â†’ï¼ˆå¯é€‰ï¼‰æŒ‡æ•°ã€‚
            - **NORMAL**ï¼šå…ˆåˆå¹¶ fast_init ç¼“å­˜ â†’ è‚¡ç¥¨å¢é‡ â†’ æŒ‡æ•°å¢é‡ â†’ æŒ‡æ ‡å¢é‡é‡ç®—ä¸åˆå¹¶ã€‚
            """
        )

        # ä¸€é”®
        c1, c2 = st.columns(2)
        with c1:
            run_all = st.button("ğŸš€ ä¸€é”®è¿è¡Œ", use_container_width=True, type="primary")
        with c2:
            dry = st.checkbox("ä»…æ‰“å°æ—¥å¿—ï¼ˆä¸æ‰§è¡Œï¼‰", value=False, help="ä»…ç”¨äºé¢„è§ˆå‚æ•°")

        # å•æ­¥æŒ‰é’®
        st.markdown("â€”â€” æˆ–æŒ‰æ­¥éª¤æ‰§è¡Œ â€”â€”")
        s1, s2, s3, s4, s5 = st.columns(5)
        with s1: b_fast = st.button("â‘  é¦–æ¬¡å»ºåº“")
        with s2: b_merge = st.button("â‘¡ Fastâ†’Daily åˆå¹¶")
        with s3: b_stock = st.button("â‘¢ è‚¡ç¥¨å¢é‡")
        with s4: b_index = st.button("â‘£ æŒ‡æ•°å¢é‡")
        with s5: b_indic = st.button("â‘¤ æŒ‡æ ‡åˆå¹¶/é‡ç®—")

        # æ‰§è¡Œé€»è¾‘ï¼ˆç»Ÿä¸€ç”¨ Stepper å±•ç¤ºé˜¶æ®µè¿›åº¦ï¼‰
        if run_all or b_fast or b_merge or b_stock or b_index or b_indic:
            if dry:
                st.info(f"[DRY-RUN] base={base} assets={assets} adj={api_adj} range={start_use}~{end_use} fast_threads={fast_threads} inc_threads={inc_threads}")
            else:
                try:
                    # â€”â€” ä¸€é”®è¿è¡Œ â€”â€” 
                    if run_all:
                        if mode.startswith("é¦–æ¬¡"):
                            steps = [
                                "å‡†å¤‡ç¯å¢ƒ",
                                "FAST_INIT å…¨é‡/åˆå¹¶",
                                "æŒ‡æ•°å…¨é‡/è¡¥é½" if "index" in set(assets) else None,
                                "è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰" if auto_rank else None,
                                "æ¸…ç†ä¸æ ¡éªŒ",
                            ]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· ä¸€é”®è¿è¡Œï¼ˆFAST_INITï¼‰", steps, key_prefix="dl_all")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("FAST_INIT å…¨é‡/åˆå¹¶")
                            _run_fast_init(end_use)
                            sp.step("æŒ‡æ•°å…¨é‡/è¡¥é½", visible=("index" in set(assets)))
                            if "index" in set(assets):
                                dl.sync_index_daily_fast(start_use, end_use, dl.INDEX_WHITELIST)
                            sp.step("è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰", visible=auto_rank)
                            if auto_rank:
                                try:
                                    top_path = se.run_for_date(None)
                                    st.success(f"âœ… å·²è‡ªåŠ¨å®Œæˆæ’åï¼š{top_path}")
                                except Exception as ee:
                                    st.warning(f"è‡ªåŠ¨æ’åå¤±è´¥ï¼š{ee}")
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "æ‰€æœ‰æ­¥éª¤å®Œæˆ")
                        else:
                            steps = [
                                "å‡†å¤‡ç¯å¢ƒ",
                                "åˆå¹¶ FastInit ç¼“å­˜ & å¢é‡åŒæ­¥ï¼ˆè‚¡/æŒ‡/æŒ‡æ ‡ï¼‰",
                                "è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰" if auto_rank else None,
                                "æ¸…ç†ä¸æ ¡éªŒ",
                            ]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· ä¸€é”®è¿è¡Œï¼ˆNORMALï¼‰", steps, key_prefix="dl_all")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("åˆå¹¶ FastInit ç¼“å­˜ & å¢é‡åŒæ­¥ï¼ˆè‚¡/æŒ‡/æŒ‡æ ‡ï¼‰")
                            _run_increment(start_use, end_use, do_stock=True, do_index=True, do_indicators=True)
                            sp.step("è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰", visible=auto_rank)
                            if auto_rank:
                                try:
                                    top_path = se.run_for_date(None)
                                    st.success(f"âœ… å·²è‡ªåŠ¨å®Œæˆæ’åï¼š{top_path}")
                                except Exception as ee:
                                    st.warning(f"è‡ªåŠ¨æ’åå¤±è´¥ï¼š{ee}")
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "æ‰€æœ‰æ­¥éª¤å®Œæˆ")
                    # â€”â€” å•æ­¥è¿è¡Œ â€”â€” 
                    else:
                        if b_fast:
                            steps = ["å‡†å¤‡ç¯å¢ƒ", "é¦–æ¬¡å»ºåº“ï¼ˆFAST_INITï¼‰", "æ¸…ç†ä¸æ ¡éªŒ"]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· é¦–æ¬¡å»ºåº“", steps, key_prefix="dl_fast")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("é¦–æ¬¡å»ºåº“ï¼ˆFAST_INITï¼‰")
                            _run_fast_init(end_use)
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "è¯¥æ­¥éª¤å®Œæˆ")
                        if b_merge:
                            steps = ["å‡†å¤‡ç¯å¢ƒ", "åˆå¹¶ Fastâ†’Daily", "æ¸…ç†ä¸æ ¡éªŒ"]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· åˆå¹¶", steps, key_prefix="dl_merge")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("åˆå¹¶ Fastâ†’Daily")
                            dl.duckdb_partition_merge()
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "è¯¥æ­¥éª¤å®Œæˆ")
                        if b_stock:
                            steps = ["å‡†å¤‡ç¯å¢ƒ", "è‚¡ç¥¨å¢é‡", "æ¸…ç†ä¸æ ¡éªŒ"]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· è‚¡ç¥¨å¢é‡", steps, key_prefix="dl_stock")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("è‚¡ç¥¨å¢é‡")
                            dl.sync_stock_daily_fast(start_use, end_use, threads=dl.STOCK_INC_THREADS)
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "è¯¥æ­¥éª¤å®Œæˆ")
                        if b_index:
                            steps = ["å‡†å¤‡ç¯å¢ƒ", "æŒ‡æ•°å¢é‡", "æ¸…ç†ä¸æ ¡éªŒ"]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· æŒ‡æ•°å¢é‡", steps, key_prefix="dl_index")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("æŒ‡æ•°å¢é‡")
                            dl.sync_index_daily_fast(start_use, end_use, dl.INDEX_WHITELIST)
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "è¯¥æ­¥éª¤å®Œæˆ")
                        if b_indic:
                            steps = ["å‡†å¤‡ç¯å¢ƒ", "æŒ‡æ ‡é‡ç®—å¹¶åˆå¹¶", "è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰" if auto_rank else None, "æ¸…ç†ä¸æ ¡éªŒ"]
                            sp = Stepper("ä¸‹è½½/åŒæ­¥ Â· æŒ‡æ ‡åˆå¹¶/é‡ç®—", steps, key_prefix="dl_indic")
                            sp.start()
                            sp.step("å‡†å¤‡ç¯å¢ƒ")
                            sp.step("æŒ‡æ ‡é‡ç®—å¹¶åˆå¹¶")
                            workers = getattr(dl, "INC_RECALC_WORKERS", None) or ((os.cpu_count() or 4) * 2)
                            dl.recalc_symbol_products_for_increment(start_use, end_use, threads=workers)
                            sp.step("è‡ªåŠ¨æ’åï¼ˆTop/All/Detailsï¼‰", visible=auto_rank)
                            if auto_rank:
                                try:
                                    top_path = se.run_for_date(None)
                                    st.success(f"âœ… å·²è‡ªåŠ¨å®Œæˆæ’åï¼š{top_path}")
                                except Exception as ee:
                                    st.warning(f"è‡ªåŠ¨æ’åå¤±è´¥ï¼š{ee}")
                            sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                            sp.finish(True, "è¯¥æ­¥éª¤å®Œæˆ")
                except Exception as e:
                    st.error(f"è¿è¡Œå¤±è´¥ï¼š{e}")

    # === æµè§ˆ/æ£€æŸ¥ï¼ˆé›†æˆ app_pv çš„æ ¸å¿ƒåŠŸèƒ½ï¼‰ ===
    with tab_view:
        st.markdown("#### æ¦‚è§ˆ & è¯Šæ–­ (æ¥è‡ª app_pv)")
        c1, c2 = st.columns([2, 1])
        with c1:
            try:
                df = apv.overview_table(base, api_adj)
                st.dataframe(df, use_container_width=True, height=360)
            except Exception as e:
                st.error(f"æ¦‚è§ˆå¤±è´¥ï¼š{e}")
        with c2:
            try:
                info = apv.get_info(base, api_adj)
                st.text_area("æ¦‚è§ˆï¼ˆæ–‡æœ¬ï¼‰", value=str(info), height=180)
                adv = apv.overview_advice(base, api_adj)
                st.markdown(adv)
            except Exception as e:
                st.error(f"è¯Šæ–­å¤±è´¥ï¼š{e}")

        st.markdown("---")
        st.caption("æ•°æ®æµè§ˆç”± parquet_viewer æ”¯æŒï¼Œå¯åœ¨å…¶ä»–é¡µæˆ–å‘½ä»¤è¡Œä½¿ç”¨æ›´ä¸°å¯Œçš„åŠŸèƒ½ã€‚")

# ================== æ™®é€šé€‰è‚¡ï¼ˆTDXè¡¨è¾¾å¼ï¼‰ ==================
with tab_screen:
    st.subheader("æ™®é€šé€‰è‚¡ï¼ˆç±»TDX è¡¨è¾¾å¼ï¼‰")
    # exp = st.text_input("è¡¨è¾¾å¼ï¼ˆç¤ºä¾‹ï¼šCLOSE>MA(CLOSE,20) AND VOL>MA(VOL,5)ï¼‰", value="")
    exp = st.text_input("è¡¨è¾¾å¼ï¼ˆç¤ºä¾‹ï¼šCLOSE>MA(CLOSE,20) AND VOL>MA(VOL,5)ï¼‰", value="", key="screen_expr")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        level = st.selectbox("æ—¶é—´çº§åˆ«", ["D","W","M"], index=0)
    with c2:
        window = st.number_input("çª—å£é•¿åº¦", min_value=1, max_value=500, value=60)
    with c3:
        scope_logic = st.selectbox("å‘½ä¸­èŒƒå›´(scope)", ["LAST","ANY","ALL","COUNT>=k","CONSEC>=m"], index=0)
    with c4:
        refD = st.text_input("å‚è€ƒæ—¥ï¼ˆå¯é€‰ï¼ŒYYYYMMDDï¼‰", value="")
    uni_choice = st.selectbox("é€‰è‚¡èŒƒå›´", ["å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•"], index=0)
    _uni_map = {"å…¨å¸‚åœº":"all", "ä»…ç™½åå•":"white", "ä»…é»‘åå•":"black", "ä»…ç‰¹åˆ«å…³æ³¨æ¦œ":"attention"}
    run_screen = st.button("è¿è¡Œç­›é€‰å¹¶é¢„è§ˆ", use_container_width=True)

    if run_screen:
        try:
            if hasattr(se, "tdx_screen"):
                df_sel = se.tdx_screen(
                    exp,
                    ref_date=refD.strip() or None,
                    timeframe=level,
                    window=int(window),
                    scope=scope_logic,
                    universe=_uni_map.get(uni_choice, "all"),
                    write_white=False,
                    write_black_rest=False,
                    return_df=True
                )
                st.dataframe(df_sel, use_container_width=True, height=480)
                st.caption(f"å…± {len(df_sel)} åªè‚¡ç¥¨")
                if not df_sel.empty and "ts_code" in df_sel.columns:
                    txt = _codes_to_txt(df_sel["ts_code"].astype(str).tolist(),
                                        st.session_state["export_pref"]["style"],
                                        st.session_state["export_pref"]["with_suffix"])
                    _download_txt("å¯¼å‡ºå‘½ä¸­ä»£ç  TXT", txt, "select.txt", key="dl_select")
            else:
                st.warning("æœªæ£€æµ‹åˆ° tdx_screenï¼Œå®ç°åæ­¤é¡µè‡ªåŠ¨å¯ç”¨ã€‚")
        except Exception as e:
            st.error(f"ç­›é€‰å¤±è´¥ï¼š{e}")

# ================== å·¥å…·ç®± ==================
with tab_tools:
    st.subheader("å·¥å…·ç®±")
    colA, colB = st.columns(2)

    with colA:
        st.markdown("**è‡ªåŠ¨è¡¥ç®—æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥**")
        n_back = st.number_input("å¤©æ•° N", min_value=1, max_value=100, value=20)
        inc_today = st.checkbox("åŒ…å«å‚è€ƒæ—¥å½“å¤©", value=True,
                                 help="å‹¾é€‰åçª—å£åŒ…å«å‚è€ƒæ—¥ï¼ˆä¾‹å¦‚ N=5 â†’ [ref-(N-1), ref]ï¼›æœªå‹¾é€‰åˆ™ [ref-N, ref-1]ï¼‰")
        do_force = st.checkbox("å¼ºåˆ¶é‡å»ºï¼ˆè¦†ç›–å·²æœ‰ï¼‰", value=False,
                               help="è‹¥ä¹‹å‰å¤±è´¥ç•™ä¸‹äº† 0 å­—èŠ‚æ–‡ä»¶æˆ–æƒ³é‡ç®—ï¼Œå‹¾é€‰æ­¤é¡¹ã€‚")

        go_fill = st.button("æ‰§è¡Œè‡ªåŠ¨è¡¥ç®—", use_container_width=True)
        if go_fill:
            try:
                if hasattr(se, "backfill_prev_n_days"):
                    out = se.backfill_prev_n_days(n=int(n_back), include_today=bool(inc_today), force=bool(do_force))
                    st.success(f"å·²å¤„ç†ï¼š{out}")
                else:
                    st.warning("æœªæ£€æµ‹åˆ° backfill_prev_n_daysã€‚")
            except Exception as e:
                st.error(f"è¡¥ç®—å¤±è´¥ï¼š{e}")

    with colB:
        st.markdown("**è¡¥é½ç¼ºå¤±çš„ All æ’åæ–‡ä»¶**")
        # start = st.text_input("èµ·å§‹æ—¥ YYYYMMDD", value="")
        start = st.text_input("èµ·å§‹æ—¥ YYYYMMDD", value="", key="tools_fix_start")
        end = st.text_input("ç»“æŸæ—¥ YYYYMMDD", value="", key="tools_fix_end")
        do_force_fix = st.checkbox("å¼ºåˆ¶é‡å»ºï¼ˆè¦†ç›–å·²æœ‰ï¼‰", value=False)
        go_fix = st.button("è¡¥é½ç¼ºå¤±", use_container_width=True)
        if go_fix and start and end:
            try:
                if hasattr(se, "backfill_missing_ranks"):                   
                    out = se.backfill_missing_ranks(start, end, force=bool(do_force_fix))
                    st.success(f"å·²è¡¥é½ï¼š{out}")
                else:
                    st.warning("æœªæ£€æµ‹åˆ° backfill_missing_ranksã€‚")
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥ï¼š{e}")
    st.markdown("---")
    with st.expander("æŸ¥çœ‹å·²æœ‰æ•°æ®ï¼ˆTop / All / Details / æ—¥å†ï¼‰", expanded=True):
        if "scan_inventory_loaded" not in st.session_state:
            st.session_state["scan_inventory_loaded"] = False
        col0, col1 = st.columns([1,3])
        with col0:
            do_scan = st.button("åŠ è½½/åˆ·æ–°åˆ—è¡¨", key="btn_scan_inventory", use_container_width=True)
            if do_scan:
                st.session_state["scan_inventory_loaded"] = True
        if not st.session_state["scan_inventory_loaded"]:
            st.info("ï¼ˆé¦–æ¬¡è¿›å…¥ä¸æ‰«æç£ç›˜ï¼Œç‚¹å‡»ä¸Šæ–¹ **åŠ è½½/åˆ·æ–°åˆ—è¡¨** æ‰è¯»å–æ–‡ä»¶æ¸…å•ã€‚ï¼‰")
        if st.session_state["scan_inventory_loaded"]:
            try:
                all_files = sorted(ALL_DIR.glob("score_all_*.csv"))
                top_files = sorted(TOP_DIR.glob("score_top_*.csv"))
                det_dirs  = sorted([p for p in DET_DIR.glob("*") if p.is_dir()])

                all_dates = [p.stem.replace("score_all_", "") for p in all_files]
                top_dates = [p.stem.replace("score_top_", "") for p in top_files]
                det_dates = [p.name for p in det_dirs]

                zero_all = [p.name for p in all_files if p.stat().st_size == 0]
                zero_top = [p.name for p in top_files if p.stat().st_size == 0]

                cov_min = min(all_dates) if all_dates else ""
                cov_max = max(all_dates) if all_dates else ""

                # äº¤æ˜“æ—¥æ—¥å†ï¼ˆè‹¥å­˜åœ¨åˆ™ç”¨äºå¯¹æ¯”ç¼ºå¤±ï¼‰
                missing: list[str] = []
                try:
                    cal_root = asset_root(PARQUET_BASE, "stock", PARQUET_ADJ)
                    trade_dates = list_trade_dates(cal_root) or []
                    if trade_dates and cov_min and cov_max:
                        rng = [d for d in trade_dates if cov_min <= d <= cov_max]
                        aset = set(all_dates)
                        missing = [d for d in rng if d not in aset]
                except Exception:
                    trade_dates = []

                col1, col2, col3, col4 = st.columns(4)
                with col1: st.metric("All æ–‡ä»¶æ•°", len(all_files))
                with col2: st.metric("Top æ–‡ä»¶æ•°", len(top_files))
                with col3: st.metric("Details æ—¥æœŸç›®å½•", len(det_dirs))
                with col4: st.metric("0 å­—èŠ‚æ–‡ä»¶", len(zero_all) + len(zero_top))

                if cov_min:
                    st.caption(f"All è¦†ç›–åŒºé—´ï¼š{cov_min} ~ {cov_max}ï¼ˆç¼ºå¤± {len(missing)} å¤©ï¼‰")
                else:
                    st.caption("All ç›®å½•ä¸ºç©ºã€‚")

                if zero_all or zero_top:
                    names = zero_all[:8] + zero_top[:8]
                    st.warning("æ£€æµ‹åˆ° 0 å­—èŠ‚æ–‡ä»¶ï¼ˆå¯ç”¨â€œå¼ºåˆ¶é‡å»ºâ€è¦†ç›–ï¼‰ï¼š\n" + "ï¼Œ".join(names) + (" â€¦â€¦" if len(zero_all)+len(zero_top) > len(names) else ""))
                colL, colR = st.columns([1, 2])
                with colL:
                    kind = st.radio("æ•°æ®ç±»å‹", ["All æ’å", "Top æ’å", "Details"], horizontal=True, key="view_kind")
                    if kind == "All æ’å":
                        cand = all_dates
                    elif kind == "Top æ’å":
                        cand = top_dates
                    else:
                        cand = det_dates
                    sel_date = st.selectbox("é€‰æ‹©æ—¥æœŸï¼ˆå€’åºï¼‰", cand[::-1] if cand else [], key="view_date") if cand else None
                    show_missing = st.checkbox("æ˜¾ç¤ºç¼ºå¤±æ—¥æœŸï¼ˆåŸºäºäº¤æ˜“æ—¥å†ï¼‰", value=False, disabled=not missing)
                with colR:
                    if sel_date:
                        if kind == "All æ’å":
                            p = _path_all(sel_date)
                            if p.exists() and p.stat().st_size > 0:
                                st.dataframe(_read_df(p).head(200), use_container_width=True, height=360)
                            else:
                                st.info("è¯¥æ—¥ All æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
                        elif kind == "Top æ’å":
                            p = _path_top(sel_date)
                            if p.exists() and p.stat().st_size > 0:
                                st.dataframe(_read_df(p).head(200), use_container_width=True, height=360)
                            else:
                                st.info("è¯¥æ—¥ Top æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
                        else:
                            pdir = DET_DIR / sel_date
                            if pdir.exists():
                                st.info(f"{sel_date} å…±æœ‰ {len(list(pdir.glob('*.json')))} ä¸ªè¯¦æƒ… JSONã€‚")
                            else:
                                st.info("è¯¥æ—¥æ²¡æœ‰ Details ç›®å½•ã€‚")

                if show_missing and missing:
                    st.markdown("**ç¼ºå¤±æ—¥æœŸï¼ˆç›¸å¯¹ All è¦†ç›–åŒºé—´ï¼‰**")
                    txt = " ".join(missing[:200]) + (" ..." if len(missing) > 200 else "")
                    st.code(txt)
            except Exception as e:
                st.error(f"æ‰«æå¤±è´¥ï¼š{e}")

# ================== ç»„åˆæ¨¡æ‹Ÿ / æŒä»“ ==================
with tab_port:
    st.subheader("ç»„åˆæ¨¡æ‹Ÿ / æŒä»“")
    from stats_core import PortfolioManager
    pm = PortfolioManager()

    # â€”â€” å…¨å±€é…ç½®ï¼ˆç”¨äºæ–°å»ºç»„åˆçš„é»˜è®¤å€¼ï¼‰ â€”â€”
    with st.expander("å…¨å±€é…ç½®ï¼ˆé»˜è®¤ç”¨äºæ–°å»ºç»„åˆï¼›æ¥è‡ª config.PF_*ï¼‰", expanded=True):
        colA, colB, colC, colD = st.columns(4)
        with colA:
            st.text_input("è´¦æœ¬åç§°", value=cfg_str("PF_LEDGER_NAME", "è´¦æœ¬1"), key="pf_ledger")
            st.number_input("åˆå§‹èµ„é‡‘ï¼ˆæ€»é¢ï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_INIT_CASH", 1_000_000.0)), key="pf_init_cash")
        with colB:
            st.number_input("åˆå§‹å¯ç”¨èµ„é‡‘", min_value=0.0, value=float(getattr(cfg, "PF_INIT_AVAILABLE", getattr(cfg, "PF_INIT_CASH", 1_000_000.0))), key="pf_init_avail")
            st.selectbox("æˆäº¤ä»·å£å¾„", ["next_open","close"], index=(0 if cfg_str("PF_TRADE_PRICE_MODE","next_open")=="next_open" else 1), key="pf_pxmode")
        with colC:
            st.number_input("ä¹°å…¥è´¹ç‡ï¼ˆbpï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_FEE_BPS_BUY", 15.0)), key="pf_fee_buy")
            st.number_input("å–å‡ºè´¹ç‡ï¼ˆbpï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_FEE_BPS_SELL", 15.0)), key="pf_fee_sell")
        with colD:
            st.number_input("æœ€ä½è´¹ç”¨ï¼ˆå…ƒï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_MIN_FEE", 0.0)), key="pf_min_fee")
        st.caption("ä»¥ä¸Šä¸ºé»˜è®¤å€¼ï¼›æ–°å»ºç»„åˆæ—¶ä¼šå¸¦å…¥ï¼ˆæ¯ä¸ªç»„åˆå¯è¦†ç›–ï¼‰ã€‚")

    # â€”â€” æ–°å»º/é€‰æ‹©ç»„åˆ â€”â€”
    col1, col2 = st.columns([1,2])
    with col1:
        st.markdown("**æ–°å»ºç»„åˆ**")
        new_name = st.text_input("åç§°", value=st.session_state.get("pf_ledger","default"))
        if st.button("åˆ›å»ºç»„åˆ", use_container_width=True):
            pid = pm.create_portfolio(
                name=new_name,
                init_cash=float(st.session_state["pf_init_cash"]),
                init_available=float(st.session_state["pf_init_avail"]),
                trade_price_mode=str(st.session_state["pf_pxmode"]),
                fee_bps_buy=float(st.session_state["pf_fee_buy"]),
                fee_bps_sell=float(st.session_state["pf_fee_sell"]),
                min_fee=float(st.session_state["pf_min_fee"]),
            )
            st.success(f"å·²åˆ›å»ºï¼š{new_name}ï¼ˆid={pid}ï¼‰")

    with col2:
        st.markdown("**å½“å‰ç»„åˆ**")
        ports = pm.list_portfolios()
        if not ports:
            st.info("æš‚æ— ç»„åˆï¼Œè¯·å…ˆåˆ›å»ºã€‚")
            st.stop()
        # ä»¥ name æ’åº
        ports_items = sorted(list(ports.items()), key=lambda kv: kv[1].name)
        names = [f"{p.name} ({pid[:6]})" for pid, p in ports_items]
        sel = st.selectbox("é€‰æ‹©ç»„åˆ", options=list(range(len(ports_items))), format_func=lambda i: names[i], index=0)
        cur_pid, cur_pf = ports_items[int(sel)][0], ports_items[int(sel)][1]

    st.divider()

    # â€”â€” å½•å…¥æˆäº¤ï¼ˆä»·æ ¼å‚è€ƒåŒºé—´ï¼‰ â€”â€”
    st.markdown("**å½•å…¥æˆäº¤ï¼ˆå¸¦å‚è€ƒä»·åŒºé—´ï¼‰**")
    colx, coly, colz, colw = st.columns([1.2, 1.2, 1.2, 2])
    with colx:
        side = st.selectbox("æ–¹å‘", ["BUY","SELL"], index=0)
    with coly:
        d_exec = st.text_input("æˆäº¤æ—¥ï¼ˆYYYYMMDDï¼‰", value=_pick_latest_ref_date() or "")
    with colz:
        ts = st.text_input("ä»£ç ", value="")
    # è¯»å–å½“æ—¥ O/H/L/C ä½œä¸ºå‚è€ƒ
    ref_low = ref_high = px_open = px_close = None
    try:
        ts_norm = normalize_ts(ts) if ts else ""
        if ts_norm and d_exec:
            df_one = read_range(PARQUET_BASE, "stock", PARQUET_ADJ, ts_norm, d_exec, d_exec, columns=["open","high","low","close"])
            if df_one is not None and not df_one.empty:
                row = df_one.iloc[-1]
                px_open = float(row.get("open", float("nan")))
                px_close = float(row.get("close", float("nan")))
                ref_low  = float(row.get("low", float("nan")))
                ref_high = float(row.get("high", float("nan")))
    except Exception:
        pass
    with colw:
        st.write({"open": px_open, "close": px_close, "low": ref_low, "high": ref_high})

    colq, colp = st.columns([1.2, 1.8])
    with colq:
        qty = st.number_input("æ•°é‡ï¼ˆè‚¡ï¼‰", min_value=0, value=0, step=100)
    with colp:
        price_mode = st.radio("æˆäº¤ä»·æ¥æº", ["æŒ‰å£å¾„è‡ªåŠ¨","è‡ªå®šä¹‰ä»·æ ¼"], index=0, horizontal=True)
        if price_mode == "è‡ªå®šä¹‰ä»·æ ¼":
            price = st.number_input("æˆäº¤ä»·ï¼ˆç•™ç©ºåˆ™ç”¨å£å¾„ä»·ï¼‰", min_value=0.0, value=float(px_close or px_open or 0.0), step=0.01)
        else:
            price = None

    if st.button("è®°å½•æˆäº¤", use_container_width=True, key="btn_rec_trade"):
        try:
            pm.record_trade(pid=cur_pid, date=str(d_exec), ts_code=str(ts_norm), side=str(side), qty=int(qty),
                            price_mode=(None if price is not None else cur_pf.trade_price_mode),
                            price=(None if price is None else float(price)), note="manual")
            st.success("å·²è®°å½•")
        except Exception as e:
            st.error(f"è®°å½•å¤±è´¥ï¼š{e}")

    st.divider()

    # â€”â€” è§‚å¯Ÿæ—¥ä¼°å€¼ / å‡€å€¼ â€”â€”
    st.markdown("**è§‚å¯Ÿæ—¥æ”¶ç›Šä¸æŒä»“ä¼°å€¼**")
    obs = st.text_input("è§‚å¯Ÿæ—¥ï¼ˆYYYYMMDDï¼›é»˜è®¤=æœ€æ–°äº¤æ˜“æ—¥ï¼‰", value=_pick_latest_ref_date() or "")
    if obs:
        # å›æ”¾ä¼°å€¼ï¼ˆä»ç»„åˆåˆ›å»ºæ—¥è‡³è§‚å¯Ÿæ—¥ï¼‰
        # æˆ‘ä»¬ç”¨ read_nav() è¯»å–ç»“æœ
        try:
            # æ‰§è¡Œä¼°å€¼
            pm.reprice_and_nav(cur_pid, date_start="19000101", date_end=str(obs), benchmarks=())
            nav_df = pm.read_nav(cur_pid)
            pos_df = pm.read_positions(cur_pid)
        except Exception as e:
            st.error(f"ä¼°å€¼å¤±è´¥ï¼š{e}")
            nav_df, pos_df = pd.DataFrame(), pd.DataFrame()
        if not nav_df.empty:
            row = nav_df.iloc[-1]
            if not pos_df.empty and "date" in pos_df.columns:
                cur_pos = pos_df[pos_df["date"] == str(obs)].copy()
                if not cur_pos.empty:
                    st.markdown("**å½“å‰æŒä»“**")
                    show_cols = [c for c in ["ts_code","qty","cost","mkt_price","mkt_value","unreal_pnl"] if c in cur_pos.columns]
                    cur_pos = cur_pos[show_cols].sort_values("mkt_value", ascending=False)
                    st.dataframe(cur_pos, use_container_width=True, height=300)
                else:
                    st.caption("è§‚å¯Ÿæ—¥æ— æŒä»“è®°å½•ã€‚")
            st.metric("ç»„åˆå¸‚å€¼", f"{(row.get('nav',1.0) * float(cur_pf.init_cash)):.0f}")
            st.metric("åŒºé—´æ”¶ç›Šç‡", f"{(row.get('nav',1.0) - 1.0):.2%}")
            cols = [c for c in ["date","cash","position_mv","nav","ret_d","max_dd"] if c in nav_df.columns]
            st.dataframe(nav_df[cols].tail(5), use_container_width=True)
            st.markdown("**å‡€å€¼æ›²çº¿ï¼ˆNAVï¼‰**")
            try:
                st.line_chart(nav_df.set_index("date")["nav"])
            except Exception:
                pass
        else:
            st.caption("æš‚æ— å‡€å€¼æ•°æ®ï¼ˆå¯èƒ½è¿˜æœªæœ‰æˆäº¤æˆ–è¡Œæƒ…æ•°æ®ç¼ºå¤±ï¼‰")

# ================== ç»Ÿè®¡ï¼ˆæ™®é€šé¡µç­¾ï¼‰ ==================
with tab_stats:
    st.subheader("ç»Ÿè®¡")
    sub_tabs = st.tabs(["è·Ÿè¸ªï¼ˆTrackingï¼‰", "å¼‚åŠ¨ï¼ˆSurgeï¼‰", "å…±æ€§ï¼ˆCommonalityï¼‰"])

    # --- Tracking ---
    with sub_tabs[0]:
        refT = st.text_input("å‚è€ƒæ—¥", value="", key="ref_1")
        # å‚è€ƒæ—¥/å›çœ‹çª—å£çš„æç¤ºï¼šå‘Šè¯‰ç”¨æˆ· t-n æ˜¯å“ªå¤©
        _back_choices = [1, 3, 5, 10, 20]
        _hint_text, _n2d = _from_last_hints(_back_choices)
        if _hint_text:
            st.caption("æŒ‰æœ€æ–°äº¤æ˜“æ—¥å›æ¨ï¼š " + _hint_text)

        wins = st.text_input("æœªæ¥æ”¶ç›Šçª—å£Nï¼ˆå¤©ï¼Œé€—å·åˆ†éš”ï¼‰", value="1,2,3,5,10,20")
        bench = st.text_input("å¯¹æ¯”æŒ‡æ•°åŸºå‡†ä»£ç ï¼ˆé€—å·ï¼Œå¯ç•™ç©ºï¼‰", value="")
        retrosT = st.text_input("é™„åŠ å›çœ‹å¤©æ•°", value="1,3,5")
        only_detail = st.checkbox("ä»…å¯¼å‡ºæ˜ç»†ï¼ˆä¸æ˜¾ç¤ºå‡å€¼/æ ‡å‡†å·®/èƒœç‡/åˆ†ä½æ•°æ±‡æ€»ï¼‰", value=True)
        gb_board = st.checkbox("åˆ†æ¿å—æ±‡æ€»", value=True)

        # === è·Ÿè¸ªå¢å¼ºï¼šå‰æ—¥æ’è¡Œ / åå• / æŒ‡æ ‡æ˜¯å¦è§¦å‘ / åç»­æ¶¨å¹… ===
        with st.expander("å¯é€‰ï¼šé€‰æ‹©è¦æ‰“å‹¾çš„æŒ‡æ ‡ï¼ˆæ¥è‡ªæ‰“åˆ†è§„åˆ™ï¼›ä»…ç”¨äºæ‰“å‹¾ï¼Œä¸å½±å“æ ·æœ¬ï¼‰", expanded=True):
            import scoring_core as se
            # è§„åˆ™ååˆ—è¡¨ï¼ˆå»é‡ï¼‰
            try:
                rule_names = [str(r.get("name") or f"RULE_{i}") for i, r in enumerate(getattr(se, "SC_RULES", []) or [])]
                rule_names = sorted(list(dict.fromkeys(rule_names)))
            except Exception:
                rule_names = []
            track_rule_names = st.multiselect("æŒ‡æ ‡ï¼ˆå¯å¤šé€‰ï¼‰", options=rule_names, default=[])
            track_max_json = st.number_input("æœ€å¤šè¯»å–æ˜ç»†JSONï¼ˆæŒ‰å½“æ—¥æ’åæ’åºï¼‰", min_value=50, max_value=5000, value=300, step=50, key="track_max_json")


        if st.button("ç”Ÿæˆè·Ÿè¸ªè¡¨ï¼ˆå«å‰æ—¥æ’è¡Œ/åå•/æŒ‡æ ‡å‹¾é€‰/åç»­æ¶¨å¹…ï¼‰", key="btn_run_tracking", use_container_width=True):
            try:
                from stats_core import run_tracking
                import scoring_core as se
                # 1) åŸºç¡€ tracking æ˜ç»†
                wlist = [int(x) for x in wins.split(",") if x.strip().isdigit()]
                blist = [s.strip() for s in bench.split(",") if s.strip()] or None
                rlist = [int(x) for x in retrosT.split(",") if x.strip().isdigit()]
                tr2 = run_tracking(
                    refT, wlist, benchmarks=blist, score_df=None,
                    group_by_board=gb_board, save=True,
                    retro_days=rlist, do_summary=(not only_detail)
                )
                detail = tr2.detail.copy()

                # 2) åˆå¹¶å‰æ—¥ rank
                prev = _prev_ref_date(refT)
                if prev:
                    df_prev = _read_df(_path_all(prev), usecols=["ts_code","rank"])
                    if df_prev is not None and len(df_prev) > 0:
                        df_prev = df_prev.rename(columns={"rank":"rank_tminus_1"})
                        detail = detail.merge(df_prev, on="ts_code", how="left")

                # 3) åˆå¹¶åå•ï¼ˆç™½/é»‘/ç‰¹åˆ«å…³æ³¨ï¼‰
                try:
                    whites = set(se._read_cache_list_codes(refT, "whitelist")) if hasattr(se, "_read_cache_list_codes") else set()
                    blacks = set(se._read_cache_list_codes(refT, "blacklist")) if hasattr(se, "_read_cache_list_codes") else set()
                    attns  = set(se._load_attention_codes(refT)) if hasattr(se, "_load_attention_codes") else set()
                    detail["in_whitelist"] = detail["ts_code"].astype(str).map(lambda c: c in whites)
                    detail["in_blacklist"] = detail["ts_code"].astype(str).map(lambda c: c in blacks)
                    detail["in_attention"] = detail["ts_code"].astype(str).map(lambda c: c in attns)
                except Exception:
                    for c in ("in_whitelist","in_blacklist","in_attention"):
                        detail[c] = False

                # 4) æŒ‡æ ‡æ˜¯å¦è§¦å‘ï¼ˆæ¥è‡ªæ’åè§„åˆ™ï¼‰
                try:
                    import scoring_core as se
                    sel_rules = track_rule_names if isinstance(track_rule_names, list) else []
                    hit_cols = [f"hit:{name}" for name in sel_rules]
                    for col in hit_cols:
                        detail[col] = False
                    if sel_rules:
                        pick_n = int(track_max_json) if "track_max_json" in locals() else 300
                        head_codes = detail.sort_values(["rank"]).head(pick_n)["ts_code"].astype(str).tolist()
                        def _read_hits_one(ts):
                            obj = _load_detail_json(str(refT), str(ts))
                            res = {}
                            if not obj:
                                return res
                            rules = obj.get("rules") or []
                            for rr in rules:
                                nm = str(rr.get("name") or "")
                                if nm in sel_rules:
                                    res[nm] = bool(rr.get("ok", False))
                            return res
                        for ts in head_codes:
                            hits_map = _read_hits_one(ts)
                            for nm in sel_rules:
                                col = f"hit:{nm}"
                                if nm in hits_map:
                                    detail.loc[detail["ts_code"].astype(str) == ts, col] = bool(hits_map[nm])
                except Exception:
                    pass

                # 5) å±•ç¤ºæ‰€éœ€åˆ—
                show_cols = [c for c in [
                    "ts_code","rank","rank_tminus_1",
                    "in_whitelist","in_blacklist","in_attention",
                    *[c for c in detail.columns if str(c).startswith("hit:")],
                    *[c for c in detail.columns if c.startswith("ret_fwd_")]
                ] if c in detail.columns]
                detail_fmt2 = _fmt_retcols_percent(detail)
                st.dataframe(detail_fmt2[show_cols].sort_values(["rank"]).reset_index(drop=True),
                             use_container_width=True, height=460)
                st.caption("ret_fwd_N = æœªæ¥ N æ—¥æ¶¨å¹…ï¼ˆTracking å·²è®¡ç®—ï¼‰ï¼›åå•åˆ—æ¥è‡ª cache/attentionï¼›hit:<è§„åˆ™å> ä¸ºæ‰€é€‰æ’åè§„åˆ™åœ¨å‚è€ƒæ—¥æ˜¯å¦è§¦å‘ã€‚")
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

    # --- Surge ---
    with sub_tabs[1]:
        refS = st.text_input("å‚è€ƒæ—¥", value=_pick_latest_ref_date() or "", key="surge_ref")
        mode = st.selectbox("æ¦œå•å£å¾„", ["today","rolling"], index=1, key="surge_mode")
        rolling_days = st.number_input("rollingæ¨¡å¼ç»Ÿè®¡å¤©æ•°", min_value=2, max_value=20, value=5, key="surge_rolling")
        sel_type = st.selectbox("é€‰æ ·", ["top_n","top_pct"], index=0, key="surge_sel_type")
        sel_val = st.number_input("é˜ˆå€¼ï¼ˆNæˆ–%ï¼‰", min_value=1, max_value=1000, value=200, key="surge_sel_val")
        retros = st.text_input("å›çœ‹å¤©æ•°é›†åˆï¼ˆé€—å·ï¼‰", value="1,2,3,4,5", key="surge_retros")
        split_label = st.selectbox("åˆ†ç»„å£å¾„", ["600/000/ç§‘åˆ›åŒ—(3ç»„)", "ä¸»vså…¶ä»–", "å„æ¿å—"], index=0, key="surge_split_label")
        split = {"600/000/ç§‘åˆ›åŒ—(3ç»„)":"combo3", "ä¸»vså…¶ä»–":"main_vs_others", "å„æ¿å—":"per_board"}[split_label]

        with st.expander("å¯é€‰ï¼šå¯¹å½“æ—¥æ ·æœ¬æŒ‰è§„åˆ™æ‰“å‹¾ï¼ˆæ¥è‡ªæ’åè§„åˆ™ï¼‰", expanded=False):
            import scoring_core as se
            try:
                rule_names = [str(r.get("name") or f"RULE_{i}") for i, r in enumerate(getattr(se, "SC_RULES", []) or [])]
                rule_names = sorted(list(dict.fromkeys(rule_names)))
            except Exception:
                rule_names = []
            surge_rule_names = st.multiselect("æŒ‡æ ‡ï¼ˆå¯å¤šé€‰ï¼‰", options=rule_names, default=[] if rule_names else [], key="surge_rule_names")
            surge_max_json = st.number_input("æœ€å¤šè¯»å–æ˜ç»†JSONï¼ˆä»…å¯¹æ ·æœ¬å†…è‚¡ç¥¨ï¼‰", min_value=50, max_value=5000, value=100, step=50, key="surge_max_json")

        if st.button("è¿è¡Œ Surge", key="btn_run_surge", use_container_width=True):
            with st.spinner("ç”Ÿæˆ Surge æ¦œå•ä¸­â€¦"):
                try:
                    from stats_core import run_surge
                    rlist = [int(x) for x in (retros or "").split(",") if x.strip().isdigit()]
                    sr = run_surge(
                        ref_date=str(refS).strip(),
                        mode=mode,
                        rolling_days=int(rolling_days),
                        selection={"type": sel_type, "value": int(sel_val)},
                        retro_days=rlist,
                        split=split,
                        score_df=None,
                        save=True,
                    )
                    table = sr.table.copy()

                    # å‘½ä¸­æ‰“å‹¾ï¼ˆå¯é€‰ï¼‰
                    if surge_rule_names:
                        codes2 = table["ts_code"].astype(str).unique().tolist()
                        if mode == "today":
                            obs_date = _prev_trade_date(str(refS), 1)  # t-1
                        else:
                            first_date = _pick_trade_dates(str(refS), int(rolling_days))[0]  # t-K
                            obs_date = _prev_trade_date(first_date, 1)                      # t-K-1
                        st.caption(f"å‘½ä¸­å£å¾„ï¼šä½¿ç”¨ã€{obs_date}ã€çš„ details ä½œä¸ºâ€œå¯åŠ¨å‰â€åˆ¤æ–­ã€‚")

                        # é¢„åˆ›å»ºåˆ—
                        for nm in surge_rule_names:
                            table[f"hit:{nm}"] = False

                        # è¯»å– JSONï¼ˆé™é¢ï¼‰
                        for ts in codes2[:int(surge_max_json)]:
                            obj = _load_detail_json(str(obs_date), str(ts)) or {}
                            rules = obj.get("rules") or []
                            hits_map = {
                                str(rr.get("name") or ""): (float(rr.get("add", 0.0)) > 0.0) or bool(rr.get("ok"))
                                for rr in rules
                            }
                            for nm in surge_rule_names:
                                col = f"hit:{nm}"
                                if nm in hits_map:
                                    table.loc[table["ts_code"].astype(str) == ts, col] = bool(hits_map[nm])

                except Exception as e:
                    st.error(f"Surge å¤±è´¥ï¼š{e}")
                else:
                    table_fmt = _fmt_retcols_percent(table)
                    st.dataframe(table_fmt, use_container_width=True, height=420)
                    st.caption("å„åˆ†ç»„æ–‡ä»¶å·²å†™å…¥ output/surge_lists/<ref>/ ã€‚")

    
    # --- Commonality ---
    with sub_tabs[2]:
        refC = st.text_input("å‚è€ƒæ—¥", value=_pick_latest_ref_date() or "", key="common_ref")
        retrosC = st.text_input("ç»Ÿè®¡å‰ n æ—¥é›†åˆï¼ˆè§‚å¯Ÿæ—¥å‰ç§» dï¼Œé€—å·ï¼‰", value="1,3,5")
        modeC = st.selectbox("æ¨¡å¼", ["rolling","today"], index=0, key="mode_2")
        rollingC = st.number_input("rolling å¤©æ•°", min_value=2, max_value=20, value=5, key="rolling_2")
        selC = st.number_input("æ ·æœ¬ Top-N", min_value=10, max_value=1000, value=200)
        splitC = st.selectbox("åˆ†ç»„å£å¾„", ["main_vs_others","per_board"], index=0, key="split_2")
        bg = st.selectbox("èƒŒæ™¯é›†", ["all","same_group"], index=0)
        countStrat = st.checkbox("ç»Ÿè®¡æ¯ä¸ªç­–ç•¥çš„è§¦å‘æ¬¡æ•°ï¼ˆç­–ç•¥åˆ†æï¼‰", value=True)
        scopeC = st.selectbox("è§¦å‘ç»Ÿè®¡èŒƒå›´", ["ä»…æ ·æœ¬(å¤§æ¶¨)","åŒç»„å…¨ä½“","ä¸¤è€…å¯¹æ¯”"], index=0, help="ä»…æ ·æœ¬ï¼šåªçœ‹å¤§æ¶¨ç¥¨ï¼›åŒç»„å…¨ä½“ï¼šæ ·æœ¬+åŒç»„éæ ·æœ¬ï¼›ä¸¤è€…å¯¹æ¯”ï¼šåŒæ—¶è¾“å‡ºä¸¤ä¸ªå£å¾„")
        w_en = st.checkbox("å¯¹å¤§æ¶¨æ ·æœ¬åŠ æƒï¼ˆç”¨äºâ€œåŒç»„å…¨ä½“/ä¸¤è€…å¯¹æ¯”â€å£å¾„ï¼‰", value=False)
        w_pos = st.slider("æ ·æœ¬æƒé‡", min_value=1.0, max_value=5.0, value=2.0, step=0.5, help="ä»…åœ¨â€œåŒç»„å…¨ä½“/ä¸¤è€…å¯¹æ¯”â€ä¸‹ç”Ÿæ•ˆ")

        if st.button("è¿è¡Œ Commonality", use_container_width=True):
            try:
                from stats_core import run_commonality
                rlist = [int(x) for x in retrosC.split(",") if x.strip().isdigit()]
                cr = run_commonality(
                    ref_date=refC,
                    retro_day=(rlist[0] if rlist else 1),
                    retro_days=rlist,
                    mode=modeC,
                    rolling_days=int(rollingC),
                    selection={"type":"top_n","value":int(selC)},
                    split=splitC,
                    background=bg,
                    save=True,
                    count_strategy=countStrat,
                    count_strategy_scope=("pos" if scopeC=="ä»…æ ·æœ¬(å¤§æ¶¨)" else ("group" if scopeC=="åŒç»„å…¨ä½“" else "both")),
                    strategy_pos_weight=(float(w_pos) if w_en else 1.0),
                )

                if countStrat:
                    import pandas as pd
                    trig = None
                    if isinstance(cr.reports, dict):
                        trig = cr.reports.get("strategy_triggers")
                        if trig is None:
                            ks = [k for k in cr.reports if str(k).startswith("strategy_triggers__")]
                            if ks:
                                trig = pd.concat([cr.reports[k] for k in ks if hasattr(cr.reports[k], "copy")], ignore_index=True, sort=False)
                    if isinstance(trig, pd.DataFrame) and not trig.empty:
                        if "trigger_count" not in trig.columns:
                            for alt in ("count","n","num"):
                                if alt in trig.columns:
                                    trig = trig.rename(columns={alt: "trigger_count"})
                                    break
                            else:
                                trig["trigger_count"] = 0
                        order_cols = [c for c in ["obs_date","scope","trigger_weighted","trigger_count","name"] if c in trig.columns]
                        if order_cols:
                            trig = trig.sort_values(order_cols, ascending=[True, True, False, False, True][:len(order_cols)])
                        st.dataframe(trig, use_container_width=True, height=420)

                        # â€”â€” å¯¹æ¯”è§†å›¾ â€”â€”
                        show_pivot = st.checkbox("æŒ‰ç»„/å£å¾„å¯¹æ¯”ï¼ˆé€è§†è¡¨ï¼‰", value=True)
                        if show_pivot:
                            
                            # æŒ‡æ ‡æ˜ å°„ï¼šæ”¹æˆã€Œè‹±æ–‡ -> ä¸­æ–‡ã€æ›´ç¨³
                            _metric_map = {
                                "trigger_count": "è§¦å‘æ¬¡æ•°",
                                "coverage": "è¦†ç›–ç‡",
                                "trigger_weighted": "åŠ æƒè§¦å‘æ¬¡æ•°",
                                "coverage_weighted": "åŠ æƒè¦†ç›–ç‡",
                            }
                            options_en = [en for en in _metric_map if en in trig.columns]

                            # â€”â€” æŒä¹…åŒ–å½“å‰é€‰æ‹©ï¼ˆæŒ‰è‹±æ–‡åˆ—åï¼‰â€”â€”
                            _pref_key = "pivot_metric_en"
                            default_en = "coverage_weighted" if "coverage_weighted" in options_en else (options_en[0] if options_en else None)
                            if default_en is not None:
                                if _pref_key not in st.session_state or st.session_state[_pref_key] not in options_en:
                                    st.session_state[_pref_key] = default_en

                            # é€‰æ‹©æ¡†ï¼šæ˜¾ç¤ºä¸­æ–‡ï¼Œå€¼ä¸ºè‹±æ–‡
                            metric_en = st.selectbox(
                                "é€‰æ‹©å¯¹æ¯”æŒ‡æ ‡",
                                options_en,
                                key=_pref_key,
                                format_func=lambda en: _metric_map.get(en, en),
                            )

                            # åç»­ç”¨ metric_en ç›´æ¥åšé€è§†ï¼›è‹¥éœ€è¦ä¸­æ–‡åå¯ç”¨ï¼š
                            pick_metric_cn = _metric_map.get(metric_en, metric_en)
                            pick_metric = metric_en

                            scopes_avail = sorted(trig["scope"].dropna().unique().tolist()) if "scope" in trig.columns else []
                            scope_pick = st.selectbox("é€‰æ‹©å£å¾„", options=(scopes_avail or ["pos"]), index=0, key="pivot_scope")
                            dfp = trig.copy()
                            if "scope" in dfp.columns and scope_pick in scopes_avail:
                                dfp = dfp[dfp["scope"]==scope_pick]
                            if "group" in dfp.columns:
                                pv = dfp.pivot_table(index="name", columns="group", values=pick_metric, aggfunc="max")
                                st.dataframe(pv, use_container_width=True, height=420)

                    # â€”â€” æ¯ç¥¨å‘½ä¸­æ¡æ•°åˆ†å¸ƒ â€”â€”
                    ks_hist_single = [k for k in (cr.reports.keys() if isinstance(cr.reports, dict) else []) if str(k).startswith("hits_histogram_single__")]
                    ks_hist_each   = [k for k in (cr.reports.keys() if isinstance(cr.reports, dict) else []) if str(k).startswith("hits_histogram_each__")]
                    import pandas as pd
                    if ks_hist_single:
                        st.markdown("**å•æ¬¡å‹ï¼ˆANY/LAST ç­‰ï¼‰å‘½ä¸­æ¡æ•°åˆ†å¸ƒ**")
                        hist_single = pd.concat([cr.reports[k] for k in ks_hist_single], ignore_index=True, sort=False)
                        scopes_hist = sorted(hist_single["scope"].dropna().unique().tolist()) if "scope" in hist_single.columns else []
                        scope_show = st.selectbox("é€‰æ‹©å£å¾„ï¼ˆå•æ¬¡å‹ï¼‰", options=(scopes_hist or ["pos"]), index=0, key="hist_scope_single")
                        show = hist_single[hist_single["scope"]==scope_show] if scopes_hist else hist_single
                        if not show.empty:
                            pv2 = show.pivot_table(index="n_single_rules_hit", columns="group", values="ratio", aggfunc="max")
                            st.dataframe(pv2, use_container_width=True, height=280)
                    if ks_hist_each:
                        st.markdown("**å¤šæ¬¡å‹ï¼ˆEACHï¼‰å‘½ä¸­æ¡æ•°åˆ†å¸ƒ**")
                        hist_each = pd.concat([cr.reports[k] for k in ks_hist_each], ignore_index=True, sort=False)
                        scopes_hist2 = sorted(hist_each["scope"].dropna().unique().tolist()) if "scope" in hist_each.columns else []
                        scope_show2 = st.selectbox("é€‰æ‹©å£å¾„ï¼ˆå¤šæ¬¡å‹ï¼‰", options=(scopes_hist2 or ["pos"]), index=0, key="hist_scope_each")
                        show2 = hist_each[hist_each["scope"]==scope_show2] if scopes_hist2 else hist_each
                        if not show2.empty:
                            pv3 = show2.pivot_table(index="n_each_rules_hit", columns="group", values="ratio", aggfunc="max")
                            st.dataframe(pv3, use_container_width=True, height=280)


                st.caption("åˆ†æé›†/æŠ¥å‘Šå·²å†™å…¥ output/commonality/<ref>/ ï¼ˆåŒ…æ‹¬ strategy_triggers__*.parquet, hits_by_stock__*.parquet, hits_histogram__*.parquetï¼‰ã€‚")

            except Exception as e:
                st.error(f"Commonality å¤±è´¥ï¼š{e}")

# ================== æ—¥å¿— ==================
with tab_logs:
    st.subheader("æ—¥å¿—")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**score.logï¼ˆå°¾éƒ¨ 400 è¡Œï¼‰**")
        st.code(_tail(LOG_DIR / "score.log", 400), language="bash")
    with col2:
        st.markdown("**score_ui.logï¼ˆå°¾éƒ¨ 400 è¡Œï¼‰**")
        st.code(_tail(LOG_DIR / "score_ui.log", 400), language="bash")