# -*- coding: utf-8 -*-
from __future__ import annotations

import os, io, json, re
import warnings
from pathlib import Path
from datetime import datetime, timedelta, date
from typing import List, Optional, Dict
import threading
from log_system import get_logger
import pandas as pd
import numpy as np
import streamlit as st

# å¿½ç•¥tushareçš„FutureWarning
warnings.filterwarnings(
    "ignore",
    category=FutureWarning,
    module="tushare.pro.data_pro",
    message=".*fillna.*method.*deprecated.*"
)

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = get_logger("score_ui")
def ui_cleanup_database_connections():
    """å¼ºåˆ¶æ¸…ç†æ‰€æœ‰æ•°æ®åº“è¿æ¥ - ç»Ÿä¸€ä½¿ç”¨ data_reader ç®¡ç†"""
    try:
        # å»¶è¿Ÿå¯¼å…¥ data_readerï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        try:
            from database_manager import clear_connections_only
        except ImportError as e:
            st.error(f"æ— æ³•å¯¼å…¥ database_manager æ¨¡å—: {e}")
            return False
        
        # æ¸…ç†æ•°æ®åº“è¿æ¥ï¼ˆè½»é‡çº§æ¸…ç†ï¼Œä¸å…³é—­å·¥ä½œçº¿ç¨‹ï¼‰
        clear_connections_only()
        
        # æ•°æ®åº“è¿æ¥å·²é€šè¿‡ database_manager æ¸…ç†
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        st.success("âœ… æ•°æ®åº“è¿æ¥æ¸…ç†å®Œæˆ")
        return True
        
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥æ¸…ç†å¤±è´¥: {e}")
        return False

def check_database_status():
    """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
    try:
        # å»¶è¿Ÿå¯¼å…¥ data_readerï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        try:
            from database_manager import get_database_manager
            # get_database_info å·²ä» database_manager å¯¼å…¥
        except ImportError as e:
            st.error(f"æ— æ³•å¯¼å…¥ database_manager æ¨¡å—: {e}")
            return False
        
        # è·å–æ•°æ®åº“ä¿¡æ¯
        db_info = get_database_info()
        
        # è·å–æ•°æ®åº“ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯
        logger.info("[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹")
        manager = get_database_manager()
        enhanced_stats = manager.get_stats()
        
        st.info(f"æ•°æ®åº“ç®¡ç†å™¨: {enhanced_stats}")
        st.info(f"æ•°æ®åº“ä¿¡æ¯: {db_info}")
        
        return True
    except Exception as e:
        st.error(f"æ£€æŸ¥æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
        return False

# è¿›ç¨‹æ§åˆ¶åŠŸèƒ½å·²ç§»é™¤ï¼Œç›¸å…³é—®é¢˜åœ¨database_managerä¸­ç»Ÿä¸€å¤„ç†

import streamlit.components.v1 as components
from contextlib import contextmanager
import shutil
import uuid
import time
import queue
import traceback

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
# import download as dl
import scoring_core as se
import config as cfg
import stats_core as stats
from utils import normalize_ts, ensure_datetime_index, normalize_trade_date, market_label
# ä½¿ç”¨ database_manager æ›¿ä»£ data_reader
from database_manager import (
    get_database_manager, query_stock_data, get_trade_dates, 
    get_stock_list, get_latest_trade_date, get_smart_end_date,
    get_database_info, get_data_source_status, close_all_connections,
    clear_connections_only,
    is_details_db_reading_enabled, get_details_db_path_with_fallback, is_details_db_available
)

def _lazy_import_download():
    """å»¶è¿Ÿå¯¼å…¥ download æ¨¡å—çš„å‡½æ•°"""
    try:
        import download as dl
        return dl
    except ImportError as e:
        logger = get_logger("score_ui")
        logger.error(f"å¯¼å…¥ download å¤±è´¥: {e}")
        return None

# ç›´æ¥ä½¿ç”¨ database_manager å‡½æ•°ï¼Œä¸å†éœ€è¦åŒ…è£…å™¨
import os
from config import DATA_ROOT, API_ADJ, SC_DETAIL_STORAGE, SC_USE_DB_STORAGE, SC_DB_FALLBACK_TO_JSON
import tdx_compat as tdx
from stats_core import _pick_trade_dates, _prev_trade_date
import indicators as ind
import predict_core as pr
from rule_editor import render_rule_editor
from predict_core import (
    PredictionInput, PositionCheckInput,
    run_prediction, run_position_checks,
    load_prediction_rules, load_position_policies, load_opportunity_policies,
    Scenario
)

# ---- Streamlit context guard & cache alias (auto-injected) ----
def _in_streamlit():
    try:
        import streamlit as st
        exists = getattr(getattr(st, "runtime", None), "exists", None)
        if callable(exists):
            return bool(exists())
    except Exception:
        pass
    # å›è½åˆ° get_script_run_ctxï¼ˆå¹¶é…åˆæ–¹æ¡ˆ1é™éŸ³ï¼‰
    from streamlit.runtime.scriptrunner import get_script_run_ctx
    return get_script_run_ctx() is not None


def _noop_cache_data(*dargs, **dkw):
    def deco(fn): 
        return fn
    return deco

cache_data = (st.cache_data if _in_streamlit() else _noop_cache_data)
# --------------------------------------------------------------

def _safe_path_hash(p: Path) -> int:
    try:
        return p.stat().st_mtime_ns
    except (OSError, FileNotFoundError):
        return hash(str(p))

def _is_valid_date(date_str: str) -> bool:
    try:
        datetime.strptime(date_str, "%Y%m%d")
        return True
    except ValueError:
        return False

def _safe_int(x, default: int = 60) -> int:
    try:
        return int(x)
    except Exception:
        return int(default)

def _init_session_state():
    """ç»Ÿä¸€åˆå§‹åŒ– Streamlit session_state çš„å…³é”®å­—æ®µï¼Œé¿å…é‡å¤åˆ¤æ–­æ•£è½å„å¤„ã€‚"""
    try:
        import streamlit as st  # local import so this can run outside Streamlit too
        if not _in_streamlit():
            return
        defaults = {
            "cur_pid": None,
            "cur_pf": None,
            "rules_obj": {
                "prescreen": getattr(se, "SC_PRESCREEN_RULES", []),
                "rules": getattr(se, "SC_RULES", []),
            },
            "export_pref": {"style": "space", "with_suffix": True},
        }
        for k, v in defaults.items():
            if k not in st.session_state:
                st.session_state[k] = v
        
        # æ·»åŠ è¡¨è¾¾å¼é€‰è‚¡æ—¶çš„æ•°æ®åº“è¿æ¥ç®¡ç†
        if "expression_screening_active" not in st.session_state:
            st.session_state["expression_screening_active"] = False
        
        # æ·»åŠ detailsæ•°æ®åº“è¯»å–æ§åˆ¶æ ‡è®°ï¼Œé»˜è®¤ä¸è¯»å–æ•°æ®åº“é¿å…å†™å…¥å†²çª
        if "details_db_reading_enabled" not in st.session_state:
            st.session_state["details_db_reading_enabled"] = False
        
        # æ·»åŠ æ•°æ®æŸ¥çœ‹é¡µé¢çš„æ•°æ®åº“æŸ¥è¯¢æ§åˆ¶æ ‡è®°ï¼Œé»˜è®¤ä¸æŸ¥è¯¢æ•°æ®åº“é¿å…å†™å…¥å†²çª
        if "data_view_db_enabled" not in st.session_state:
            st.session_state["data_view_db_enabled"] = False
    except Exception:
        pass

if _in_streamlit():
    st.set_page_config(page_title="ScoreApp", layout="wide")
    _init_session_state()
# ===== å¸¸é‡è·¯å¾„ =====
SC_OUTPUT_DIR = Path(getattr(cfg, "SC_OUTPUT_DIR", "output/score"))
TOP_DIR  = SC_OUTPUT_DIR / "top"
ALL_DIR  = SC_OUTPUT_DIR / "all"
DET_DIR  = SC_OUTPUT_DIR / "details"
ATTN_DIR = SC_OUTPUT_DIR / "attention"
LOG_DIR  = Path("./log")


for p in [TOP_DIR, ALL_DIR, DET_DIR, ATTN_DIR, LOG_DIR]:
    p.mkdir(parents=True, exist_ok=True)

def _apply_overrides(
    base: str,
    assets: List[str],
    start: str,
    end: str,
    api_adj: str,
    fast_threads: int,
    inc_threads: int,
    inc_ind_workers: int | None,
):
    """æŠŠ UI è¾“å…¥åŒæ­¥åˆ° download.py çš„å…¨å±€ï¼Œä»¥ä¾¿å…¶å‡½æ•°è¯»å–ã€‚"""
    # å»¶è¿Ÿå¯¼å…¥ download æ¨¡å—
    dl = _lazy_import_download()
    if dl is None:
        raise ImportError("æ— æ³•å¯¼å…¥ download æ¨¡å—")
    
    # download.py å†…éƒ¨å¤šæ•°ç›´æ¥ä½¿ç”¨æ¨¡å—çº§å¸¸é‡ï¼Œè¿™é‡ŒåŸåœ°è¦†å†™å®ƒä»¬
    dl.DATA_ROOT = base
    dl.ASSETS = [a.lower() for a in assets]
    dl.START_DATE = start
    dl.END_DATE = end
    dl.API_ADJ = api_adj.lower()
    dl.FAST_INIT_THREADS = int(max(1, fast_threads))
    dl.STOCK_INC_THREADS = int(max(1, inc_threads))
    if inc_ind_workers is not None and int(inc_ind_workers) > 0:
        dl.INC_RECALC_WORKERS = int(inc_ind_workers)

    # åŒæ­¥åˆ° configï¼Œä»¥ä¾¿å…¶ä»–æ¨¡å—ï¼ˆå¦‚ parquet_viewerï¼‰çœ‹åˆ°ä¸€è‡´çš„ base/adj
    try:
        cfg.DATA_ROOT = base
        cfg.API_ADJ = api_adj.lower() if api_adj.lower() in {"raw","qfq","hfq"} else getattr(cfg, "API_ADJ", "qfq")
    except Exception:
        pass

@cache_data(show_spinner=False, ttl=300)
def _latest_trade_date(base: str, adj: str) -> str | None:
    try:
        # ä½¿ç”¨ database_manager è·å–æœ€æ–°äº¤æ˜“æ—¥
        latest_date = get_latest_trade_date()
        return latest_date
    except Exception:
        return None

# -------------------- æ‰§è¡ŒåŠ¨ä½œï¼ˆå°è£… download.pyï¼‰ --------------------
def _run_fast_init(end_use: str):
    # å»¶è¿Ÿå¯¼å…¥ download æ¨¡å—
    dl = _lazy_import_download()
    if dl is None:
        raise ImportError("æ— æ³•å¯¼å…¥ download æ¨¡å—")
    
    dl.fast_init_download(end_use)                       # é¦–æ¬¡å…¨é‡ï¼ˆå•è‚¡ç¼“å­˜ï¼‰
    # æ•°æ®åº“æ“ä½œå·²è¿ç§»åˆ° data_reader.pyï¼Œåˆå¹¶æ“ä½œå·²é›†æˆåˆ°ä¸‹è½½è¿‡ç¨‹ä¸­


def _run_increment(start_use: str, end_use: str, do_stock: bool, do_index: bool, do_indicators: bool):
    # å»¶è¿Ÿå¯¼å…¥ download æ¨¡å—
    dl = _lazy_import_download()
    if dl is None:
        raise ImportError("æ— æ³•å¯¼å…¥ download æ¨¡å—")
    
    # è‹¥ fast_init çš„ç¼“å­˜å­˜åœ¨ï¼Œå…ˆåˆå¹¶ä¸€æ¬¡ï¼ˆä¸ main() é€»è¾‘ä¸€è‡´ï¼‰
    try:
        if any(
            os.path.isdir(os.path.join(dl.FAST_INIT_STOCK_DIR, d))
            and any(f.endswith(".parquet") for f in os.listdir(os.path.join(dl.FAST_INIT_STOCK_DIR, d)))
            for d in ("raw","qfq","hfq")
        ):
            # æ•°æ®åº“æ“ä½œå·²è¿ç§»åˆ° data_reader.py
            pass
    except Exception:
        pass

    if do_stock and ("stock" in set(dl.ASSETS)):
        dl.sync_stock_daily_fast(start_use, end_use, threads=dl.STOCK_INC_THREADS)
    if do_index and ("index" in set(dl.ASSETS)):
        dl.sync_index_daily_fast(start_use, end_use, dl.INDEX_WHITELIST)
    if do_indicators:
        workers = getattr(dl, "INC_RECALC_WORKERS", None) or ((os.cpu_count() or 4) * 2)
        dl.recalc_symbol_products_for_increment(start_use, end_use, threads=workers)

# ===== å°å·¥å…· =====
def _path_top(ref: str) -> Path: return TOP_DIR / f"score_top_{ref}.csv"
def _path_all(ref: str) -> Path: return ALL_DIR / f"score_all_{ref}.csv"
def _path_detail(ref: str, ts: str) -> Path: return DET_DIR / ref / f"{normalize_ts(ts)}_{ref}.json"
def _today_str() -> str:
    return date.today().strftime("%Y%m%d")

@cache_data(show_spinner=False, hash_funcs={Path: _safe_path_hash}, ttl=60)
def _read_df(path: Path, usecols=None, dtype=None, encoding: str = "utf-8-sig") -> pd.DataFrame:
    try:
        return pd.read_csv(path, usecols=usecols, dtype=dtype, encoding=encoding, engine="c")
    except Exception:
        return pd.DataFrame()

@cache_data(show_spinner=False, ttl=600)
def _cached_trade_dates(base: str, adj: str):
    # ä½¿ç”¨ database_manager è·å–äº¤æ˜“æ—¥åˆ—è¡¨
    return get_trade_dates() or []

# ==== è¿›åº¦è½¬å‘åˆ°ä¸»çº¿ç¨‹ï¼šä»…å­çº¿ç¨‹/å­è¿›ç¨‹å…¥é˜Ÿï¼Œä¸»çº¿ç¨‹æ¶ˆè´¹å¹¶æ¸²æŸ“ ====
@contextmanager
def se_progress_to_streamlit():
    if not _in_streamlit():
        # bare/å­çº¿ç¨‹ä¸‹ï¼šæŒ‚ç©ºå›è°ƒï¼Œå•¥ä¹Ÿä¸ç”»ï¼Œé¿å…ä»»ä½• st.* è°ƒç”¨
        def _noop(*a, **k): 
            pass
        # ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿæ›¿ä»£åºŸå¼ƒçš„ set_progress_handler
        from log_system import get_logger
        logger = get_logger("scoring_core")
        logger.info("ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿè¿›è¡Œè¿›åº¦è·Ÿè¸ª")
        try:
            yield None, None, None
        finally:
            pass
        return
    status = st.status("å‡†å¤‡ä¸­â€¦", expanded=True)
    bar = st.progress(0, text="å°±ç»ª")
    info = st.empty()

    import queue as _q
    _evq = _q.Queue()
    
    # åå°çº¿ç¨‹åªå…¥é˜Ÿï¼Œä¸ç›´æ¥ç¢° st.*
    def _enqueue_handler(phase, current=None, total=None, message=None, **kw):
        try:
            _evq.put_nowait((phase, current, total, message))
        except Exception:
            pass

    def _render_event(phase, current=None, total=None, message=None):
        txt = {
            "select_ref_date": "é€‰æ‹©å‚è€ƒæ—¥", "compute_read_window": "è®¡ç®—è¯»å–åŒºé—´",
            "build_universe_done": "æ„å»ºè¯„åˆ†æ¸…å•", "score_start": "å¹¶è¡Œè¯„åˆ†å¯åŠ¨",
            "score_progress": "è¯„åˆ†è¿›è¡Œä¸­", "screen_start": "ç­›é€‰å¯åŠ¨",
            "screen_progress": "ç­›é€‰è¿›è¡Œä¸­", "screen_done": "ç­›é€‰å®Œæˆ",
            "write_cache_lists": "å†™å…¥é»‘ç™½åå•", "write_top_all_start": "å†™å‡º Top/All",
            "write_top_all_done": "Top/All å®Œæˆ", "hooks_start": "ç»Ÿè®¡/å›çœ‹",
            "hooks_done": "ç»Ÿè®¡å®Œæˆ",
        }.get(phase, phase)
        if total and current is not None:
            pct = int(current * 100 / max(total, 1))
            # æ˜¾ç¤ºè¿›åº¦è¯¦æƒ…ï¼šè¯„åˆ†å’Œç­›é€‰éƒ½æ˜¾ç¤ºæ•°é‡
            if phase in ("score_progress", "screen_progress"):
                bar.progress(pct, text=f"{txt} Â· {current}/{total}")
            else:
                bar.progress(pct, text=txt)
        else:
            # ä½¿ç”¨messageä½œä¸ºä¸»è¦æ˜¾ç¤ºå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨txt
            display_text = message if message else txt
            info.write(display_text)

    # ä¸»çº¿ç¨‹æ¶ˆè´¹ï¼šä¾› run_se_run_for_date_in_bg å¾ªç¯è°ƒç”¨
    def _drain():
        try:
            while True:
                ev = _evq.get_nowait()
                _render_event(*ev)
        except _q.Empty:
            pass

    # ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿå¹¶è®¾ç½®è¿›åº¦å¤„ç†å™¨
    from log_system import get_logger
    logger = get_logger("scoring_core")
    logger.info("ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿè¿›è¡Œè¿›åº¦è·Ÿè¸ª")
    
    # å…³é”®ï¼šè®¾ç½®è¿›åº¦å¤„ç†å™¨ï¼Œä½¿è¯„åˆ†ç³»ç»Ÿèƒ½å¤Ÿå‘é€è¿›åº¦äº‹ä»¶
    _orig_drain = getattr(se, "drain_progress_events", None)
    se.set_progress_handler(_enqueue_handler)
    se.drain_progress_events = _drain  # å°†"æŠ½å¹²"æ›¿æ¢æˆä¸»çº¿ç¨‹æ¸²æŸ“
    
    try:
        yield status, bar, info
    finally:
        # è¿˜åŸ drainï¼ˆä¿æŒæ¨¡å—æ•´æ´ï¼‰
        if callable(_orig_drain):
            se.drain_progress_events = _orig_drain
        else:
            se.drain_progress_events = lambda: None

@cache_data(show_spinner=False)
def _read_md_file(path: str) -> str:
    try:
        return Path(path).read_text(encoding="utf-8-sig")
    except Exception:
        # å…œåº•æç¤ºï¼Œé¿å…é¡µé¢æŠ¥é”™
        return "âš ï¸ æœªæ‰¾åˆ°å¸®åŠ©æ–‡æ¡£ï¼š" + path


def run_se_run_for_date_in_bg(arg):
    """åœ¨åå°çº¿ç¨‹è¿è¡Œ se.run_for_date(arg)ï¼Œå¹¶åœ¨ä¸»çº¿ç¨‹æ¸²æŸ“è¿›åº¦"""
    with se_progress_to_streamlit() as (status, bar, info):
        done = threading.Event()
        result = {"path": None, "err": None}

        def _worker():
            try:
                try:
                    # prefer local UI cleanup if present
                    if 'ui_cleanup_database_connections' in globals():
                        ui_cleanup_database_connections()
                    else:
                        # ä½¿ç”¨è½»é‡çº§æ¸…ç†å‡½æ•°ï¼Œé¿å…å…³é—­å·¥ä½œçº¿ç¨‹
                        from database_manager import clear_connections_only
                        clear_connections_only()
                except Exception:
                    pass
                
                # åœ¨å­çº¿ç¨‹ä¸­è¿è¡Œè¯„åˆ†ï¼Œä½†ç¡®ä¿æ•°æ®åº“è¿æ¥æ­£ç¡®åˆå§‹åŒ–
                from database_manager import get_database_manager
                logger.info("[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (è¯„åˆ†çº¿ç¨‹)")
                manager = get_database_manager()
                
                # ç¡®ä¿æ•°æ®åº“ç®¡ç†å™¨å·²æ­£ç¡®åˆå§‹åŒ–ï¼Œé¿å…è¿æ¥é—®é¢˜
                try:
                    # æµ‹è¯•æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸
                    test_date = manager.get_latest_trade_date()
                    if test_date:
                        logger.info(f"[è¯„åˆ†] æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œæœ€æ–°äº¤æ˜“æ—¥: {test_date}")
                    else:
                        logger.warning("[è¯„åˆ†] æ•°æ®åº“è¿æ¥æ­£å¸¸ä½†æ— æœ€æ–°äº¤æ˜“æ—¥æ•°æ®")
                except Exception as e:
                    logger.warning(f"[è¯„åˆ†] æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
                
                result["path"] = se.run_for_date(arg)
            except Exception as e:
                result["err"] = e
            finally:
                done.set()
        t = threading.Thread(target=_worker, daemon=True)
        t.start()

        # ä¸»çº¿ç¨‹å¾ªç¯æŠ½å–è¿›åº¦äº‹ä»¶å¹¶åˆ·æ–° UI
        while not done.is_set():
            se.drain_progress_events()
            time.sleep(0.05)
        # æŠ½å¹²å‰©ä½™äº‹ä»¶
        se.drain_progress_events()
        if status is not None:
            status.update(label="å·²å®Œæˆ", state="complete")

        if result["err"]:
            raise result["err"]
        return result["path"]


def run_se_screen_in_bg(*, when_expr, ref_date, timeframe, window, scope, universe, write_white, write_black_rest, return_df=True):
    """åœ¨åå°çº¿ç¨‹è¿è¡Œ se.tdx_screen(...)ï¼Œå¹¶åœ¨ä¸»çº¿ç¨‹æ¸²æŸ“è¿›åº¦ï¼ˆç”¨äºâ€œæ™®é€šé€‰è‚¡â€ï¼‰"""
    with se_progress_to_streamlit() as (status, bar, info):
        import threading, time
        done = threading.Event()
        result = {"df": None, "err": None}

        def _worker():
            try:
                try:
                    # prefer local UI cleanup if present
                    if 'ui_cleanup_database_connections' in globals():
                        ui_cleanup_database_connections()
                    else:
                        # ä½¿ç”¨è½»é‡çº§æ¸…ç†å‡½æ•°ï¼Œé¿å…å…³é—­å·¥ä½œçº¿ç¨‹
                        from database_manager import clear_connections_only
                        clear_connections_only()
                except Exception:
                    pass
                
                st.session_state["expression_screening_active"] = True
                
                try:
                    result["df"] = se.tdx_screen(
                        when_expr,
                        ref_date=ref_date,
                        timeframe=timeframe,
                        window=_safe_int(window, 30),
                        scope=scope,
                        universe=universe,
                        write_white=write_white,
                        write_black_rest=write_black_rest,
                        return_df=return_df
                    )
                finally:
                    st.session_state["expression_screening_active"] = False
                    
            except Exception as e:
                result["err"] = e
                st.session_state["expression_screening_active"] = False
            finally:
                done.set()

        t = threading.Thread(target=_worker, daemon=True)
        t.start()

        # ä¸»çº¿ç¨‹å¾ªç¯æŠ½å–è¿›åº¦äº‹ä»¶å¹¶åˆ·æ–° UI
        while not done.is_set():
            se.drain_progress_events()
            time.sleep(0.05)
        # æŠ½å¹²å‰©ä½™äº‹ä»¶
        se.drain_progress_events()
        if status is not None:
            status.update(label="å·²å®Œæˆ", state="complete")

        if result["err"]:
            raise result["err"]
        return result["df"]


def _get_latest_date_from_files() -> Optional[str]:
    """ä»è¯„åˆ†ç»“æœæ–‡ä»¶åä¸­æå–æœ€æ–°æ—¥æœŸ"""
    files = sorted(TOP_DIR.glob("score_top_*.csv"))
    dates = []
    for p in files:
        m = re.search(r"(\d{8})", p.name)
        if m: dates.append(m.group(1))
    return max(dates) if dates else None


def _get_latest_date_from_database() -> Optional[str]:
    """ä»æ•°æ®åº“è·å–æœ€æ–°äº¤æ˜“æ—¥"""
    try:
        from database_manager import get_latest_trade_date
        latest = get_latest_trade_date()
        if latest:
            logger.info(f"ä»æ•°æ®åº“è·å–æœ€æ–°äº¤æ˜“æ—¥: {latest}")
            return latest
    except Exception as e:
        logger.warning(f"ä»æ•°æ®åº“è·å–æœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}")
    return None


def _get_latest_date_from_daily_partition() -> Optional[str]:
    """ä»dailyåˆ†åŒºè·å–æœ€æ–°äº¤æ˜“æ—¥"""
    try:
        from database_manager import get_trade_dates
        dates = get_trade_dates()
        if dates:
            latest = dates[-1]
            logger.info(f"ä»dailyåˆ†åŒºè·å–æœ€æ–°äº¤æ˜“æ—¥: {latest}")
            return latest
    except Exception as e:
        logger.warning(f"ä»dailyåˆ†åŒºè·å–æœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}")
    return None


def _pick_smart_ref_date() -> Optional[str]:
    """æ™ºèƒ½è·å–å‚è€ƒæ—¥æœŸï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šç§æ–¹å¼"""
    # 1. ä¼˜å…ˆä»æ•°æ®åº“è·å–
    latest = _get_latest_date_from_database()
    if latest:
        return latest
    
    # 2. ä»dailyåˆ†åŒºè·å–
    latest = _get_latest_date_from_daily_partition()
    if latest:
        return latest
    
    # 3. æœ€åä»è¯„åˆ†ç»“æœæ–‡ä»¶è·å–
    latest = _get_latest_date_from_files()
    if latest:
        logger.warning(f"å›é€€åˆ°è¯„åˆ†ç»“æœæ–‡ä»¶ä¸­çš„æœ€æ–°æ—¥æœŸ: {latest}")
    else:
        logger.error("æ— æ³•è·å–ä»»ä½•å‚è€ƒæ—¥æœŸ")
    
    return latest


def _prev_ref_date(cur: str) -> Optional[str]:
    files = sorted(TOP_DIR.glob("score_top_*.csv"))
    dates = []
    for p in files:
        m = re.search(r"(\d{8})", p.name)
        if m and m.group(1) < cur:
            dates.append(m.group(1))
    return dates[-1] if dates else None


def _from_last_hints(days: list[int] | None = None,
                     base: str = DATA_ROOT, adj: str = API_ADJ,
                     last: str | None = None):
    """
    åŸºäºâ€œæœ€æ–°äº¤æ˜“æ—¥ lastï¼ˆç¼ºçœ=æœ¬åœ°æ•°æ®çš„æœ€åä¸€å¤©ï¼‰â€ï¼Œè¿”å›ï¼š
      - æ–‡æœ¬æç¤ºä¸²ï¼ˆå«æ˜ŸæœŸï¼‰ï¼Œç”¨äºå±•ç¤ºï¼›
      - æ˜ å°„ dict: {n: d8}ï¼Œn ä¸ªäº¤æ˜“æ—¥å‰å¯¹åº”çš„ yyyymmdd å­—ç¬¦ä¸²ã€‚
    """
    try:
        ds = get_trade_dates() or []
        if not ds:
            return "", {}
        last = last or ds[-1]
        if last not in ds:
            return "", {}

        idx = ds.index(last)
        days = sorted({int(x) for x in (days or []) if int(x) >= 1})

        from datetime import date as _d
        def _fmt(d8: str) -> str:
            y, m, d = int(d8[:4]), int(d8[4:6]), int(d8[6:])
            wk = "ä¸€äºŒä¸‰å››äº”å…­æ—¥"[_d(y, m, d).weekday()]
            return f"{y:04d}-{m:02d}-{d:02d}(å‘¨{wk})"

        parts = [f"æœ€æ–°={_fmt(last)}"]
        mapping = {}
        for n in days:
            j = idx - n
            if j >= 0:
                mapping[n] = ds[j]
                parts.append(f"{n}ä¸ªäº¤æ˜“æ—¥å‰={_fmt(ds[j])}")
            else:
                parts.append(f"{n}ä¸ªäº¤æ˜“æ—¥å‰=--ï¼ˆæ•°æ®ä¸è¶³ï¼‰")
        return " Â· ".join(parts), mapping
    except Exception:
        return "", {}


def _rule_to_screen_args(rule: dict):
    """è¿”å› (when_expr, timeframe, window, scope)"""
    if rule.get("clauses"):
        tfs = {str(c.get("timeframe","D")).upper() for c in rule["clauses"]}
        wins = {int(c.get("window", 60)) for c in rule["clauses"]}
        scopes = {str(c.get("scope","ANY")).upper() for c in rule["clauses"]}
        whens = [f"({c.get('when','').strip()})" for c in rule["clauses"] if c.get("when","").strip()]
        if not whens:
            raise ValueError("å¤åˆè§„åˆ™ç¼ºå°‘ when")
        # ç›®å‰ä»…æ”¯æŒâ€œç›¸åŒ tf/window/scopeâ€çš„å¤åˆè§„åˆ™ï¼›å¦åˆ™å°±æ— æ³•ä¸€æ¬¡æ€§å±å…¨å¸‚åœº
        if len(tfs)==len(wins)==len(scopes)==1:
            return " AND ".join(whens), list(tfs)[0], list(wins)[0], list(scopes)[0]
        else:
            raise ValueError("å…¨å¸‚åœºè·‘ç›®å‰ä»…æ”¯æŒå„å­å¥ tf/window/scope å®Œå…¨ä¸€è‡´çš„å¤åˆè§„åˆ™")
    else:
        when = (rule.get("when") or "").strip()
        if not when:
            raise ValueError("when ä¸èƒ½ä¸ºç©º")
        tf = str(rule.get("timeframe","D")).upper()
        win = int(rule.get("window", 60))
        scope = str(rule.get("scope","ANY")).upper()
        # --- substitute placeholders (K/M/N) for scope ---
        try:
            import re
            k = int(rule.get("k", rule.get("n", 0)) or 0)
            m = int(rule.get("m", 0) or 0)
            # COUNT>=K -> COUNT>=<k or 3>
            if "COUNT" in scope and re.search(r"\bK\b", scope):
                scope = re.sub(r"\bK\b", str(k or 3), scope)
            # CONSEC>=M -> CONSEC>=<m or 3>
            if "CONSEC" in scope and re.search(r"\bM\b", scope):
                scope = re.sub(r"\bM\b", str(m or 3), scope)
            # ANY_N / ALL_N -> ANY_<k or 3> / ALL_<k or 3>
            scope = scope.replace("ANY_N", f"ANY_{k or 3}").replace("ALL_N", f"ALL_{k or 3}")
        except Exception:
            pass
        return when, tf, win, scope


def _load_detail_json(ref: str, ts: str) -> Optional[Dict]:
    """
    åŠ è½½ä¸ªè‚¡è¯¦æƒ…ï¼Œä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼Œå¤±è´¥æ—¶å›é€€åˆ°JSONæ–‡ä»¶
    æ³¨æ„ï¼šåªæœ‰å½“ details_db_reading_enabled ä¸º True æ—¶æ‰ä¼šè¯»å–æ•°æ®åº“ï¼Œé¿å…ä¸å†™å…¥æ“ä½œå†²çª
    """
    # æ£€æŸ¥æ˜¯å¦å…è®¸è¯»å–æ•°æ®åº“ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°ï¼‰
    db_reading_enabled = is_details_db_reading_enabled()
    
    # 1. ä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼ˆåªæœ‰å½“db_reading_enabledä¸ºTrueä¸”æ•°æ®åº“å¯ç”¨æ—¶æ‰è¯»å–ï¼‰
    if db_reading_enabled and is_details_db_available():
        db_success = False
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°è·å–detailsæ•°æ®åº“è·¯å¾„ï¼ˆåŒ…å«å›é€€é€»è¾‘ï¼‰
            details_db_path = get_details_db_path_with_fallback()
            if not details_db_path:
                # æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°JSON
                logger.debug(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°JSON: {ts}_{ref}")
                db_success = False
                raise FileNotFoundError("Detailsæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            
            # æŸ¥è¯¢è‚¡ç¥¨è¯¦æƒ…è¡¨
            logger.info(f"[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (æŸ¥è¯¢è‚¡ç¥¨è¯¦æƒ…: {ts}, {ref})")
            manager = get_database_manager()
            sql = "SELECT * FROM stock_details WHERE ts_code = ? AND ref_date = ?"
            df = manager.execute_sync_query(details_db_path, sql, [ts, ref], timeout=30.0)
            
            if not df.empty:
                row = df.iloc[0]
                
                # è§£æ rules å­—æ®µï¼šä¼˜å…ˆ json.loadsï¼Œå¤±è´¥åˆ™ ast.literal_evalï¼Œæœ€åä¿è¯æ˜¯ list[dict]
                rules_raw = row.get('rules')
                rules = []
                if rules_raw:
                    if isinstance(rules_raw, str):
                        try:
                            rules = json.loads(rules_raw)
                        except Exception:
                            try:
                                import ast
                                rules = ast.literal_eval(rules_raw)
                            except Exception:
                                rules = []
                    elif isinstance(rules_raw, list):
                        rules = rules_raw
                
                # ç¡®ä¿ rules æ˜¯ list[dict] æ ¼å¼
                if not isinstance(rules, list):
                    rules = []
                
                # è§£æ highlights/drawbacks/opportunities å­—æ®µä¸º list[str]
                def parse_string_list(field_value):
                    if not field_value:
                        return []
                    if isinstance(field_value, str):
                        try:
                            parsed = json.loads(field_value)
                            return parsed if isinstance(parsed, list) else []
                        except Exception:
                            try:
                                import ast
                                parsed = ast.literal_eval(field_value)
                                return parsed if isinstance(parsed, list) else []
                            except Exception:
                                return []
                    elif isinstance(field_value, list):
                        return field_value
                    return []
                
                highlights = parse_string_list(row.get('highlights'))
                drawbacks = parse_string_list(row.get('drawbacks'))
                opportunities = parse_string_list(row.get('opportunities'))
                
                # è·å– rank å’Œ total å€¼
                rank_val = row.get('rank')
                total_val = row.get('total')
                
                # ç»„è£… summaryï¼ŒåŒ…å« rank å’Œ total
                summary = {
                    'score': row.get('score'),
                    'tiebreak': row.get('tiebreak'),
                    'highlights': highlights,
                    'drawbacks': drawbacks,
                    'opportunities': opportunities,
                    'rank': int(rank_val) if pd.notna(rank_val) else None,
                    'total': int(total_val) if pd.notna(total_val) else None,
                }
                
                # ç»„è£…æˆä¸ JSON æ–‡ä»¶å®Œå…¨ä¸€è‡´çš„ç»“æ„ï¼Œä¿æŒå…¼å®¹æ€§
                result = {
                    'ts_code': row.get('ts_code'),
                    'ref_date': row.get('ref_date'),
                    'summary': summary,
                    'rules': rules,
                    'rank': summary['rank'],   # å…¼å®¹æ—§è°ƒç”¨
                    'total': summary['total'],
                }
                db_success = True
                return result
            else:
                # æ•°æ®åº“æŸ¥è¯¢æˆåŠŸä½†æ— æ•°æ®ï¼Œå›é€€åˆ°JSON
                logger.debug(f"æ•°æ®åº“æŸ¥è¯¢ä¸ºç©ºï¼Œå›é€€åˆ°JSON: {ts}_{ref}")
                db_success = False
        except Exception as e:
            # æ•°æ®åº“è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°JSON
            logger.debug(f"æ•°æ®åº“è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°JSON {ts}_{ref}: {e}")
            db_success = False
        
        # å¦‚æœæ•°æ®åº“è¯»å–å¤±è´¥ï¼ˆå¼‚å¸¸æˆ–æŸ¥è¯¢ä¸ºç©ºï¼‰ï¼Œå›é€€åˆ°JSON
        if not db_success:
            # ç»§ç»­ä¸‹é¢çš„JSONå›é€€é€»è¾‘
            pass
        else:
            # æ•°æ®åº“è¯»å–æˆåŠŸï¼Œå·²è¿”å›ç»“æœï¼Œä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
            pass
    
    # 2. å¦‚æœæ•°æ®åº“å¤±è´¥ä¸”é…ç½®äº†å›é€€ï¼Œæˆ–è€…é…ç½®äº†JSONå­˜å‚¨ï¼Œæˆ–è€…æœªå¯ç”¨æ•°æ®åº“è¯»å–ï¼Œåˆ™ä½¿ç”¨JSONæ–‡ä»¶
    if (not db_reading_enabled) or (SC_DB_FALLBACK_TO_JSON) or SC_DETAIL_STORAGE in ["json", "both"]:
        try:
            p = _path_detail(ref, ts)
            if not p.exists(): 
                # JSONæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£å¸¸è¿”å›Noneï¼Œä¸æŠ¥é”™
                return None
            try:
                data = json.loads(p.read_text(encoding="utf-8-sig"))
                return data
            except json.JSONDecodeError as e:
                # JSONè§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸æŠ¥é”™
                logger.debug(f"JSONæ–‡ä»¶è§£æå¤±è´¥ {ts}_{ref}: {e}")
                return None
            except Exception as e:
                # å…¶ä»–è¯»å–å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—ä½†ä¸æŠ¥é”™
                logger.debug(f"JSONæ–‡ä»¶è¯»å–å¤±è´¥ {ts}_{ref}: {e}")
                return None
        except Exception as e:
            # è·¯å¾„æ„å»ºæˆ–å…¶ä»–å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—ä½†ä¸æŠ¥é”™
            logger.debug(f"JSONæ–‡ä»¶è·¯å¾„å¤„ç†å¤±è´¥ {ts}_{ref}: {e}")
            return None
    
    # å…œåº•ï¼šæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œè¿”å›None
    return None


def _codes_to_txt(codes: List[str], style: str="space", with_suffix: bool=True) -> str:
    def fmt(c):
        c = normalize_ts(c)
        return c if with_suffix else c.split(".")[0]
    arr = [fmt(c) for c in codes]
    return (" ".join(arr)) if style == "space" else ("\n".join(arr))


def _download_txt(label: str, text: str, filename: str, key: Optional[str]=None):
    st.download_button(label, data=text.encode("utf-8-sig"),
                       file_name=filename, mime="text/plain",
                       width='stretch', key=key)


def copy_txt_button(text: str, label: str = "ä¸€é”®å¤åˆ¶ï¼ˆTXTï¼‰", key: str = "copy0"):
    st.code(text or "", language="text")
    components.html(f"""
    <button id="{key}" style="padding:6px 10px;border:1px solid #444;border-radius:8px;cursor:pointer">{label}</button>
    <script>
      const btn = document.getElementById("{key}");
      const payload = {json.dumps(text or "")};
      btn.addEventListener("click", async () => {{
        try {{
          await navigator.clipboard.writeText(payload);
          btn.innerText = "å·²å¤åˆ¶";
        }} catch (e) {{
          btn.innerText = "å¤åˆ¶å¤±è´¥ï¼ˆè¯·æ‰‹åŠ¨ Ctrl+Cï¼‰";
        }}
      }});
    </script>
    """, height=50)


def _tail(path: Path, n: int=400) -> str:
    try:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return "".join(f.readlines()[-n:])
    except Exception:
        return ""


def _fmt_retcols_percent(df):
    df = df.copy()
    cols = [c for c in df.columns if str(c).startswith("ret_fwd_")]
    if not cols:
        return df
    for c in cols:
        # è½¬æˆæ•°å€¼
        s = pd.to_numeric(df[c], errors="coerce")
        finite = s[np.isfinite(s)]
        if finite.shape[0] == 0:
            continue
        q95 = finite.abs().quantile(0.95)
        # å°äºç­‰äº 0.5 è¯´æ˜æ˜¯å°æ•°ï¼ˆä¾‹å¦‚ 0.034ï¼‰ï¼Œéœ€è¦Ã—100
        if pd.notna(q95) and q95 <= 0.5:
            s = s * 100.0
        # ç»Ÿä¸€ä¸¤ä½å°æ•° + ç™¾åˆ†å·
        df[c] = s.map(lambda x: (f"{x:.2f}%" if pd.notna(x) else None))
    return df


def _apply_runtime_overrides(rules_obj: dict,
                             topk: int, tie_break: str, max_workers: int,
                             attn_on: bool, universe: str|List[str]):
    # è§„åˆ™è¦†ç›–é…ç½®
    if rules_obj:
        pres = rules_obj.get("prescreen")
        rules = rules_obj.get("rules")
        if pres is not None: setattr(se, "SC_PRESCREEN_RULES", pres)
        if rules is not None: setattr(se, "SC_RULES", rules)
    setattr(se, "SC_TOP_K", int(topk))
    setattr(se, "SC_TIE_BREAK", str(tie_break))
    setattr(se, "SC_MAX_WORKERS", int(max_workers))
    # setattr(se, "SC_ATTENTION_ENABLE", bool(attn_on))
    setattr(se, "SC_UNIVERSE", universe)


def _humanize_error(err) -> tuple[str, list[str], list[str], str]:
    s = str(err) if not isinstance(err, dict) else str(err.get("error", ""))
    causes, fixes = [], []
    title = "è¿è¡Œå‡ºé”™"

    # ç»“æ„åŒ–åˆ¤æ–­
    if "JSONDecodeError" in s or "Expecting value" in s or "Invalid control character" in s:
        title = "JSON æ ¼å¼é”™è¯¯"
        causes = ["JSON ä¸åˆæ³•ï¼ˆé€—å·/å¼•å·/èŠ±æ‹¬å·/ç»“å°¾é€—å·ç­‰ï¼‰"]
        fixes = ["ç”¨ JSON æ ¡éªŒå·¥å…·æ£€æŸ¥ï¼›å­—æ®µåä¸€å¾‹åŒå¼•å·ï¼›æœ€åä¸€é¡¹ä¸è¦åŠ é€—å·"]
    elif "è¡¨è¾¾å¼é”™è¯¯" in s or "evaluate_bool" in s:
        title = "ç­–ç•¥è¡¨è¾¾å¼è¯­æ³•é”™è¯¯"
        causes = ["æ‹¬å·ä¸é…å¯¹ / å‚æ•°ç¼ºå¤± / ä¸æ”¯æŒçš„å‡½æ•°æˆ–åˆ—å"]
        fixes = ["æ£€æŸ¥æ‹¬å·ä¸é€—å·ï¼›ç¡®è®¤åˆ—åå­˜åœ¨ï¼›å¿…è¦æ—¶ç®€åŒ–è¡¨è¾¾å¼é€æ®µæ’æŸ¥"]
    elif "timeframe" in s or "resample" in s:
        title = "ä¸æ”¯æŒçš„å‘¨æœŸ (timeframe)"
        causes = ["ä¼ å…¥äº†æœªå®ç°çš„å‘¨æœŸ"]
        fixes = ["æ”¹ä¸ºé¡¹ç›®æ”¯æŒçš„ D/W/M/60MIN ç­‰"]
    elif "empty-window" in s or "empty window" in s or "æ— å¯ç”¨æ ‡çš„" in s:
        title = "æ•°æ®çª—å£æ— æ•°æ®"
        causes = ["çª—å£åŒºé—´è¿‡çŸ­æˆ–å‚è€ƒæ—¥æ— äº¤æ˜“æ•°æ®", "æ ‡çš„é€€å¸‚/é•¿æœŸåœç‰Œå¯¼è‡´æ— æ•°æ®"]
        fixes = ["æ‹‰é•¿ windowï¼›æ›´æ¢å‚è€ƒæ—¥ï¼›è°ƒæ•´è‚¡ç¥¨æ± /å¸‚åœºèŒƒå›´"]
    elif "KeyError" in s or "missing" in s or "åˆ—" in s:
        title = "ç¼ºå°‘åˆ—/æŒ‡æ ‡"
        causes = ["è¡¨è¾¾å¼å¼•ç”¨äº†æ•°æ®ä¸­ä¸å­˜åœ¨çš„åˆ—"]
        fixes = ["åœ¨æ•°æ®ä¾§è¡¥åˆ—ï¼Œæˆ–ä½¿ç”¨å†…ç½®å…œåº•ï¼ˆå¦‚ J/VRï¼‰"]
    elif "database is locked" in s or "file is locked" in s or "database is busy" in s or "file is being used" in s or "å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶" in s:
        title = "æ•°æ®åº“è¢«å ç”¨"
        causes = ["å¤šä¸ªè¿›ç¨‹åŒæ—¶è®¿é—®æ•°æ®åº“æ–‡ä»¶", "æ•°æ®åº“æ–‡ä»¶è¢«å…¶ä»–ç¨‹åºé”å®š", "ç³»ç»Ÿèµ„æºä¸è¶³"]
        fixes = ["ç­‰å¾…å…¶ä»–æ“ä½œå®Œæˆ", "é‡å¯åº”ç”¨ç¨‹åº", "æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºåœ¨ä½¿ç”¨æ•°æ®åº“æ–‡ä»¶", "ä½¿ç”¨å†…å­˜æ•°æ®åº“æ¨¡å¼"]

    return title, causes, fixes, s


def show_database_diagnosis():
    """æ˜¾ç¤ºæ•°æ®åº“è¯Šæ–­ä¿¡æ¯"""
    try:
        # è¯Šæ–­åŠŸèƒ½éœ€è¦é‡æ–°å®ç°
        # ä½¿ç”¨ database_manager è·å–è¯Šæ–­ä¿¡æ¯
        logger.info("[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (æ•°æ®åº“è¯Šæ–­)")
        manager = get_database_manager()
        stats = manager.get_stats()
        diagnosis = {
            "database_status": "connected" if stats else "disconnected",
            "queue_size": stats.get("queue_size", 0),
            "worker_count": stats.get("worker_count", 0)
        }
        
        st.subheader("æ•°æ®åº“è¯Šæ–­ä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("æ•°æ®åº“æ–‡ä»¶å­˜åœ¨", "æ˜¯" if diagnosis.get("database_exists") else "å¦")
            st.metric("æ•°æ®åº“æ–‡ä»¶è¢«é”å®š", "æ˜¯" if diagnosis.get("database_locked") else "å¦")
            if diagnosis.get("file_size"):
                st.metric("æ–‡ä»¶å¤§å°", f"{diagnosis['file_size'] / (1024*1024):.1f} MB")
        
        with col2:
            if diagnosis.get("file_permissions"):
                st.metric("æ–‡ä»¶æƒé™", diagnosis["file_permissions"])
            if diagnosis.get("last_modified"):
                import datetime
                last_mod = datetime.datetime.fromtimestamp(diagnosis["last_modified"])
                st.metric("æœ€åä¿®æ”¹", last_mod.strftime("%Y-%m-%d %H:%M:%S"))
        
        # æ˜¾ç¤ºè¿›ç¨‹å ç”¨ä¿¡æ¯
        processes = diagnosis.get("processes_using_db", [])
        if processes:
            st.warning(f"âš ï¸ å‘ç° {len(processes)} ä¸ªè¿›ç¨‹æ­£åœ¨ä½¿ç”¨æ•°æ®åº“æ–‡ä»¶:")
            for proc in processes:
                st.write(f"- PID: {proc['pid']}, è¿›ç¨‹å: {proc['name']}")
        else:
            st.success("âœ… æ²¡æœ‰å‘ç°å…¶ä»–è¿›ç¨‹å ç”¨æ•°æ®åº“æ–‡ä»¶")
        
        if diagnosis.get("database_locked"):
            st.error("æ•°æ®åº“æ–‡ä»¶è¢«é”å®šï¼Œè¿™å¯èƒ½å¯¼è‡´è¡¨è¾¾å¼é€‰è‚¡å¤±è´¥")
            st.info("å»ºè®®ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–åº”ç”¨åœ¨ä½¿ç”¨æ•°æ®åº“æ–‡ä»¶ï¼Œæˆ–é‡å¯ç›¸å…³è¿›ç¨‹")
        
        if st.button("é‡æ–°è¯Šæ–­"):
            st.rerun()
            
    except Exception as e:
        st.error(f"è¯Šæ–­æ•°æ®åº“å¤±è´¥: {e}")


def show_database_status():
    """æ˜¾ç¤ºæ•°æ®åº“è¿æ¥çŠ¶æ€"""
    try:
        # get_data_source_status å·²ä» database_manager å¯¼å…¥
        status = get_data_source_status()
        
        st.subheader("æ•°æ®åº“è¿æ¥çŠ¶æ€")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("æ•°æ®åº“æ–‡ä»¶å­˜åœ¨", "æ˜¯" if status.get("database_file_exists") else "å¦")
            st.metric("æ•°æ®åº“æ–‡ä»¶è¢«é”å®š", "æ˜¯" if status.get("database_file_locked") else "å¦")
            st.metric("ä½¿ç”¨ç»Ÿä¸€æ•°æ®åº“", "æ˜¯" if status.get("use_unified_db") else "å¦")
        
        with col2:
            dispatcher_stats = status.get("dispatcher_stats", {})
            st.metric("å·¥ä½œçº¿ç¨‹æ•°", dispatcher_stats.get("worker_threads", 0))
            st.metric("ç¼“å­˜å¤§å°", dispatcher_stats.get("cache_size", 0))
            st.metric("é˜Ÿåˆ—å¤§å°", dispatcher_stats.get("queue_size", 0))
        
        if status.get("database_file_locked"):
            st.error("âš ï¸ æ•°æ®åº“æ–‡ä»¶è¢«é”å®šï¼Œè¿™å¯èƒ½å¯¼è‡´è¡¨è¾¾å¼é€‰è‚¡å¤±è´¥")
            st.info("å»ºè®®ï¼šç­‰å¾…å…¶ä»–æ“ä½œå®Œæˆæˆ–é‡å¯åº”ç”¨ç¨‹åº")
        
        if st.button("åˆ·æ–°çŠ¶æ€"):
            st.rerun()
            
    except Exception as e:
        st.error(f"æ£€æŸ¥æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")


def _indicator_options(tag: str | None = "product"):
    try:
        # åªåˆ—å‡ºæœ‰ py_func çš„ï¼ˆèƒ½åœ¨æœ¬åœ°ç®—ï¼‰çš„æŒ‡æ ‡å
        names = [k for k, m in getattr(ind, "REGISTRY", {}).items() if getattr(m, "py_func", None)]
        if tag and hasattr(ind, "names_by_tag"):
            tagged = set(ind.names_by_tag(tag))  # åªè¦æ‰“äº† product æ ‡ç­¾çš„
            names = [n for n in names if n in tagged] or names
        return sorted(set(names))
    except Exception:
        # å…œåº•ï¼šä¿æŒç°åœ¨çš„ä¸‰ä¸ª
        return ["kdj", "ma", "macd"]


@cache_data(show_spinner=False, ttl=300)
def _get_rule_names() -> list[str]:
    """è·å–è§„åˆ™åç§°åˆ—è¡¨ï¼Œå¸¦ç¼“å­˜"""
    try:
        rule_names = [str(r.get("name") or f"RULE_{i}") for i, r in enumerate(getattr(se, "SC_RULES", []) or [])]
        return sorted(list(dict.fromkeys(rule_names)))
    except Exception:
        return []

@cache_data(show_spinner=False, ttl=300)
def _cached_load_prediction_rules() -> list[dict]:
    """ç¼“å­˜ç‰ˆæœ¬çš„ load_prediction_rules å‡½æ•°"""
    try:
        return load_prediction_rules()
    except Exception:
        return []

def _apply_tiebreak_sorting(df: pd.DataFrame, tiebreak_mode: str = "none") -> pd.DataFrame:
    """
    å¯¹è‚¡ç¥¨è¡¨æ ¼åº”ç”¨æ’åº
    
    Args:
        df: åŒ…å«ts_codeå’Œscoreåˆ—çš„DataFrame
        tiebreak_mode: æ’åºæ¨¡å¼ ("none", "kdj_j_asc")
    
    Returns:
        æ’åºåçš„DataFrame
    """
    if df.empty or "ts_code" not in df.columns or "score" not in df.columns:
        return df
    
    # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®
    df_sorted = df.copy()
    
    if tiebreak_mode == "kdj_j_asc" and "tiebreak_j" in df_sorted.columns:
        # æŒ‰å¾—åˆ†é™åºï¼ŒåŒåˆ†æ—¶æŒ‰Jå€¼å‡åºï¼Œå†åŒåˆ†æ—¶æŒ‰ä»£ç å‡åºï¼ˆå…œåº•ï¼‰
        df_sorted = df_sorted.sort_values(["score", "tiebreak_j", "ts_code"], ascending=[False, True, True]).reset_index(drop=True)
    else:
        # é»˜è®¤ï¼šåªæŒ‰å¾—åˆ†é™åºæ’åºï¼ŒåŒåˆ†æ—¶æŒ‰ä»£ç å‡åºï¼ˆå…œåº•ï¼‰
        df_sorted = df_sorted.sort_values(["score", "ts_code"], ascending=[False, True]).reset_index(drop=True)
    
    return df_sorted

@cache_data(show_spinner=False, ttl=120)
def _resolve_pred_universe(label: str, ref: str) -> list[str]:
    """
    å°† UI çš„èŒƒå›´æ ‡ç­¾å±•å¼€ä¸º ts_code åˆ—è¡¨ï¼š
    - allï¼šè¯» output/score/all/score_all_<ref>.csvï¼ˆè‹¥æ— ï¼Œåˆ™é€€å› topï¼‰
    - white/blackï¼šè¯» scoring_core çš„ç¼“å­˜åå•
    - attentionï¼šè¯»â€œç‰¹åˆ«å…³æ³¨æ¦œâ€ï¼ˆè‹¥æ‰¾ä¸åˆ°åˆ™å°è¯•æŒ‰æ–‡ä»¶ååŒ¹é…ï¼‰
    """
    label = (label or "").strip().lower()
    codes: list[str] = []

    if label == "all":
        p_all = _path_all(ref)  # è¿™ä¸ªå·¥å…·åœ¨ç°æœ‰æ–‡ä»¶é‡Œå·²å®šä¹‰
        if p_all.exists() and p_all.stat().st_size > 0:
            df = _read_df(p_all, dtype={"ts_code": str})
            if df is not None and not df.empty and "ts_code" in df.columns:
                codes = df["ts_code"].astype(str).tolist()
        if not codes:
            # å…œåº•ç”¨ Topï¼ˆè‡³å°‘ä¸ä¼šæ˜¯ç©ºï¼‰
            p_top = _path_top(ref)
            if p_top.exists() and p_top.stat().st_size > 0:
                df = _read_df(p_top, dtype={"ts_code": str})
                if df is not None and not df.empty and "ts_code" in df.columns:
                    df = df.sort_values(df.columns[0])  # ä»»æ„ç¨³å®šé¡ºåº
                    codes = df["ts_code"].astype(str).tolist()

    elif label in {"white", "black"}:
        try:
            kind = "whitelist" if label == "white" else "blacklist"
            codes = se._read_cache_list_codes(ref, kind) or []
        except Exception:
            codes = []

    elif label == "attention":
        try:
            codes = se._load_attention_codes(ref) or []
        except Exception:
            # é€€å›æŒ‰æ–‡ä»¶åæ‰¾ â€œattention*<ref>.csvâ€
            p = _find_attn_file_by_date(ref)  # è¿™ä¸ªå·¥å…·å·²åœ¨æ–‡ä»¶å†…å®šä¹‰
            if p:
                df = _read_df(p, dtype={"ts_code": str})
                if df is not None and not df.empty:
                    # æ™ºèƒ½è¯†åˆ«åˆ—å
                    for cand in ["ts_code", "code", "ts", "symbol"]:
                        if cand in df.columns:
                            codes = df[cand].astype(str).tolist()
                            break

    # è§„èŒƒåŒ–ã€å»é‡ã€æ’åº
    try:
        codes = [normalize_ts(c) for c in codes if c]
    except Exception:
        codes = [str(c).strip() for c in codes if c]
    return sorted(set(codes))

# ==== å¼ºåº¦æ¦œæ–‡ä»¶å®šä½====
def _pick_latest_attn_date() -> Optional[str]:
    """
    æ‰«æ attention ç›®å½•æ‰€æœ‰ CSVã€‚
    è§„åˆ™ï¼šæŠŠâ€œæ–‡ä»¶åé‡Œæœ€åä¸€æ¬¡å‡ºç°çš„ 8 ä½æ•°å­—â€è§†ä¸ºè¯¥æ–‡ä»¶çš„ç»“æŸæ—¥ï¼›
         è‹¥åŒä¸€ç»“æŸæ—¥æœ‰å¤šä»½ï¼Œåˆ™æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´(mtime)å–æœ€æ–°é‚£ä»½çš„ç»“æŸæ—¥ã€‚
    """
    best_key = None
    best_ref = None
    for p in ATTN_DIR.glob("*.csv"):
        ms = re.findall(r"(\d{8})", p.name)
        if not ms:
            continue
        end = ms[-1]  # è§†ä¸ºç»“æŸæ—¥ï¼ˆæœ€å 8 ä½ï¼‰
        key = (end, p.stat().st_mtime)  # å…ˆæ¯”æ—¥æœŸï¼Œå†æ¯”ä¿®æ”¹æ—¶é—´
        if best_key is None or key > best_key:
            best_key, best_ref = key, end
    return best_ref


def _find_attn_file_by_date(ref: str) -> Optional[Path]:
    """
    æ ¹æ®ç»“æŸæ—¥ ref å®šä½æ–‡ä»¶ï¼š
    - å…ˆæ”¶é›†æ‰€æœ‰åŒ…å«è¯¥ ref çš„ attention CSVï¼›
    - ä¼˜å…ˆâ€œè§„èŒƒåŒ–å‘½åâ€çš„æ–‡ä»¶ï¼ˆä»¥ attention_ å¼€å¤´ä¸”åŒ…å« _win/_topM/_topN è¿™äº›å…³é”®å­—ï¼‰ï¼›
    - å…¶ä½™åˆ™æŒ‰ä¿®æ”¹æ—¶é—´å€’åºä½œä¸ºæ¬¡åºã€‚
    """
    cands = list(ATTN_DIR.glob(f"*attention*{ref}*.csv"))
    if not cands:
        return None

    def _score(p: Path):
        nm = p.name
        normalized = nm.startswith("attention_") and ("_win" in nm or nm == f"attention_{ref}.csv")
        return (1 if normalized else 0, p.stat().st_mtime)

    return sorted(cands, key=_score, reverse=True)[0]

# ---- è¯»å– config çš„ç¨³å¥å·¥å…· ----
def cfg_int(name: str, default: int) -> int:
    val = getattr(cfg, name, default)
    try:
        # è¿‡æ»¤ None / "" ç­‰å¼‚å¸¸å–å€¼
        if val is None or (isinstance(val, str) and val.strip() == ""):
            return int(default)
        return int(val)
    except Exception:
        return int(default)


def cfg_str(name: str, default: str) -> str:
    val = getattr(cfg, name, default)
    if val is None:
        return str(default)
    s = str(val).strip()
    return s if s else str(default)


def cfg_bool(name: str, default: bool) -> bool:
    val = getattr(cfg, name, default)
    if isinstance(val, bool):
        return val
    if val is None:
        return bool(default)
    s = str(val).strip().lower()
    if s in {"1","true","yes","y","on","t"}:
        return True
    if s in {"0","false","no","n","off","f"}:
        return False
    return bool(default)

# é€šç”¨å¤šé˜¶æ®µè¿›åº¦å™¨ï¼ˆç»Ÿä¸€ç®¡ç†å•æ¬¡ä»»åŠ¡çš„è¿›åº¦æ¡+çŠ¶æ€æ—¥å¿—ï¼‰
class Stepper:
    """
    ç”¨æ³•ï¼š
        steps = ["å‡†å¤‡ç¯å¢ƒ", "ä¸‹è½½æºæ•°æ®", "åˆå¹¶å¢é‡", "å†™å‡ºå¯¼å‡º", "è‡ªåŠ¨æ’å"]
        sp = Stepper("ä¸‹è½½/åŒæ­¥", steps, key_prefix="dl_sync")  # æ¯æ¬¡ç‚¹å‡»éƒ½ä¼šç”Ÿæˆç‹¬ç«‹ run_id
        sp.start()

        sp.step("å‡†å¤‡ç¯å¢ƒ")     # åšå‡†å¤‡...
        sp.tick(0.3, "æ ¡éªŒç›®æ ‡ç›®å½•")
        sp.tick(1.0)           # æœ¬æ­¥éª¤æ”¶å°¾

        sp.step("ä¸‹è½½æºæ•°æ®")   # å…·ä½“ä¸‹è½½...
        sp.step("åˆå¹¶å¢é‡")
        sp.step("å†™å‡ºå¯¼å‡º")
        sp.step("è‡ªåŠ¨æ’å", visible=auto_rank)  # æ”¯æŒæŒ‰æ¡ä»¶æ˜¾ç¤º/è·³è¿‡
        sp.finish(success=True, note="å…¨éƒ¨å®Œæˆ")
    """
    def __init__(self, title, steps, key_prefix="stepper"):
        self.title = title
        self.steps_all = steps[:]  # æ–‡æ¡ˆåˆ—è¡¨ï¼ˆå¯å« Noneï¼‰
        self.steps = [s for s in steps if s]  # å®é™…å‚ä¸ç»Ÿè®¡çš„æ­¥éª¤
        self.total = len(self.steps)
        self.key = f"{key_prefix}_{uuid.uuid4().hex[:8]}"
        self._init_state()

    def _init_state(self):
        st.session_state[self.key] = {
            "idx": 0,        # å·²å®Œæˆåˆ°ç¬¬å‡ ä¸ªï¼ˆä» 0 å¼€å§‹ï¼‰
            "run_id": self.key,
        }

    def start(self):
        self.status = st.status(
            label=f"{self.title}ï¼šå¼€å§‹ï¼ˆ0/{self.total}ï¼‰",
            state="running",
        )
        self.prog = st.progress(0, text="å‡†å¤‡ä¸­â€¦")
        with self.status:
            st.write("ğŸŸ¡ å¼€å§‹ä»»åŠ¡â€¦")

    def _update_prog(self, idx, label):
        pct = 0 if self.total == 0 else int(idx / self.total * 100)
        self.prog.progress(pct, text=f"{idx}/{self.total}ï¼š{label}")

    def step(self, label, visible=True, info=None):
        """è¿›å…¥ä¸‹ä¸€ä¸»æ­¥éª¤ï¼›visible=False æ—¶ï¼Œä»…è®°å½•æ—¥å¿—ï¼Œä¸çº³å…¥è¿›åº¦æ¯”ä¾‹"""
        if not visible:
            # ä»…è¿½åŠ æ—¥å¿—æç¤º
            with self.status:
                st.write(f"â­ï¸ è·³è¿‡ï¼š{label}")
            return

        state = st.session_state[self.key]
        state["idx"] += 1
        idx = min(state["idx"], self.total)
        text = label if not info else f"{label}ï½œ{info}"

        with self.status:
            st.write(f"â–¶ï¸ {text}")
        self._update_prog(idx, text)

    def tick(self, delta_ratio, info=None):
        """åœ¨å½“å‰æ­¥éª¤ä¸­æ˜¾ç¤ºç»†ç²’åº¦æ¨è¿›ï¼ˆä¾‹å¦‚å¾ªç¯/åˆ†æ‰¹å¤„ç†ï¼‰"""
        state = st.session_state[self.key]
        # æŒ‰å½“å‰ä¸»æ­¥éª¤ä½ç½® + ç»†åˆ†æ¯”ä¾‹ åˆæˆä¸€ä¸ªæ›´å¹³æ»‘çš„ç™¾åˆ†æ¯”å±•ç¤º
        base = min(state["idx"], self.total - 1)
        now = min(1.0, max(0.0, float(delta_ratio)))
        overall = int(((base + now) / self.total) * 100) if self.total else 0
        self.prog.progress(overall, text=info or "å¤„ç†ä¸­â€¦")
        # åœ¨æ—¥å¿—é‡Œä¹Ÿå¯æ‰“ç‚¹
        if info:
            with self.status:
                st.write(f"â€¦ {info}")

    def finish(self, success=True, note=None):
        if success:
            self.status.update(
                label=f"{self.title}ï¼šå®Œæˆï¼ˆ{self.total}/{self.total}ï¼‰",
                state="complete",
            )
            self.prog.progress(100, text=note or "å®Œæˆ")
        else:
            self.status.update(
                label=f"{self.title}ï¼šå¤±è´¥",
                state="error",
            )


@contextmanager
def pred_progress_to_streamlit():
    if not _in_streamlit():
        # éStreamlitç¯å¢ƒå›è°ƒ
        def _noop(*a, **k): pass
        # ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿæ›¿ä»£åºŸå¼ƒçš„ set_progress_handler
        from log_system import get_logger
        logger = get_logger("predict_core")
        logger.info("ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿè¿›è¡Œè¿›åº¦è·Ÿè¸ª")
        try:
            yield None, None, None
        finally:
            pass
        return

    status = st.status("å‡†å¤‡ä¸­â€¦", expanded=True)
    bar = st.progress(0, text="å°±ç»ª")
    info = st.empty()

    import queue as _q
    _evq = _q.Queue()

    # åå°çº¿ç¨‹åªå…¥é˜Ÿï¼Œä¸ç›´æ¥ç¢° st.*
    def _enqueue_handler(phase, current=None, total=None, message=None, **kw):
        try:
            _evq.put_nowait((phase, current, total, message))
        except Exception:
            pass

    def _render_event(phase, current=None, total=None, message=None):
        txt = {
            "pred_select_ref_date": "é€‰æ‹©å‚è€ƒæ—¥",
            "pred_build_universe_done": "æ„å»ºæ¨¡æ‹Ÿæ¸…å•",
            "pred_start": "æ¨¡æ‹Ÿå¼€å§‹",
            "pred_progress": "æ¨¡æ‹Ÿè¿›è¡Œä¸­",
            "pred_done": "æ¨¡æ‹Ÿå®Œæˆ",
        }.get(phase, phase)
        
        # ä½¿ç”¨messageä½œä¸ºä¸»è¦æ˜¾ç¤ºå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨txt
        display_text = message if message else txt
        
        if total and current is not None:
            pct = int(current * 100 / max(total, 1))
            bar.progress(pct, text=f"{display_text} ({current}/{total})")
        else:
            bar.progress(0, text=display_text)

    # ä¸»çº¿ç¨‹æ¶ˆè´¹ï¼šä¾› run_prediction_in_bg å¾ªç¯è°ƒç”¨
    def _drain():
        try:
            while True:
                ev = _evq.get_nowait()
                _render_event(*ev)
        except _q.Empty:
            pass

    # ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿæ›¿ä»£åºŸå¼ƒçš„ set_progress_handler
    from log_system import get_logger
    logger = get_logger("predict_core")
    logger.info("ä½¿ç”¨æ–°çš„æ—¥å¿—ç³»ç»Ÿè¿›è¡Œè¿›åº¦è·Ÿè¸ª")
    _orig_drain = getattr(pr, "drain_progress_events", None)
    pr.drain_progress_events = _drain  # å…³é”®ï¼šæŠŠ"æŠ½å¹²"æ›¿æ¢æˆä¸»çº¿ç¨‹æ¸²æŸ“

    try:
        yield status, bar, info
    finally:
        # è¿˜åŸ drainï¼ˆä¿æŒæ¨¡å—æ•´æ´ï¼‰
        if callable(_orig_drain):
            pr.drain_progress_events = _orig_drain
        else:
            pr.drain_progress_events = lambda: None


def run_prediction_in_bg(inp):
    with pred_progress_to_streamlit() as (status, bar, info):
        done = threading.Event()
        result = {"df": None, "err": None}
        def _worker():
            try:
                # ä½¿ç”¨å®‰å…¨çš„æ•°æ®åº“æ“ä½œ
                from predict_core import run_prediction
                result["df"] = run_prediction(inp)
            except Exception as e:
                result["err"] = e
            finally:
                done.set()
        t = threading.Thread(target=_worker, daemon=True)
        t.start()

        while not done.is_set():
            # æ¶ˆè´¹ predict_core çš„è¿›åº¦äº‹ä»¶ï¼ˆå¦‚æœå†…éƒ¨ä½¿ç”¨äº‹ä»¶é˜Ÿåˆ—çš„è¯ï¼‰
            try:
                pr.drain_progress_events()
            except Exception:
                pass
            time.sleep(0.05)
        # æŠ½å¹²å‰©ä½™äº‹ä»¶
        try:
            pr.drain_progress_events()
        except Exception:
            pass
        if status is not None:
            status.update(label="å·²å®Œæˆ", state="complete")
        if result["err"]:
            raise result["err"]
        return result["df"]

# ===== ä¸»uiéƒ¨åˆ† =====
if _in_streamlit():
    # ===== é¡µçœ‰ =====
    st.title("ScoreApp")
    

    # === Global portfolio state (added by assistant) ===
    if "cur_pid" not in st.session_state:
        st.session_state["cur_pid"] = None
    if "cur_pf" not in st.session_state:
        st.session_state["cur_pf"] = None

    # Local aliases for convenience across tabs
    cur_pid = st.session_state.get("cur_pid")
    cur_pf  = st.session_state.get("cur_pf")
    # === End global portfolio state ===

    if "rules_obj" not in st.session_state:
        st.session_state["rules_obj"] = {
            # "prescreen": getattr(cfg, "SC_PRESCREEN_RULES", []),
            # "rules": getattr(cfg, "SC_RULES", []),
            "prescreen": getattr(se, "SC_PRESCREEN_RULES", []),
            "rules": getattr(se, "SC_RULES", []),
        }
    if "export_pref" not in st.session_state:
        st.session_state["export_pref"] = {"style": "space", "with_suffix": True}

    # ===== é¡¶å±‚é¡µç­¾ =====
    tab_rank, tab_detail, tab_position, tab_predict, tab_rules, tab_attn, tab_screen, tab_tools, tab_port, tab_stats, tab_data_view, tab_logs, = st.tabs(
        ["æ’å", "ä¸ªè‚¡è¯¦æƒ…", "æŒä»“å»ºè®®", "æ˜æ—¥æ¨¡æ‹Ÿ", "è§„åˆ™ç¼–è¾‘", "å¼ºåº¦æ¦œ", "é€‰è‚¡", "å·¥å…·ç®±", "ç»„åˆæ¨¡æ‹Ÿ/æŒä»“", "ç»Ÿè®¡", "æ•°æ®ç®¡ç†", "æ—¥å¿—"])

    # ================== æ’å ==================
    with tab_rank:
        st.subheader("æ’å")
        with st.expander("å‚æ•°è®¾ç½®ï¼ˆè¿è¡Œå‰è¯·ç¡®è®¤ï¼‰", expanded=True):
            c1, c2, c3, c4 = st.columns([1,1,1,1])
            with c1:
                ref_inp = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°ï¼‰", value="", key="rank_ref_input")
                topk = st.number_input("Top-K", min_value=1, max_value=2000, value=cfg_int("SC_TOP_K", 50))
            with c2:
                tie_default = cfg_str("SC_TIE_BREAK", "none").lower()
                tie = st.selectbox("åŒåˆ†æ’åºï¼ˆTie-breakï¼‰", ["none", "kdj_j_asc"], index=0 if tie_default=="none" else 1)
                maxw = st.number_input("æœ€å¤§å¹¶è¡Œæ•°", min_value=1, max_value=64, value=cfg_int("SC_MAX_WORKERS", 8))
            with c3:
                universe = st.selectbox("è¯„åˆ†èŒƒå›´", ["å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•"], index=0)
                style = st.selectbox("TXT å¯¼å‡ºæ ¼å¼", ["ç©ºæ ¼åˆ†éš”", "ä¸€è¡Œä¸€ä¸ª"], index=0)
            with c4:
                attn_on = False
                with_suffix = st.checkbox("å¯¼å‡ºå¸¦äº¤æ˜“æ‰€åç¼€ï¼ˆ.SZ/.SHï¼‰", value=False)
            st.session_state["export_pref"] = {"style": "space" if style=="ç©ºæ ¼åˆ†éš”" else "lines",
                                            "with_suffix": with_suffix}
            run_col1, run_col2 = st.columns([1,1])
            with run_col1:
                run_btn = st.button("ğŸš€ è¿è¡Œè¯„åˆ†ï¼ˆå†™å…¥ Top/All/Detailsï¼‰", width='stretch')
            with run_col2:
                latest_btn = st.button("ğŸ“… è¯»å–æœ€è¿‘ä¸€æ¬¡ç»“æœï¼ˆä¸é‡æ–°è®¡ç®—ï¼‰", width='stretch')

        # è¿è¡Œ
        ref_to_use = ref_inp.strip() or _pick_smart_ref_date()
        if run_btn:
            # ç¦ç”¨detailsæ•°æ®åº“è¯»å–ï¼Œé¿å…å†™å…¥å†²çª
            st.session_state["details_db_reading_enabled"] = False
            logger.info(f"ç”¨æˆ·ç‚¹å‡»è¿è¡Œè¯„åˆ†æŒ‰é’®: å‚è€ƒæ—¥={ref_to_use}, TopK={topk}, å¹¶è¡Œæ•°={maxw}, èŒƒå›´={universe}ï¼Œå·²ç¦ç”¨detailsæ•°æ®åº“è¯»å–")
            
            # å…³é—­detailsæ•°æ®åº“çš„è¿æ¥æ± ï¼Œæ–­å¼€æ‰€æœ‰è¿æ¥
            try:
                manager = get_database_manager()
                if manager:
                    details_db_path = get_details_db_path_with_fallback()
                    if details_db_path:
                        manager.close_db_pools(details_db_path)
                        logger.info(f"å·²å…³é—­detailsæ•°æ®åº“è¿æ¥æ± : {details_db_path}")
            except Exception as e:
                logger.warning(f"å…³é—­detailsæ•°æ®åº“è¿æ¥æ± æ—¶å‡ºé”™: {e}")
            
            _apply_runtime_overrides(st.session_state["rules_obj"], topk, tie, maxw, attn_on,
                                    {"å…¨å¸‚åœº":"all","ä»…ç™½åå•":"white","ä»…é»‘åå•":"black","ä»…ç‰¹åˆ«å…³æ³¨æ¦œ":"attention"}[universe])
            try:
                top_path = run_se_run_for_date_in_bg(ref_inp.strip() or None)
                st.success(f"è¯„åˆ†å®Œæˆï¼š{top_path}")
                # è§£æå‚è€ƒæ—¥
                m = re.search(r"(\d{8})", str(top_path))
                if m:
                    ref_to_use = m.group(1)
                    if latest_btn and not ref_to_use:
                        ref_to_use = _pick_smart_ref_date()
            except Exception as e:
                st.error(f"è¯„åˆ†å¤±è´¥ï¼š{e}")
                ref_to_use = None

        # "è¯»å–æœ€è¿‘ä¸€æ¬¡ç»“æœ"æŒ‰é’®ï¼šä»…è¯»å–ï¼Œä¸è®¡ç®—
        if latest_btn and not run_btn:
            ref_to_use = _get_latest_date_from_files()

        # ---- ç»Ÿä¸€çš„ Top é¢„è§ˆåŒºå—ï¼ˆæ— è®º run æˆ– è¯»å–æœ€è¿‘ä¸€æ¬¡ï¼‰ ----
        if ref_to_use:
            # è·å–æœ€æ–°æ’åæ–‡ä»¶æ—¥æœŸå’Œæ•°æ®åº“æœ€æ–°æ—¥æœŸç”¨äºå¯¹æ¯”
            latest_rank_date = _get_latest_date_from_files()
            db_latest_date = _get_latest_date_from_database()
            
            # æ˜¾ç¤ºä¸‰ä¸ªæ—¥æœŸçš„å¯¹æ¯”
            col1, col2, col3 = st.columns(3)
            with col1:
                if latest_rank_date:
                    st.markdown(f"**æœ€æ–°æ’åæ–‡ä»¶ï¼š{latest_rank_date}**")
                else:
                    st.markdown("**æœ€æ–°æ’åæ–‡ä»¶ï¼šæœªçŸ¥**")
            with col2:
                st.markdown(f"**å½“å‰æ˜¾ç¤ºæ’åï¼š{ref_to_use}**")
            with col3:
                if db_latest_date:
                    st.markdown(f"**æ•°æ®åº“æœ€æ–°æ—¥æœŸï¼š{db_latest_date}**")
                else:
                    st.markdown("**æ•°æ®åº“æœ€æ–°æ—¥æœŸï¼šæœªçŸ¥**")
            
            # å¦‚æœæœ‰æ—¥æœŸå·®å¼‚ï¼Œç»™å‡ºæç¤º
            if latest_rank_date and latest_rank_date != ref_to_use:
                st.info(f"å½“å‰æ˜¾ç¤ºçš„æ˜¯ {ref_to_use} çš„æ’åï¼Œæœ€æ–°æ’åæ–‡ä»¶æ˜¯ {latest_rank_date}")
            
            if db_latest_date and db_latest_date != ref_to_use:
                if db_latest_date > ref_to_use:
                    st.warning(f"æ’åæ•°æ®æ—¥æœŸï¼ˆ{ref_to_use}ï¼‰æ—©äºæ•°æ®åº“æœ€æ–°æ—¥æœŸï¼ˆ{db_latest_date}ï¼‰ï¼Œå»ºè®®é‡æ–°è¿è¡Œè¯„åˆ†è·å–æœ€æ–°æ’å")
                else:
                    st.info(f"æ’åæ•°æ®æ—¥æœŸï¼ˆ{ref_to_use}ï¼‰æ™šäºæ•°æ®åº“æœ€æ–°æ—¥æœŸï¼ˆ{db_latest_date}ï¼‰ï¼Œæ’åæ•°æ®åŸºäºè¾ƒæ–°çš„æ•°æ®")
            
            df_all = _read_df(_path_all(ref_to_use))
        else:
            st.info("æœªæ‰¾åˆ°ä»»ä½• Top æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè¯„åˆ†æˆ–æ£€æŸ¥è¾“å‡ºç›®å½•ã€‚")

        st.divider()

        with st.container(border=True):
            st.markdown("**Top-K é¢„è§ˆ**")
            show_mode = st.radio("å±•ç¤ºæ–¹å¼", ["é™åˆ¶æ¡æ•°", "æ˜¾ç¤ºå…¨éƒ¨"], horizontal=True, key="topk_show_mode")
            rows_to_show = None
            if show_mode == "é™åˆ¶æ¡æ•°":
                rows_to_show = st.number_input("Top-K æ˜¾ç¤ºè¡Œæ•°", min_value=5, max_value=1000, value=cfg_int("SC_TOPK_ROWS", 30), key="topk_rows_cfg")
            if ref_to_use and df_all is not None and not df_all.empty:
                if show_mode == "æ˜¾ç¤ºå…¨éƒ¨":
                    rows_eff = len(df_all)
                    st.caption(f"å·²é€‰æ‹©æ˜¾ç¤ºå…¨éƒ¨ï¼ˆå…± {rows_eff} è¡Œï¼‰ã€‚")
                else:
                    rows_eff = int(rows_to_show)
                st.dataframe(df_all.head(rows_eff), width='stretch', height=420)
                if "ts_code" in df_all.columns:
                    codes = df_all["ts_code"].astype(str).head(rows_eff).tolist()
                    txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"], st.session_state["export_pref"]["with_suffix"])
                    copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶ä»¥ä¸Šï¼ˆæŒ‰å½“å‰é¢„è§ˆï¼‰", key=f"copy_top_{ref_to_use}")
            else:
                st.caption("æš‚æ—  Top-K æ•°æ®")

    # ================== ä¸ªè‚¡è¯¦æƒ… ==================
    with tab_detail:
        st.subheader("ä¸ªè‚¡è¯¦æƒ…")

        # â€”â€” æ•°æ®åº“è¯»å–æ§åˆ¶æŒ‰é’® â€”â€”
        db_reading_enabled = is_details_db_reading_enabled()
        col_db_ctrl1, col_db_ctrl2 = st.columns([3, 1])
        with col_db_ctrl1:
            if db_reading_enabled:
                st.success("âœ… æ•°æ®åº“è¯»å–å·²å¯ç”¨ï¼ˆæ•°æ®å°†ä»æ•°æ®åº“è¯»å–ï¼‰")
            else:
                st.info("â„¹ï¸ æ•°æ®åº“è¯»å–æœªå¯ç”¨ï¼ˆé¿å…ä¸å†™å…¥æ“ä½œå†²çªï¼‰")
        with col_db_ctrl2:
            if not db_reading_enabled:
                if st.button("ğŸ”“ å¯ç”¨æ•°æ®åº“è¯»å–", key="enable_db_reading"):
                    st.session_state["details_db_reading_enabled"] = True
                    st.rerun()
            else:
                # ä¸€æ—¦å¯ç”¨å°±ä¸å†æ˜¾ç¤ºæŒ‰é’®ï¼Œä¿æŒå¯ç”¨çŠ¶æ€
                pass
        
        st.divider()

        # â€”â€” é€‰æ‹©å‚è€ƒæ—¥ + ä»£ç ï¼ˆæ”¯æŒä» Top-K ä¸‹æ‹‰é€‰æ‹©ï¼‰ â€”â€”
        c0, c1 = st.columns([1,2])
        with c0:
            ref_d = st.text_input("å‚è€ƒæ—¥ï¼ˆç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="", key="detail_ref_input")
        ref_real = (ref_d or "").strip() or _get_latest_date_from_files() or ""
        # è¯»å–è¯¥å‚è€ƒæ—¥ Top æ–‡ä»¶ä»¥ä¾¿ä¸‹æ‹‰é€‰æ‹©
        try:
            # åˆ·æ–°ç¼“å­˜
            if ref_real:
                top_path = _path_top(ref_real)
                if top_path.exists():
                    # æ¸…é™¤å¯èƒ½çš„ç¼“å­˜
                    if hasattr(_read_df, 'clear'):
                        _read_df.clear()
                    df_top_ref = _read_df(top_path)
                else:
                    df_top_ref = pd.DataFrame()
            else:
                df_top_ref = pd.DataFrame()
                
            options_codes = df_top_ref["ts_code"].astype(str).tolist() if ("ts_code" in df_top_ref.columns and not df_top_ref.empty) else []
            st.caption(f"è°ƒè¯•: å‚è€ƒæ—¥={ref_real}, TopKæ–‡ä»¶è¡Œæ•°={len(df_top_ref)}, å¯é€‰è‚¡ç¥¨æ•°={len(options_codes)}")
        except Exception as e:
            options_codes = []
            st.caption(f"è°ƒè¯•: è¯»å–TopKæ–‡ä»¶å¤±è´¥: {e}")
        with c1:
            # ç¡®ä¿options_codesä¸ä¸ºç©ºï¼Œä¸”indexæœ‰æ•ˆ
            if options_codes:
                code_from_list = st.selectbox("ä» Top-K é€‰æ‹©ï¼ˆå¯é€‰ï¼‰", options=options_codes,
                                            index=0, placeholder="ä¹Ÿå¯æ‰‹åŠ¨è¾“å…¥ â†“", key="detail_code_from_top")
            else:
                # å½“æ²¡æœ‰TopKæ•°æ®æ—¶ï¼Œæä¾›ä¸€ä¸ªé»˜è®¤é€‰é¡¹ä½†ä¸ç¦ç”¨
                code_from_list = st.selectbox("ä» Top-K é€‰æ‹©ï¼ˆå¯é€‰ï¼‰", options=[""],
                                            index=0, placeholder="æš‚æ— Top-Kæ•°æ®ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ â†“", 
                                            key="detail_code_from_top")

        # åˆå§‹åŒ–session_state
        if 'detail_last_code' not in st.session_state:
            st.session_state.detail_last_code = ""
        
        # ç¡®å®šé»˜è®¤æ˜¾ç¤ºçš„ä»£ç 
        default_code = ""
        if st.session_state.detail_last_code:
            # å¦‚æœæœ‰å†å²è®°å½•ï¼Œä½¿ç”¨å†å²è®°å½•
            default_code = st.session_state.detail_last_code
        elif options_codes:
            # å¦‚æœæ²¡æœ‰å†å²è®°å½•ä½†æœ‰Top-Kæ•°æ®ï¼Œä½¿ç”¨ç¬¬ä¸€å
            default_code = options_codes[0]
        
        # å§‹ç»ˆæ˜¾ç¤ºæ‰‹åŠ¨è¾“å…¥æ¡†ï¼ˆå¹³çº§è¾“å…¥æ–¹å¼ï¼‰
        code_typed = st.text_input("æˆ–æ‰‹åŠ¨è¾“å…¥è‚¡ç¥¨ä»£ç ", 
                                 value=default_code,
                                 key="detail_code_input")

        # â€”â€” å¹³çº§åˆå¹¶é€»è¾‘ï¼šè°å˜åŒ–ç”¨è° â€”â€”
        if 'detail_prev_select' not in st.session_state:
            st.session_state.detail_prev_select = ""
        if 'detail_prev_input' not in st.session_state:
            st.session_state.detail_prev_input = ""

        cur_select = (code_from_list or "").strip()
        cur_input  = (code_typed or "")
        changed_select = bool(cur_select) and (cur_select != st.session_state.detail_prev_select)
        changed_input  = (cur_input != st.session_state.detail_prev_input)

        if changed_select:
            effective_code = cur_select
        elif changed_input:
            effective_code = cur_input
        else:
            # äºŒè€…éƒ½æœªå˜åŒ–æ—¶ï¼Œå–å½“å‰éç©ºè¾“å…¥ï¼›å†å…œåº•é»˜è®¤
            effective_code = cur_input or cur_select or default_code

        # è®°å½•å½“å‰å€¼ï¼Œä¾›ä¸‹ä¸€æ¬¡å¯¹æ¯”
        st.session_state.detail_prev_select = cur_select
        st.session_state.detail_prev_input = cur_input

        # æ›´æ–°å†å²è®°å½•
        if effective_code and effective_code.strip() != "":
            st.session_state.detail_last_code = effective_code
        
        code_norm = normalize_ts(effective_code) if effective_code else ""

        # â€”â€” æ¸²æŸ“è¯¦æƒ…ï¼ˆå« old ç‰ˆåŠŸèƒ½ï¼‰ â€”â€”
        if code_norm and ref_real:
            obj = _load_detail_json(ref_real, code_norm)
            if not obj:
                st.warning("æœªæ‰¾åˆ°è¯¥ç¥¨çš„è¯¦æƒ…æ•°æ®(è¯·æ£€æŸ¥æ•°æ®åº“æ˜¯å¦è§£é”ä»¥åŠæ˜¯å¦å†™å…¥)ã€‚")
            else:
                data = obj
                # å…¼å®¹æ•°æ®åº“æ ¼å¼å’ŒJSONæ ¼å¼
                if "summary" in data:
                    # ç»Ÿä¸€æ ¼å¼ï¼š{ts_code, ref_date, summary: {...}, rules}
                    summary = data.get("summary", {}) or {}
                    ts = data.get("ts_code", code_norm)
                else:
                    # å…¼å®¹æ—§æ ¼å¼ï¼š{ts_code, ref_date, score, highlights, drawbacks, opportunities, rules, ...}
                    summary = {
                        "score": data.get("score", 0.0),
                        "tiebreak": data.get("tiebreak"),
                        "highlights": data.get("highlights", []),
                        "drawbacks": data.get("drawbacks", []),
                        "opportunities": data.get("opportunities", []),
                        "rank": data.get("rank"),
                        "total": data.get("total")
                    }
                    ts = data.get("ts_code", code_norm)
                
                # æ˜¾ç¤ºæ•°æ®æ¥æºä¿¡æ¯ï¼ˆåªæœ‰åœ¨å…è®¸è¯»å–æ•°æ®åº“æ—¶æ‰æŸ¥è¯¢æ•°æ®åº“çŠ¶æ€ï¼‰
                db_reading_enabled = is_details_db_reading_enabled()
                if db_reading_enabled:
                    try:
                        # ä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°è·å–detailsæ•°æ®åº“è·¯å¾„ï¼ˆåŒ…å«å›é€€é€»è¾‘ï¼‰
                        details_db_path = get_details_db_path_with_fallback()
                        if details_db_path:
                            # æŸ¥è¯¢è‚¡ç¥¨è¯¦æƒ…è¡¨
                            logger.info(f"[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (æŸ¥è¯¢è‚¡ç¥¨è¯¦æƒ…: {code_norm}, {ref_real})")
                            manager = get_database_manager()
                            sql = "SELECT * FROM stock_details WHERE ts_code = ? AND ref_date = ?"
                            df = manager.execute_sync_query(details_db_path, sql, [code_norm, ref_real], timeout=30.0)
                            
                            if not df.empty:
                                st.info("æ•°æ®æ¥æºï¼šæ•°æ®åº“")
                            else:
                                st.info("æ•°æ®æ¥æºï¼šJSONæ–‡ä»¶")
                        else:
                            st.info("æ•°æ®æ¥æºï¼šJSONæ–‡ä»¶")
                    except:
                        st.info("æ•°æ®æ¥æºï¼šJSONæ–‡ä»¶")
                else:
                    st.info("æ•°æ®æ¥æºï¼šJSONæ–‡ä»¶ï¼ˆæ•°æ®åº“è¯»å–æœªå¯ç”¨ï¼‰")
                
                try:
                    score = float(summary.get("score", 0))
                    if not np.isfinite(score):
                        score = 0.0
                except Exception:
                    score = 0.0
                # è®¡ç®—å½“æ—¥æ’åï¼ˆä¼˜å…ˆ JSON â†’ å…¨é‡CSV â†’ Top-K å›é€€ï¼‰
                rank_display = "â€”"
                r_json = summary.get("rank")
                t_json = summary.get("total")
                if isinstance(r_json, (int, float)) and int(r_json) > 0:
                    rank_display = f"{int(r_json)}" + (f" / {int(t_json)}" if isinstance(t_json, (int, float)) and int(t_json) > 0 else "")
                else:
                    all_path = _path_all(ref_real)
                    if all_path.exists():
                        try:
                            df_allx = _read_df(all_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                            if not df_allx.empty:
                                row = df_allx.loc[df_allx["ts_code"].astype(str) == str(ts)]
                                if not row.empty and "rank" in row.columns:
                                    rank_display = f"{int(row['rank'].iloc[0])} / {len(df_allx)}"
                        except Exception:
                            pass
                    # 2) è‹¥å…¨é‡æ— æœï¼Œå›é€€åˆ° Top æ–‡ä»¶ï¼šæŒ‰è¡Œå·è¿‘ä¼¼åæ¬¡
                    if rank_display == "â€”":
                        top_path = _path_top(ref_real)
                        if top_path.exists():
                            try:
                                df_topx = _read_df(top_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                                if not df_topx.empty:
                                    if "rank" not in df_topx.columns:
                                        df_topx = df_topx.reset_index(drop=True)
                                        df_topx["rank"] = np.arange(1, len(df_topx) + 1)
                                    row = df_topx.loc[df_topx["ts_code"].astype(str) == str(ts)]
                                    if not row.empty and "rank" in row.columns:
                                        rank_display = f"{int(row['rank'].iloc[0])} / {len(df_topx)}"
                            except Exception:
                                pass
                            try:
                                df_topx = pd.read_csv(top_path, dtype={"ts_code": str}, encoding="utf-8-sig")
                                pos = df_topx.index[df_topx["ts_code"].astype(str) == str(ts)]
                                if len(pos) > 0:
                                    rank_display = str(int(pos[0]) + 1)
                            except Exception:
                                pass

                # æ€»è§ˆ + é«˜äº®/ç¼ºç‚¹ï¼ˆç¾åŒ–æ˜¾ç¤ºï¼‰
                colA, colB = st.columns([1,1])
                with colA:
                    st.markdown("**æ€»è§ˆ**")
                    # ç¾åŒ–æ˜¾ç¤ºsummaryå†…å®¹
                    with st.container(border=True):
                        # åŸºæœ¬ä¿¡æ¯
                        st.metric("ä»£ç ", ts)
                        st.metric("å¸‚åœº", market_label(ts))
                        st.metric("å‚è€ƒæ—¥", ref_real)
                        st.divider()
                        # è¯„åˆ†ä¿¡æ¯
                        if "score" in summary:
                            st.metric("åˆ†æ•°", f"{summary.get('score', 0.0):.2f}")
                        if "tiebreak" in summary and summary.get("tiebreak") is not None:
                            st.metric("KDJ-J", f"{summary.get('tiebreak', 0.0):.2f}")
                        if "rank" in summary and summary.get("rank") is not None:
                            total = summary.get("total", 0)
                            rank_val = summary.get("rank", 0)
                            if total > 0:
                                st.metric("æ’å", f"{rank_val} / {total}")
                            else:
                                st.metric("æ’å", str(rank_val))
                        # æ˜¾ç¤ºå…¶ä»–summaryå­—æ®µ
                        other_fields = {k: v for k, v in summary.items() 
                                      if k not in ["score", "tiebreak", "rank", "total", "highlights", "drawbacks", "opportunities"]}
                        if other_fields:
                            with st.expander("å…¶ä»–ä¿¡æ¯", expanded=False):
                                for key, value in other_fields.items():
                                    st.text(f"{key}: {value}")
                with colB:
                    st.markdown("**é«˜äº® / ç¼ºç‚¹**")
                    # ç¾åŒ–æ˜¾ç¤ºhighlightså’Œdrawbacks
                    with st.container(border=True):
                        highlights = summary.get("highlights", [])
                        drawbacks = summary.get("drawbacks", [])
                        
                        if highlights:
                            st.markdown("**âœ… é«˜äº®**")
                            for h in highlights:
                                if h:
                                    st.success(f"â€¢ {h}")
                        
                        if drawbacks:
                            st.markdown("**âš ï¸ ç¼ºç‚¹**")
                            for d in drawbacks:
                                if d:
                                    st.error(f"â€¢ {d}")
                        
                        if not highlights and not drawbacks:
                            st.caption("æš‚æ— ")

                # äº¤æ˜“æ€§æœºä¼š
                ops = (summary.get("opportunities") or [])
                with st.expander("äº¤æ˜“æ€§æœºä¼š", expanded=True):
                    if ops:
                        for t in ops:
                            st.write("â€¢ " + str(t))
                    else:
                        st.caption("æš‚æ— ")

                # é€è§„åˆ™æ˜ç»†ï¼ˆå¯é€‰æ˜¾ç¤º whenï¼‰
                # ruleså­—æ®µå·²ç»é€šè¿‡_load_detail_jsonç»Ÿä¸€è§£æä¸ºlist[dict]æ ¼å¼
                rules_list = data.get("rules", [])
                if not isinstance(rules_list, list):
                    rules_list = []
                rules = pd.DataFrame(rules_list)
                name_to_when = {}
                
                from datetime import datetime
                import re

                if not rules.empty:
                    
                    def _days_from_ref(d: str | None) -> int | None:
                        if isinstance(d, str) and re.fullmatch(r"\d{8}", d):
                            return (datetime.strptime(ref_real, "%Y%m%d") - datetime.strptime(d, "%Y%m%d")).days
                        return None

                    if not rules.empty:
                        def _pick_last_hit_days(row):
                            # å…ˆçœ‹ lag æ˜¯å¦æœ‰å€¼ï¼ˆä»… RECENT/DIST/NEARï¼‰
                            lag = row.get("lag")
                            if pd.notna(lag):
                                try:
                                    return int(lag)
                                except Exception:
                                    pass
                            # å¦åˆ™å›è½åˆ° hit_date â†’ å¤©æ•°
                            return _days_from_ref(row.get("hit_date"))

                        rules["last_hit_days"] = rules.apply(_pick_last_hit_days, axis=1)
                        # å¯é€‰ï¼šæ˜¾ç¤ºæ›´å¹²å‡€ï¼ˆæ”¯æŒç©ºå€¼ï¼‰
                        rules["last_hit_days"] = rules["last_hit_days"].astype("Int64")
                try:
                    for r in (getattr(se, "SC_RULES", []) or []):
                        if "clauses" in r and r["clauses"]:
                            ws = [c.get("when","") for c in r["clauses"] if c.get("when")]
                            name_to_when[str(r.get("name","<unnamed>"))] = " AND ".join(ws)
                        else:
                            name_to_when[str(r.get("name","<unnamed>"))] = str(r.get("when",""))
                except Exception:
                    name_to_when = {}
                
                # åˆ›å»ºnameåˆ°explainçš„æ˜ å°„ï¼ˆä»ç­–ç•¥ä»“åº“ä¸­è·å–ï¼‰
                name_to_explain = {}
                try:
                    for r in (getattr(se, "SC_RULES", []) or []):
                        rule_name = str(r.get("name", ""))
                        if rule_name:
                            explain_val = r.get("explain")
                            if explain_val:
                                name_to_explain[rule_name] = str(explain_val)
                except Exception:
                    name_to_explain = {}
                show_when = st.checkbox("æ˜¾ç¤ºè§„åˆ™ when è¡¨è¾¾å¼", value=False, key="detail_show_when")
                if not rules.empty:
                    if show_when:
                        rules["when"] = rules["name"].map(name_to_when).fillna("")
                    st.markdown("**è§„åˆ™æ˜ç»†**")
                    
                    # åˆ›å»ºç”¨äºæ˜¾ç¤ºçš„DataFrameå‰¯æœ¬
                    rules_display = rules.copy()
                    
                    # ä»ç­–ç•¥ä»“åº“ä¸­è·å–explainï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
                    if "name" in rules_display.columns:
                        # æ·»åŠ explainåˆ—ï¼ˆä»ç­–ç•¥ä»“åº“ä¸­è·å–ï¼‰
                        if "explain" not in rules_display.columns:
                            rules_display["explain"] = rules_display["name"].map(lambda n: name_to_explain.get(str(n), ""))
                        else:
                            # å¦‚æœæ•°æ®åº“ä¸­æœ‰explainåˆ—ï¼Œä½†å¯èƒ½ä¸ºç©ºï¼Œåˆ™ä»ç­–ç•¥ä»“åº“è¡¥å……
                            rules_display["explain"] = rules_display.apply(
                                lambda row: row.get("explain") if pd.notna(row.get("explain")) and str(row.get("explain")).strip() 
                                else name_to_explain.get(str(row.get("name", "")), ""), axis=1
                            )
                    
                    # ä½¿ç”¨streamlit dataframeæ˜¾ç¤ºï¼Œä¿ç•™åŸç”Ÿäº¤äº’åŠŸèƒ½ï¼ˆæ’åºã€ç­›é€‰ç­‰ï¼‰
                    # ç¡®ä¿åˆ—é¡ºåºï¼šnameåœ¨æœ€å‰ï¼Œexplainåœ¨æœ€åï¼ˆå¦‚æœæœ‰ï¼‰
                    col_order = ["name"]
                    for col in rules_display.columns:
                        if col not in ["name", "explain"]:
                            col_order.append(col)
                    # explainåˆ—æ”¾åœ¨æœ€åï¼ˆå¦‚æœæœ‰ï¼‰
                    if "explain" in rules_display.columns:
                        col_order.append("explain")
                    col_order = [c for c in col_order if c in rules_display.columns]
                    rules_display = rules_display[col_order]
                    
                    # é…ç½®åˆ—çš„æ˜¾ç¤ºæ–¹å¼ï¼ˆå¦‚æœexplainå­˜åœ¨ï¼Œä¸ºnameåˆ—æ·»åŠ helpæç¤ºï¼‰
                    column_config = None
                    if "explain" in rules_display.columns and "name" in rules_display.columns:
                        try:
                            # å°è¯•ä½¿ç”¨column_configé…ç½®ï¼ˆstreamlit >= 1.23.0æ”¯æŒï¼‰
                            column_config = {}
                            # nameåˆ—çš„é…ç½®ï¼Œæç¤ºç”¨æˆ·å¯ä»¥æŸ¥çœ‹explainåˆ—
                            column_config["name"] = st.column_config.TextColumn(
                                "ç­–ç•¥åç§°",
                                help="ç­–ç•¥çš„ç®€çŸ­åç§°ï¼Œè¯¦ç»†è¯´æ˜è§å³ä¾§explainåˆ—"
                            )
                            # explainåˆ—çš„é…ç½®ï¼Œè¯´æ˜è¿™æ˜¯è¯¦ç»†è¯´æ˜
                            column_config["explain"] = st.column_config.TextColumn(
                                "è¯¦ç»†è¯´æ˜",
                                help="ç­–ç•¥çš„è¯¦ç»†è¯´æ˜ï¼ˆé¼ æ ‡æ‚¬æµ®åœ¨æ­¤åˆ—æ ‡é¢˜ä¸Šå¯æŸ¥çœ‹æç¤ºï¼‰",
                                width="medium"
                            )
                        except Exception:
                            # å¦‚æœcolumn_configä¸æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤æ–¹å¼
                            column_config = None
                    
                    # æ˜¾ç¤ºstreamlit dataframeï¼Œä¿ç•™æ‰€æœ‰åŸç”Ÿäº¤äº’åŠŸèƒ½
                    st.dataframe(
                        rules_display,
                        width='stretch',
                        height=420,
                        hide_index=True,
                        column_config=column_config
                    )
                else:
                    st.info("æ— è§„åˆ™æ˜ç»†ã€‚")
                # st.markdown('<div id="rank_rule_anchor"></div>', unsafe_allow_html=True)
                st.markdown('<div id="detail_rule_anchor_detail"></div>', unsafe_allow_html=True)

    # ================== æŒä»“å»ºè®® ==================
    with tab_position:
        st.subheader("æŒä»“å»ºè®®ï¼ˆä¸ªè‚¡ï¼‰")
        with st.expander("è¾“å…¥", expanded=True):
            c1, c2, c3 = st.columns([1,1,1])
            with c1:
                pos_ref = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°ï¼‰", value="", key="pos_ref_input")
                price_mode = st.selectbox("ä¹°ç‚¹æ¥æº", ["æŒ‰æ—¥æœŸå–ä»·", "ç­–ç•¥å–ä»·ï¼ˆå¯é€‰ï¼‰", "æ‰‹å·¥è¾“å…¥"], index=0)
            with c2:
                raw_code = st.text_input("è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒå¤šç§å†™æ³•ï¼‰", value="", key="pos_code_input")
                price_field = st.selectbox("ä»·æ ¼å£å¾„", ["å¼€ç›˜ä»·(open)", "æ”¶ç›˜ä»·(close)", "æœ€é«˜ä»·(high)", "æœ€ä½ä»·(low)"], index=0)
            with c3:
                # recompute_opts = st.multiselect("ä»…é‡ç®—éœ€è¦çš„æŒ‡æ ‡", ["kdj","ma","macd"], default=["kdj"], key="pos_recompute_indicators")
                recalc_mode_pos = st.radio("æŒ‡æ ‡é‡ç®—", ["è‡ªé€‰", "å…¨éƒ¨(all)", "ä¸é‡ç®—(none)"],
                                        index=0, horizontal=True, key="pos_recalc_mode")
                if recalc_mode_pos == "è‡ªé€‰":
                    recompute_opts = st.multiselect("ä»…é‡ç®—éœ€è¦çš„æŒ‡æ ‡",
                                                    _indicator_options(),
                                                    default=["kdj"],
                                                    key="pos_recompute_pick")
                    recompute_to_pass = tuple(recompute_opts) if recompute_opts else ("kdj",)
                elif recalc_mode_pos == "å…¨éƒ¨(all)":
                    recompute_to_pass = "all"
                else:
                    recompute_to_pass = "none"

                use_virtual = st.checkbox("åŸºäºâ€œæ˜æ—¥è™šæ‹Ÿæ—¥â€æ£€æŸ¥ï¼ˆå‹¾é€‰åæŒ‰ä¸‹æ–¹åœºæ™¯ï¼‰", value=False)

            # åœºæ™¯å‚æ•°ï¼ˆä»…å½“ use_virtualï¼‰
            scen = Scenario()
            if use_virtual:
                # with st.expander("æ˜æ—¥æƒ…æ™¯å‚æ•°", expanded=False):
                with st.container(border=True):
                    st.markdown("**æ˜æ—¥æƒ…æ™¯å‚æ•°**")
                    cc1, cc2, cc3 = st.columns([1,1,1])
                    with cc1:
                        scen_mode = st.selectbox("ä»·æ ¼æ¨¡å¼", ["close_pct","open_pct","gap_then_close_pct","flat","limit_up","limit_down"], index=0)
                        pct = st.number_input("æ¶¨è·Œå¹… pctï¼ˆ%ï¼‰", value=2.0, step=0.5, format="%.2f")
                        gap_pct = st.number_input("è·³ç©º gap_pctï¼ˆ%ï¼‰", value=0.0, step=0.5, format="%.2f")
                    with cc2:
                        vol_mode = st.selectbox("é‡èƒ½æ¨¡å¼", ["same","pct","mult"], index=2)
                        vol_arg = st.number_input("é‡èƒ½å‚æ•°ï¼ˆ% æˆ– å€æ•°ï¼‰", value=1.2, step=0.1, format="%.2f")
                        hl_mode = st.selectbox("é«˜ä½ç”Ÿæˆ", ["follow","atr_like","range_pct"], index=0)
                    with cc3:
                        range_pct = st.number_input("range_pctï¼ˆ%ï¼‰", value=2.0, step=0.5, format="%.2f")
                        atr_mult = st.number_input("atr_mult", value=1.0, step=0.1, format="%.2f")
                        lock_hi_open = st.checkbox("é”å®šæ”¶ç›˜é«˜äºå¼€ç›˜", value=False)
                    scen = Scenario(mode=scen_mode, pct=pct, gap_pct=gap_pct, vol_mode=vol_mode, vol_arg=vol_arg,
                                    hl_mode=hl_mode, range_pct=range_pct, atr_mult=atr_mult,
                                    lock_higher_than_open=lock_hi_open)

            # ä¹°ç‚¹æ¥æº
            entry_price = None
            # ç»Ÿä¸€å‚è€ƒæ—¥
            try:
                trade_dates = get_trade_dates()
                latest_ref = trade_dates[-1] if trade_dates else ""
            except Exception:
                latest_ref = ""
            ref_use = pos_ref.strip() or latest_ref

            code_norm = normalize_ts(raw_code.strip()) if raw_code.strip() else ""
            if price_mode == "æŒ‰æ—¥æœŸå–ä»·":
                sel_date = st.text_input("ä¹°ç‚¹æ—¥æœŸï¼ˆYYYYMMDDï¼‰", value=ref_use, key="pos_entry_date")
                if st.button("å–ä»·", width='stretch'):
                    if code_norm and sel_date:
                        try:
                            # è¯»å–è¯¥æ—¥çš„ä»·æ ¼
                            try:
                                from config import DATA_ROOT, UNIFIED_DB_PATH
                                db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                                df = query_stock_data(
                                    db_path=db_path,
                                    ts_code=code_norm,
                                    start_date=sel_date,
                                    end_date=sel_date,
                                    adj_type="qfq"
                                )
                            except:
                                # å›é€€åˆ°ç›´æ¥æŸ¥è¯¢
                                from config import DATA_ROOT, UNIFIED_DB_PATH
                                db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                                logger.info(f"[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (å›é€€æŸ¥è¯¢å•æ—¥æ•°æ®: {code_norm}, {sel_date})")
                                manager = get_database_manager()
                                sql = "SELECT * FROM stock_data WHERE ts_code = ? AND trade_date = ?"
                                df = manager.execute_sync_query(db_path, sql, [code_norm, sel_date], timeout=30.0)
                            if not df.empty:
                                row = df.sort_values("trade_date").iloc[-1]
                                fld = {"å¼€ç›˜ä»·(open)":"open","æ”¶ç›˜ä»·(close)":"close","æœ€é«˜ä»·(high)":"high","æœ€ä½ä»·(low)":"low"}[price_field]
                                entry_price = float(row[fld])
                                st.success(f"ä¹°ç‚¹={entry_price:.4f}")
                            else:
                                st.warning("è¯¥æ—¥æ— æ•°æ®")
                        except Exception as e:
                            st.error(f"å–ä»·å¤±è´¥ï¼š{e}")
            elif price_mode == "æ‰‹å·¥è¾“å…¥":
                entry_price = st.number_input("æ‰‹å·¥è¾“å…¥ä¹°ç‚¹", value=0.0, step=0.01, format="%.4f")
            else:
                # ç­–ç•¥å–ä»·ï¼ˆå¯é€‰ï¼‰
                opps = load_opportunity_policies()
                names = [r.get("name","") for r in opps]
                if not names:
                    st.info("æš‚æ— â€œä¹°ç‚¹ç­–ç•¥ï¼ˆä¸ªè‚¡ï¼‰â€å¯ç”¨ï¼Œè¯·åœ¨ strategies_repo.py å¡«å†™ OPPORTUNITY_POLICIESã€‚")
                opp_name = st.selectbox("é€‰æ‹©ä¹°ç‚¹ç­–ç•¥", names, index=0 if names else None)
                lookback_days = st.number_input("å›çœ‹å¤©æ•°", min_value=30, max_value=1000, value=180)
                if st.button("æŒ‰ç­–ç•¥å–æœ€è¿‘ä¸€æ¬¡è§¦å‘æ—¥å¹¶å®šä»·", width='stretch', disabled=not (code_norm and names)):
                    try:
                        start = (datetime.strptime(ref_use, "%Y%m%d") - timedelta(days=int(lookback_days))).strftime("%Y%m%d")
                        try:
                            from config import DATA_ROOT, UNIFIED_DB_PATH
                            db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                            df = query_stock_data(
                                db_path=db_path,
                                ts_code=code_norm,
                                start_date=start,
                                end_date=ref_use,
                                adj_type="qfq"
                            )
                        except:
                            # å›é€€åˆ°ç›´æ¥æŸ¥è¯¢
                            from config import DATA_ROOT, UNIFIED_DB_PATH
                            db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                            logger.info(f"[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (å›é€€æŸ¥è¯¢æ—¥æœŸèŒƒå›´æ•°æ®: {code_norm}, {start}~{ref_use})")
                            manager = get_database_manager()
                            sql = "SELECT * FROM stock_data WHERE ts_code = ? AND trade_date >= ? AND trade_date <= ?"
                            df = manager.execute_sync_query(db_path, sql, [code_norm, start, ref_use], timeout=30.0)
                        df = df.sort_values("trade_date")
                        if df.empty:
                            st.warning("æ— æ•°æ®")
                        else:
                            # è¡¨è¾¾å¼è¿è¡Œ
                            expr = next((r.get("when") or r.get("check") or "" for r in opps if r.get("name")==opp_name), "")
                            if not expr:
                                st.warning("ç­–ç•¥æ²¡æœ‰ when/check è¡¨è¾¾å¼")
                            else:
                                # è®¡ç®—æŒ‡æ ‡ï¼ˆæ‰©å±•æ•°æ®ï¼‰
                                try:
                                    # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                                    df['open'] = pd.to_numeric(df['open'], errors='coerce')
                                    df['high'] = pd.to_numeric(df['high'], errors='coerce')
                                    df['low'] = pd.to_numeric(df['low'], errors='coerce')
                                    df['close'] = pd.to_numeric(df['close'], errors='coerce')
                                    df['vol'] = pd.to_numeric(df['vol'], errors='coerce')
                                    
                                    # è®¡ç®—KDJæŒ‡æ ‡
                                    if 'j' in expr.lower():
                                        df['j'] = ind.kdj(df)
                                    
                                    # æ‰©å±•ctxï¼ŒåŒ…å«æŒ‡æ ‡
                                    ctx = {}
                                    for col in df.columns:
                                        if col.lower() not in ['trade_date', 'ts_code', 'adj_factor']:
                                            try:
                                                ctx[col.upper()] = pd.to_numeric(df[col], errors='coerce').values
                                            except:
                                                pass
                                    
                                    # å¦‚æœctxä¸ºç©ºï¼Œä½¿ç”¨åŸºç¡€OHLCV
                                    if not ctx:
                                        ctx = {
                                            "OPEN": df["open"].astype(float).values,
                                            "HIGH": df["high"].astype(float).values,
                                            "LOW": df["low"].astype(float).values,
                                            "CLOSE": df["close"].astype(float).values,
                                            "V": df["vol"].astype(float).values,
                                        }
                                    
                                    # è®¾ç½®EXTRA_CONTEXTä»¥ä¾¿GET_LAST_CONDITION_PRICEç­‰å‡½æ•°ä½¿ç”¨
                                    original_ctx_df = None
                                    try:
                                        from tdx_compat import EXTRA_CONTEXT
                                        original_ctx_df = EXTRA_CONTEXT.get("DF")
                                        # åˆ›å»ºåŒ…å«æ‰€æœ‰åˆ—çš„DataFrame
                                        ctx_df = pd.DataFrame(ctx)
                                        # ç¡®ä¿åˆ—åå°å†™ï¼ˆtdx_compatéœ€è¦ï¼‰
                                        ctx_df.columns = ctx_df.columns.str.lower()
                                        EXTRA_CONTEXT["DF"] = ctx_df
                                    except:
                                        pass
                                    
                                    try:
                                        # ä½¿ç”¨evaluate_boolè¯„ä¼°è¡¨è¾¾å¼
                                        sig = tdx.evaluate_bool(expr, pd.DataFrame(ctx))
                                    finally:
                                        # æ¢å¤åŸå§‹EXTRA_CONTEXT
                                        if original_ctx_df is not None:
                                            try:
                                                from tdx_compat import EXTRA_CONTEXT
                                                EXTRA_CONTEXT["DF"] = original_ctx_df
                                            except:
                                                pass
                                    idx = [i for i, v in enumerate(sig) if bool(v)]
                                    if not idx:
                                        st.info("å›çœ‹æœŸå†…æ— è§¦å‘")
                                    else:
                                        last_i = idx[-1]
                                        row = df.iloc[last_i]
                                        fld = {"å¼€ç›˜ä»·(open)":"open","æ”¶ç›˜ä»·(close)":"close","æœ€é«˜ä»·(high)":"high","æœ€ä½ä»·(low)":"low"}[price_field]
                                        entry_price = float(row[fld])
                                        st.success(f"è§¦å‘æ—¥ {row['trade_date']}ï¼Œä¹°ç‚¹={entry_price:.4f}")
                                except Exception as e2:
                                    st.error(f"è®¡ç®—å¤±è´¥ï¼š{e2}")
                                    import traceback
                                    st.code(traceback.format_exc())
                    except Exception as e:
                        st.error(f"ç­–ç•¥å–ä»·å¤±è´¥ï¼š{e}")

        # é€‰æ‹©â€œæŒä»“æ£€æŸ¥ç­–ç•¥ï¼ˆä¸ªè‚¡ï¼‰â€
        pos_rules = load_position_policies()
        pos_names = [r.get("name","") for r in pos_rules]
        selected = st.multiselect("é€‰æ‹©è¦æ£€æŸ¥çš„ç­–ç•¥", pos_names, default=pos_names)
        selected_rules = [r for r in pos_rules if r.get("name") in set(selected)]

        if st.button("æ‰§è¡Œæ£€æŸ¥", width='stretch', disabled=not (code_norm and ref_use and selected_rules)):
            try:
                # å†³å®š entry_price
                ep = float(entry_price) if entry_price else None
                if ep is None:
                    st.warning("è¯·å…ˆè®¾ç½®ä¹°ç‚¹ï¼ˆä¸Šé¢çš„ã€å–ä»·ã€‘æˆ–æ‰‹å·¥è¾“å…¥ï¼‰ã€‚")
                else:
                    pci = PositionCheckInput(
                        ref_date=ref_use,
                        ts_code=code_norm,
                        rules=selected_rules,
                        entry_price=ep,
                        use_scenario=bool(use_virtual),
                        scenario=scen if use_virtual else None,
                        # recompute_indicators=tuple(recompute_opts) if recompute_opts else ("kdj",),
                        recompute_indicators=recompute_to_pass,
                        extra_vars=None
                    )
                    tbl = run_position_checks(pci)
                    st.dataframe(tbl, width='stretch')
                    # å¯¼å‡º
                    csv = tbl.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("å¯¼å‡º CSV", data=csv, file_name=f"position_checks_{code_norm}_{ref_use}.csv", mime="text/csv", width='stretch')
            except Exception as e:
                st.error(f"æ‰§è¡Œå¤±è´¥ï¼š{e}")

    # ================== æ˜æ—¥æ¨¡æ‹Ÿ ==================
    with tab_predict:
        st.subheader("æ˜æ—¥æ¨¡æ‹Ÿ")
        
        # æ˜æ—¥æ¨¡æ‹Ÿ
        # ä½¿ç”¨ st.form é˜²æ­¢å‚æ•°å˜åŒ–æ—¶ç«‹å³åˆ·æ–°UI
        with st.form("prediction_form"):
            with st.expander("è¾“å…¥å‚æ•°", expanded=True):
                c1, c2 = st.columns([1,1])
                with c1:
                    pred_ref = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°äº¤æ˜“æ—¥ï¼‰", value="", key="pred_ref_input")
                    if not pred_ref.strip():
                        # æ˜¾ç¤ºå½“å‰ä¼šè‡ªåŠ¨ä½¿ç”¨çš„å‚è€ƒæ—¥
                        auto_ref = _pick_smart_ref_date()
                        if auto_ref:
                            st.caption(f"ğŸ’¡ å°†è‡ªåŠ¨ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥: {auto_ref}")
                        else:
                            st.caption("âš ï¸ æ— æ³•è‡ªåŠ¨è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
                    use_rule_scen = st.checkbox("ä½¿ç”¨è§„åˆ™å†…ç½®åœºæ™¯ï¼ˆè‹¥è§„åˆ™æä¾›ï¼‰", value=False)
                    expr_text = st.text_input("ä¸´æ—¶æ£€æŸ¥è¡¨è¾¾å¼ï¼ˆå¯ç•™ç©ºï¼‰", value="")
                    # recompute_opts = st.multiselect("ä»…é‡ç®—éœ€è¦çš„æŒ‡æ ‡", ["kdj","ma","macd"], default=["kdj"], key="pred_recompute_indicators")
                    recalc_mode_pred = st.radio("æŒ‡æ ‡é‡ç®—", ["è‡ªé€‰", "å…¨éƒ¨(all)", "ä¸é‡ç®—(none)"],
                                                index=0, horizontal=True, key="pred_recalc_mode")
                    if recalc_mode_pred == "è‡ªé€‰":
                        recompute_opts = st.multiselect("ä»…é‡ç®—éœ€è¦çš„æŒ‡æ ‡",
                                                        _indicator_options(),
                                                        default=["kdj"],
                                                        key="pred_recompute_pick")
                        recompute_to_pass = tuple(recompute_opts) if recompute_opts else ("kdj",)
                    elif recalc_mode_pred == "å…¨éƒ¨(all)":
                        recompute_to_pass = "all"
                    else:
                        recompute_to_pass = "none"
                with c2:
                    uni_choice_pred = st.selectbox(
                        "é€‰è‚¡èŒƒå›´",
                        ["è‡ªå®šä¹‰ï¼ˆä¸‹æ–¹æ–‡æœ¬ï¼‰","å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•","ä»…ç‰¹åˆ«å…³æ³¨æ¦œ"],
                        index=0, key="pred_uni_choice")
                    # æ–‡æœ¬æ¡†ä»…åœ¨"è‡ªå®šä¹‰"æ—¶ä½¿ç”¨
                    pasted = st.text_area("é€‰è‚¡èŒƒå›´ï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šç©ºæ ¼ã€æ¢è¡Œã€é€—å·ã€åˆ†å·ã€ç«–çº¿ç­‰ï¼›å¯æ··åˆ ts_code / ç®€å†™ï¼‰", height=120, placeholder="ä¾‹ï¼š\n000001.SZ 600000.SH 000001\næˆ–ï¼š\n000001.SZ,600000.SH;000001|300001", disabled=(not uni_choice_pred.startswith("è‡ªå®šä¹‰")) )
            # with st.expander("å…¨å±€åœºæ™¯ï¼ˆè‹¥æœªä½¿ç”¨è§„åˆ™å†…ç½®åœºæ™¯åˆ™ç”Ÿæ•ˆï¼‰", expanded=False):
            with st.container(border=True):
                st.markdown("**å…¨å±€åœºæ™¯ï¼ˆè‹¥æœªä½¿ç”¨è§„åˆ™å†…ç½®åœºæ™¯åˆ™ç”Ÿæ•ˆï¼‰**")
                cc1, cc2, cc3 = st.columns([1,1,1])
                with cc1:
                    scen_mode = st.selectbox("ä»·æ ¼æ¨¡å¼", ["close_pct","open_pct","gap_then_close_pct","flat","limit_up","limit_down","reverse_indicator"], index=0)
                    pct = st.number_input("æ¶¨è·Œå¹… pctï¼ˆ%ï¼‰", value=2.0, step=0.5, format="%.2f")
                    gap_pct = st.number_input("è·³ç©º gap_pctï¼ˆ%ï¼‰", value=0.0, step=0.5, format="%.2f")
                with cc2:
                    vol_mode = st.selectbox("é‡èƒ½æ¨¡å¼", ["same","pct","mult"], index=2)
                    vol_arg = st.number_input("é‡èƒ½å‚æ•°ï¼ˆ% æˆ– å€æ•°ï¼‰", value=1.2, step=0.1, format="%.2f")
                    hl_mode = st.selectbox("é«˜ä½ç”Ÿæˆ", ["follow","atr_like","range_pct"], index=0)
                with cc3:
                    range_pct = st.number_input("range_pctï¼ˆ%ï¼‰", value=2.0, step=0.5, format="%.2f")
                    atr_mult = st.number_input("atr_mult", value=1.0, step=0.1, format="%.2f")
                    lock_hi_open = st.checkbox("é”å®šæ”¶ç›˜é«˜äºå¼€ç›˜", value=False)
            
            # åæ¨æ¨¡å¼å‚æ•°é…ç½®
            if scen_mode == "reverse_indicator":
                with st.container(border=True):
                    st.markdown("**åæ¨æ¨¡å¼å‚æ•°**")
                    rc1, rc2, rc3 = st.columns([1,1,1])
                    with rc1:
                        reverse_indicator = st.selectbox("æŒ‡æ ‡åç§°", ["j", "rsi", "ma", "macd", "diff"], index=0)
                        reverse_target_value = st.number_input("ç›®æ ‡æŒ‡æ ‡å€¼", value=10.0, step=0.1, format="%.2f")
                    with rc2:
                        reverse_method = st.selectbox("æ±‚è§£æ–¹æ³•", ["optimize", "binary_search", "grid_search"], index=0)
                        reverse_tolerance = st.number_input("æ±‚è§£ç²¾åº¦", value=1e-6, step=1e-7, format="%.2e")
                    with rc3:
                        reverse_max_iterations = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", value=1000, step=100, min_value=100, max_value=10000)
                        st.caption("åæ¨æ¨¡å¼è¯´æ˜ï¼šæ ¹æ®ç›®æ ‡æŒ‡æ ‡å€¼åæ¨ä»·æ ¼æ•°æ®")
            
            # è§„åˆ™é€‰æ‹©ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            rules = _cached_load_prediction_rules()
            names = [r.get("name","") for r in rules]
            chosen = st.multiselect("é€‰æ‹©æ¨¡æ‹Ÿç­–ç•¥ï¼ˆå¯ç•™ç©ºï¼‰", names, default=[])
            chosen_rules = [r for r in rules if r.get("name") in set(chosen)]
            
            # Tie-breakæ’åºé€‰æ‹©
            tiebreak_pred = st.selectbox("åŒåˆ†æ’åº", ["none", "kdj_j_asc"], index=1, key="pred_tiebreak")

            # æäº¤æŒ‰é’®
            submitted = st.form_submit_button("è¿è¡Œæ˜æ—¥æ¨¡æ‹Ÿ", width='stretch')
        
        # åªæœ‰åœ¨è¡¨å•æäº¤æ—¶æ‰æ‰§è¡Œè®¡ç®—
        if submitted:
            # å‚è€ƒæ—¥ä¸ä»£ç é›† - ä½¿ç”¨æ™ºèƒ½è·å–å‡½æ•°
            ref_use = pred_ref.strip() or _pick_smart_ref_date() or ""

            # è§£æç²˜è´´çš„æ–‡æœ¬èŒƒå›´ - æ”¯æŒç©ºæ ¼å’Œå„ç§åˆ†éš”ç¬¦çš„å…¼å®¹ç‰ˆæœ¬
            def _parse_codes(txt: str):
                out = []
                if not txt:
                    return out
                
                # æ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šæ¢è¡Œã€ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€é€—å·ã€åˆ†å·ã€ç«–çº¿
                import re
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²ï¼Œæ”¯æŒå¤šç§åˆ†éš”ç¬¦
                separators = r'[\s\n\r\t,;|]+'
                codes = re.split(separators, txt)
                
                for code in codes:
                    s = code.strip()
                    if not s:
                        continue
                    try:
                        out.append(normalize_ts(s))
                    except Exception:
                        continue
                # å»é‡
                return sorted(set([x for x in out if x]))
            uni = _parse_codes(pasted)

            # åˆ›å»ºScenarioå¯¹è±¡ï¼Œæ ¹æ®æ¨¡å¼åŒ…å«ä¸åŒå‚æ•°
            if scen_mode == "reverse_indicator":
                scen = Scenario(
                    mode=scen_mode, 
                    pct=pct, 
                    gap_pct=gap_pct, 
                    vol_mode=vol_mode, 
                    vol_arg=vol_arg,
                    hl_mode=hl_mode, 
                    range_pct=range_pct, 
                    atr_mult=atr_mult,
                    lock_higher_than_open=lock_hi_open,
                    # åæ¨æ¨¡å¼å‚æ•°
                    reverse_indicator=reverse_indicator,
                    reverse_target_value=reverse_target_value,
                    reverse_method=reverse_method,
                    reverse_tolerance=reverse_tolerance,
                    reverse_max_iterations=reverse_max_iterations
                )
            else:
                scen = Scenario(
                    mode=scen_mode, 
                    pct=pct, 
                    gap_pct=gap_pct, 
                    vol_mode=vol_mode, 
                    vol_arg=vol_arg,
                    hl_mode=hl_mode, 
                    range_pct=range_pct, 
                    atr_mult=atr_mult,
                    lock_higher_than_open=lock_hi_open
                )

            _uni_map = {"å…¨å¸‚åœº": "all", "ä»…ç™½åå•": "white", "ä»…é»‘åå•": "black", "ä»…ç‰¹åˆ«å…³æ³¨æ¦œ": "attention"}
            use_codes = uni_choice_pred.startswith("è‡ªå®šä¹‰")
            if use_codes:
                uni_arg = uni  # ç²˜è´´çš„è‡ªå®šä¹‰åˆ—è¡¨ï¼Œå‰é¢å·² normalize å»é‡
            else:
                uni_label = _uni_map.get(uni_choice_pred, "all")
                uni_arg = _resolve_pred_universe(uni_label, ref_use)

            # åªæœ‰å½“ ref æœ‰æ•ˆä¸”èŒƒå›´"éç©º"æ—¶æ‰å…è®¸è¿è¡Œ
            can_run = bool(ref_use) and bool(uni_arg)

            # å¯é€‰ï¼šä¸ºç©ºæ—¶ç»™ä¸ªæç¤º
            if not use_codes and not uni_arg:
                st.info(f"ã€{uni_choice_pred}ã€‘åœ¨ {ref_use} æ— å¯ç”¨ä»£ç æºï¼Œè¯·å…ˆåœ¨\"æ’å\"é¡µç­¾ç”Ÿæˆå½“æ—¥ all/top æ–‡ä»¶æˆ–æ£€æŸ¥åå•ç¼“å­˜ã€‚")
            
            if use_codes:
                if uni_arg:
                    st.success(f"âœ… è‡ªå®šä¹‰åå•è§£ææˆåŠŸï¼šå…± {len(uni_arg)} åªè‚¡ç¥¨")
                    # æ˜¾ç¤ºå‰å‡ åªè‚¡ç¥¨ä½œä¸ºé¢„è§ˆ
                    preview_codes = uni_arg[:5]
                    st.caption(f"é¢„è§ˆï¼š{', '.join(preview_codes)}{'...' if len(uni_arg) > 5 else ''}")
                else:
                    st.warning("âš ï¸ è‡ªå®šä¹‰åå•ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥çš„è‚¡ç¥¨ä»£ç æ ¼å¼")
                    st.caption("æ”¯æŒçš„æ ¼å¼ï¼š000001ã€000001.SZã€SZ000001ã€600000.SH ç­‰ï¼›æ”¯æŒåˆ†éš”ç¬¦ï¼šç©ºæ ¼ã€æ¢è¡Œã€é€—å·ã€åˆ†å·ã€ç«–çº¿")

            if can_run:
                try:
                    inp = PredictionInput(
                        ref_date=ref_use,
                        universe=uni_arg,
                        scenario=scen,
                        rules=chosen_rules if chosen_rules else None,
                        expr=(expr_text or None),
                        use_rule_scenario=bool(use_rule_scen),
                        # recompute_indicators=tuple(recompute_opts) if recompute_opts else ("kdj",),
                        recompute_indicators=recompute_to_pass,
                        cache_dir="cache/sim_pred"
                    )
                    # df = run_prediction(inp)
                    df = run_prediction_in_bg(inp)
                    # åº”ç”¨Tie-breakæ’åº
                    df_sorted = _apply_tiebreak_sorting(df, tiebreak_pred)
                    
                    # æ˜¾ç¤ºç»“æœä¿¡æ¯
                    if not df_sorted.empty:
                        st.caption(f"å‘½ä¸­ {len(df_sorted)} åªï¼›å‚è€ƒæ—¥ï¼š{ref_use}")
                        if 'score' in df_sorted.columns and df_sorted['score'].notna().any():
                            st.caption("å·²æŒ‰å¾—åˆ†æ’åºï¼ˆé™åºï¼‰ï¼ŒåŒåˆ†æ—¶æŒ‰Jå€¼å‡åº")
                        else:
                            st.caption("æœªæ‰¾åˆ°å¾—åˆ†æ•°æ®ï¼ŒæŒ‰é»˜è®¤æ’åº")
                    
                    st.dataframe(df_sorted, width='stretch')
                    
                    # å¤åˆ¶ä»£ç åŠŸèƒ½ï¼ˆä¸é€‰è‚¡é¡µé¢ä¿æŒä¸€è‡´ï¼‰
                    if not df_sorted.empty and "ts_code" in df_sorted.columns:
                        codes = df_sorted["ts_code"].astype(str).tolist()
                        txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"], 
                                          st.session_state["export_pref"]["with_suffix"])
                        copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶å‘½ä¸­ä»£ç ", key=f"copy_prediction_{ref_use}")
                    
                    # ä¸‹è½½
                    csv = df_sorted.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("å¯¼å‡º CSV", data=csv, file_name=f"prediction_hits_{ref_use}.csv", mime="text/csv", width='stretch')
                    # ä»…å¯¼å‡ºä»£ç  TXT
                    if not df_sorted.empty:
                        codes_txt = "\n".join(df_sorted["ts_code"].astype(str).tolist())
                        st.download_button("å¯¼å‡ºä»£ç TXTï¼ˆä»…å‘½ä¸­é›†ï¼‰", data=codes_txt, file_name=f"prediction_hits_{ref_use}.txt", mime="text/plain", width='stretch')
                except Exception as e:
                    st.error(f"è¿è¡Œå¤±è´¥ï¼š{e}")
                    with st.expander("è°ƒè¯•ä¿¡æ¯", expanded=False):
                        st.write(f"""
**é”™è¯¯è¯¦æƒ…ï¼š**
- å‚è€ƒæ—¥ï¼š{ref_use}
- è‚¡ç¥¨æ•°é‡ï¼š{len(uni_arg) if uni_arg else 0}
- è‚¡ç¥¨åˆ—è¡¨ï¼š{uni_arg[:10] if uni_arg else 'æ— '}
- åœºæ™¯æ¨¡å¼ï¼š{scen_mode}
- è§„åˆ™æ•°é‡ï¼š{len(chosen_rules) if chosen_rules else 0}
- è¡¨è¾¾å¼ï¼š{expr_text or 'æ— '}

**å¯èƒ½çš„åŸå› ï¼š**
1. è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ­£ç¡®
2. å‚è€ƒæ—¥æ— äº¤æ˜“æ•°æ®
3. è‚¡ç¥¨åœ¨å‚è€ƒæ—¥åœç‰Œæˆ–é€€å¸‚
4. è§„åˆ™è¡¨è¾¾å¼æœ‰è¯­æ³•é”™è¯¯
5. æ•°æ®æ–‡ä»¶ç¼ºå¤±æˆ–æŸå

**å»ºè®®ï¼š**
1. æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆå¦‚ï¼š000001.SZï¼‰
2. å°è¯•ä½¿ç”¨å…¶ä»–å‚è€ƒæ—¥
3. æ£€æŸ¥è§„åˆ™è¡¨è¾¾å¼è¯­æ³•
4. ç¡®è®¤æ•°æ®æ–‡ä»¶å®Œæ•´æ€§
                        """)
            else:
                st.warning("è¯·æ£€æŸ¥å‚æ•°è®¾ç½®ï¼Œç¡®ä¿å‚è€ƒæ—¥å’Œé€‰è‚¡èŒƒå›´éƒ½æœ‰æ•ˆ")

    # ================== è§„åˆ™ç¼–è¾‘è¾…åŠ©æ¨¡å— ==================
    with tab_rules:
        render_rule_editor()
        
        st.markdown("---")
        
        # ================== ç­–ç•¥è¯­æ³•æ£€æŸ¥ ==================
        st.subheader("ç­–ç•¥è¯­æ³•æ£€æŸ¥å™¨")
        st.info("è‡ªåŠ¨æ£€æŸ¥æœ¬åœ°ç­–ç•¥æ–‡ä»¶çš„è¯­æ³•é”™è¯¯ã€å¿…å¡«å­—æ®µã€è¡¨è¾¾å¼æœ‰æ•ˆæ€§ç­‰")
        
        with st.expander("ä½¿ç”¨æ–¹æ³• / å­—æ®µè¯´æ˜", expanded=False):
            st.markdown("""
            **ç­–ç•¥è¯­æ³•æ£€æŸ¥å™¨åŠŸèƒ½ï¼š**
            
            1. **è‡ªåŠ¨æ–‡ä»¶å®šä½** - è‡ªåŠ¨æ‰«æå¹¶å®šä½ç­–ç•¥æ–‡ä»¶
            2. **è¯­æ³•éªŒè¯** - éªŒè¯ç­–ç•¥è§„åˆ™çš„è¯­æ³•å’Œå­—æ®µæœ‰æ•ˆæ€§
            3. **è¡¨è¾¾å¼æ£€æŸ¥** - æ£€æŸ¥TDXè¡¨è¾¾å¼çš„æ­£ç¡®æ€§
            4. **å­—æ®µéªŒè¯** - æ£€æŸ¥å¿…å¡«å­—æ®µå’Œå­—æ®µç±»å‹
            5. **æŒ‡æ ‡æ£€æŸ¥** - éªŒè¯æŒ‡æ ‡ä¾èµ–å…³ç³»
            
            **æ”¯æŒçš„ç­–ç•¥ç±»å‹ï¼š**
            - æ’åç­–ç•¥ (ranking)
            - ç­›é€‰ç­–ç•¥ (filter)  
            - æ¨¡æ‹Ÿç­–ç•¥ (prediction)
            - æŒä»“ç­–ç•¥ (position)
            - ä¹°ç‚¹ç­–ç•¥ (opportunity)
            
            **æ£€æŸ¥å†…å®¹ï¼š**
            - âœ… Pythonæ–‡ä»¶è¯­æ³•æ­£ç¡®æ€§
            - âœ… ç­–ç•¥åˆ—è¡¨ç»“æ„æ­£ç¡®æ€§
            - âœ… æ¯ä¸ªè§„åˆ™çš„å­—æ®µå’Œè¡¨è¾¾å¼
            - âœ… å¿…å¡«å­—æ®µå®Œæ•´æ€§
            - âœ… å­—æ®µç±»å‹æ­£ç¡®æ€§
            - âœ… è¡¨è¾¾å¼è¯­æ³•æ­£ç¡®æ€§
            - âœ… æ”¯æŒçš„å‡½æ•°å’Œå˜é‡
            - âœ… ç¼ºå¤±çš„æ•°æ®åˆ—å’ŒæŒ‡æ ‡
            """)

        # å¯¼å…¥éªŒè¯å™¨
        try:
            from strategies_repo import validate_strategy_file
            validation_available = True
        except ImportError:
            st.error("ç­–ç•¥éªŒè¯å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ strategy_validator.py æ–‡ä»¶å­˜åœ¨")
            validation_available = False
        
        if validation_available:
            # è‡ªåŠ¨å®šä½ç­–ç•¥æ–‡ä»¶
            strategy_files = []
            import glob
            import os
            
            # æŒ‰ä¼˜å…ˆçº§æœç´¢ç­–ç•¥æ–‡ä»¶
            search_paths = [
                "strategies_repo.py",  # å½“å‰ç›®å½•
                "strategies/strategies_repo.py",  # strategiesç›®å½•
                "**/strategies_repo.py",  # é€’å½’æœç´¢
            ]
            
            for pattern in search_paths:
                files = glob.glob(pattern, recursive=True)
                for file in files:
                    if os.path.isfile(file):
                        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„é¿å…é‡å¤
                        abs_path = os.path.abspath(file)
                        if abs_path not in strategy_files:
                            strategy_files.append(abs_path)
            
            # å»é‡å¹¶æ’åº
            strategy_files = sorted(strategy_files)
            
            if strategy_files:
                # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸»è¦çš„ç­–ç•¥æ–‡ä»¶ï¼‰
                default_file = strategy_files[0]
                
                if len(strategy_files) > 1:
                    selected_file = st.selectbox(
                        "é€‰æ‹©ç­–ç•¥æ–‡ä»¶",
                        strategy_files,
                        index=0,
                        help=f"è‡ªåŠ¨å®šä½åˆ° {len(strategy_files)} ä¸ªç­–ç•¥æ–‡ä»¶ï¼Œé»˜è®¤é€‰æ‹©: {default_file}"
                    )
                else:
                    selected_file = default_file
                    st.info(f"è‡ªåŠ¨å®šä½åˆ°ç­–ç•¥æ–‡ä»¶: {selected_file}")
                
                col1, col2 = st.columns([1, 1])
                with col1:
                    check_btn = st.button("ğŸ” æ£€æŸ¥è¯­æ³•", width='stretch')
                with col2:
                    if st.button("ğŸ“„ æŸ¥çœ‹æ–‡ä»¶å†…å®¹", width='stretch'):
                        try:
                            with open(selected_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                            st.code(content, language='python')
                        except Exception as e:
                            st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                
                if check_btn:
                    with st.spinner("æ­£åœ¨æ£€æŸ¥ç­–ç•¥æ–‡ä»¶..."):
                        try:
                            result = validate_strategy_file(selected_file)
                            
                            # æ˜¾ç¤ºéªŒè¯ç»“æœ
                            if result.is_valid:
                                st.success("âœ… ç­–ç•¥æ–‡ä»¶éªŒè¯é€šè¿‡ï¼")
                            else:
                                st.error("âŒ ç­–ç•¥æ–‡ä»¶éªŒè¯å¤±è´¥")
                            
                            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                            if result.errors:
                                st.markdown("#### ğŸš¨ é”™è¯¯")
                                for error in result.errors:
                                    field_info = f" (å­—æ®µ: {error['field']})" if error.get('field') else ""
                                    st.error(f"â€¢ {error['message']}{field_info}")
                            
                            if result.warnings:
                                st.markdown("#### âš ï¸ è­¦å‘Š")
                                for warning in result.warnings:
                                    field_info = f" (å­—æ®µ: {warning['field']})" if warning.get('field') else ""
                                    st.warning(f"â€¢ {warning['message']}{field_info}")
                            
                            # æ˜¾ç¤ºå»ºè®®
                            if result.suggestions:
                                st.markdown("#### ğŸ’¡ å»ºè®®")
                                for suggestion in result.suggestions:
                                    field_info = f" (å­—æ®µ: {suggestion['field']})" if suggestion.get('field') else ""
                                    st.info(f"â€¢ {suggestion['message']}{field_info}")
                            
                            # æ˜¾ç¤ºç¼ºå¤±çš„åˆ—å’ŒæŒ‡æ ‡
                            if result.missing_columns:
                                st.markdown("#### ğŸ“Š ç¼ºå¤±çš„æ•°æ®åˆ—")
                                st.warning(f"ä»¥ä¸‹åˆ—åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨: {', '.join(result.missing_columns)}")
                            
                            if result.missing_indicators:
                                st.markdown("#### ğŸ”§ ç¼ºå¤±çš„æŒ‡æ ‡")
                                st.warning(f"ä»¥ä¸‹æŒ‡æ ‡æœªæ³¨å†Œ: {', '.join(result.missing_indicators)}")
                            
                            if result.syntax_issues:
                                st.markdown("#### ğŸ” è¯­æ³•é—®é¢˜")
                                for issue in result.syntax_issues:
                                    st.warning(f"â€¢ {issue}")
                            
                        except Exception as e:
                            st.error(f"æ–‡ä»¶éªŒè¯å‡ºé”™: {e}")
            else:
                st.warning("æœªæ‰¾åˆ°ç­–ç•¥æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ strategies_repo.py æ–‡ä»¶å­˜åœ¨")

    # ================== å¼ºåº¦æ¦œ ==================
    with tab_attn:
        st.subheader("å¼ºåº¦æ¦œ")
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            src = st.selectbox("æ¥æº", ["top","white","black","attention"], index=0)
            method = st.selectbox("æ–¹æ³•", ["å¼ºåº¦ï¼ˆå¸¦æƒï¼‰","æ¬¡æ•°ï¼ˆä¸å¸¦æƒï¼‰"], index=0)
        with c2:
            win_n = st.number_input("çª—å£å¤©æ•° N", min_value=1, max_value=365, value=60)
            top_m = st.number_input("Top-M è¿‡æ»¤ï¼ˆä»…ç»Ÿè®¡å‰ M åï¼‰", min_value=1, max_value=5000, value=3000)
        with c3:
            weight = st.selectbox("æ—¶é—´æƒé‡", ["ä¸åŠ æƒ","æŒ‡æ•°åŠè¡°","çº¿æ€§æœ€å°å€¼"], index=1)
            out_n = st.number_input("è¾“å‡º Top-N", min_value=1, max_value=1000, value=100)
        with c4:
            # date_end = st.text_input("ç»“æŸæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="")
            date_end = st.text_input("ç»“æŸæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value="", key="attn_end_date")
            gen_btn = st.button("ç”Ÿæˆå¹¶é¢„è§ˆ", width='stretch')

        if gen_btn:
            try:
                # 1) è®¡ç®— start/endï¼ˆæŒ‰äº¤æ˜“æ—¥ï¼‰
                days = _cached_trade_dates(DATA_ROOT, API_ADJ)
                end = (date_end or (days[-1] if days else None))
                if not end:
                    st.error("æœªèƒ½ç¡®å®šç»“æŸæ—¥"); st.stop()
                if end in days:
                    j = days.index(end)
                    start = days[max(0, j - int(win_n))]
                else:
                    start = days[-int(win_n)] if days else end

                # 2) å‚æ•°æ˜ å°„
                mode_map = {"å¼ºåº¦ï¼ˆå¸¦æƒï¼‰": "strength", "æ¬¡æ•°ï¼ˆä¸å¸¦æƒï¼‰": "hits"}
                w_map    = {"ä¸åŠ æƒ": "none", "æŒ‡æ•°åŠè¡°": "exp", "çº¿æ€§æœ€å°å€¼": "linear"}

                # 3) æ­£ç¡®è°ƒç”¨ scoring_core æ¥å£
                csv_path = se.build_attention_rank(
                    start=start, end=end, source=src,
                    min_hits=None, topN=int(out_n), write=True,
                    mode=mode_map[method], weight_mode=w_map[weight],
                    topM=int(top_m)
                )
                st.success(f"å¼ºåº¦æ¦œå·²ç”Ÿæˆï¼š{csv_path}")
                df_a = pd.read_csv(csv_path)
                st.dataframe(df_a, width='stretch', height=480)
                try:
                    if df_a is not None and not df_a.empty:
                        # è¯†åˆ«ä»£ç åˆ—ï¼ˆä¼˜å…ˆ ts_codeï¼‰
                        code_col = None
                        for cand in ["ts_code", "code", "ts", "symbol"]:
                            if cand in df_a.columns:
                                code_col = cand
                                break

                        if code_col:
                            codes = df_a[code_col].astype(str).tolist()
                            txt = _codes_to_txt(
                                codes,
                                st.session_state["export_pref"]["style"],
                                st.session_state["export_pref"]["with_suffix"]
                            )
                            # å¤åˆ¶æŒ‰é’®ï¼ˆä½¿ç”¨å·²æœ‰çš„ copy_txt_buttonï¼‰
                            copy_txt_button(
                                txt,
                                label="ğŸ“‹ å¤åˆ¶å¼ºåº¦æ¦œï¼ˆæŒ‰å½“å‰è¾“å‡ºï¼‰",
                                key=f"copy_attn_{end}_{src}"
                            )
                            # TXT å¯¼å‡ºï¼ˆæ–‡ä»¶åå«å‚æ•°ï¼Œä¾¿äºè¿½æº¯ï¼‰
                            _download_txt(
                                "å¯¼å‡ºå¼ºåº¦æ¦œ TXT",
                                txt,
                                f"attention_{src}_{mode_map[method]}_{w_map[weight]}_{start}_{end}.txt",
                                key="dl_attention_txt"
                            )
                        else:
                            st.caption("æœªæ‰¾åˆ°ä»£ç åˆ—ï¼ˆæœŸæœ›åˆ—åï¼šts_codeï¼‰ã€‚")
                except Exception as e:
                    st.warning(f"å¯¼å‡º/å¤åˆ¶å¤±è´¥ï¼š{e}")
                    
                # â€”â€” ä»¥ä¸‹ä¸ºâ€œå¼ºåº¦æ¦œè½ç›˜ï¼ˆCSV/TXTï¼Œå«æ¸…æ™°æ–‡ä»¶åï¼‰â€ 
                save_extra = cfg_bool("SC_ATTENTION_SAVE_EXTRA", False)
                if save_extra:
                    try:
                        fname_base = f"attention_{src}_{mode_map[method]}_{w_map[weight]}_win{int(win_n)}_topM{int(top_m)}_{start}_{end}_topN{int(out_n)}"
                        dest_csv = ATTN_DIR / f"{fname_base}.csv"
                        dest_txt = ATTN_DIR / f"{fname_base}.txt"

                        # 1) å¤åˆ¶ CSVï¼ˆè‹¥åå­—ä¸åŒï¼‰
                        try:
                            if str(csv_path) != str(dest_csv):
                                shutil.copyfile(csv_path, dest_csv)
                        except Exception as _e:
                            st.warning(f"CSV è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“é¡µé¢é¢„è§ˆï¼‰ï¼š{_e}")

                        # 2) å†™ TXTï¼ˆåªæœ‰å‰é¢ç”Ÿæˆè¿‡ txt æ‰å†™ï¼‰
                        if 'txt' in locals():
                            try:
                                dest_txt.write_text(txt, encoding="utf-8-sig")
                            except Exception as _e:
                                st.warning(f"TXT è½ç›˜å¤±è´¥ï¼ˆä¸å½±å“é¡µé¢é¢„è§ˆï¼‰ï¼š{_e}")

                        st.caption(f"å·²è½ç›˜ï¼š{dest_csv.name} / {dest_txt.name}ï¼ˆç›®å½•ï¼š{ATTN_DIR}ï¼‰")
                    except Exception as _e:
                        st.warning(f"å¼ºåº¦æ¦œè½ç›˜å‡ºç°å¼‚å¸¸ï¼š{_e}")

            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
                
        st.subheader("æœ¬åœ°è¯»å–")

        c1, c2 = st.columns([1,1])
        with c1:
            ref_inp_attn = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼›ç•™ç©º=è‡ªåŠ¨å–æœ€æ–°ï¼‰", value="", key="attn_ref_input")
        with c2:
            sort_key = st.selectbox("æ’åºä¾æ®", ["score â†“", "rank â†‘", "ä¿æŒåŸæ–‡ä»¶é¡ºåº"], index=0, key="attn_sort_key")
        topn_attn = st.number_input("Top-K æ˜¾ç¤ºè¡Œæ•°", min_value=5, max_value=1000, value=cfg_int("SC_ATTENTION_TOP_K", 50), key="attn_topn")
        # å†³å®šå‚è€ƒæ—¥ä¸æ–‡ä»¶è·¯å¾„
        ref_attn = (ref_inp_attn.strip() or _pick_latest_attn_date())
        if not ref_attn:
            st.info("æœªåœ¨ attention ç›®å½•å‘ç°ä»»ä½• CSVï¼Œè¯·å…ˆäº§å‡ºå¼ºåº¦æ¦œæˆ–æ£€æŸ¥è¾“å‡ºè·¯å¾„ã€‚")
        else:
            attn_path = _find_attn_file_by_date(ref_attn)
            st.caption(f"å‚è€ƒæ—¥ï¼š{ref_attn}")
            if not attn_path or (not attn_path.exists()):
                st.warning("æœªæ‰¾åˆ°è¯¥æ—¥çš„å¼ºåº¦æ¦œæ–‡ä»¶ã€‚")
            else:
                # è¯»å–å¼ºåº¦æ¦œ
                df_attn = _read_df(attn_path)
                if df_attn is None or df_attn.empty:
                    st.warning("å¼ºåº¦æ¦œæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")

        # åªæœ‰åœ¨æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰è¿›è¡Œæ’åºå’Œæ˜¾ç¤º
        if 'df_attn' in locals() and df_attn is not None and not df_attn.empty:
            # ç»Ÿä¸€/å®¹é”™æ’åºï¼šé»˜è®¤ä¼˜å…ˆæŒ‰ score é™åºï¼ŒåŒåˆ†æ—¶æŒ‰Jå€¼å‡åºï¼›æ²¡æœ‰ score åˆ™æŒ‰ rank å‡åºï¼›å¦åˆ™ä¿æŒåŸé¡ºåº
            def _auto_sort(df: pd.DataFrame) -> pd.DataFrame:
                if "score" in df.columns:
                    if "tiebreak_j" in df.columns:
                        return df.sort_values(["score", "tiebreak_j"], ascending=[False, True])
                    else:
                        return df.sort_values(["score"], ascending=[False])
                if "rank" in df.columns:
                    return df.sort_values(["rank"], ascending=[True])
                return df

            if sort_key == "score â†“" and "score" in df_attn.columns:
                if "tiebreak_j" in df_attn.columns:
                    df_attn = df_attn.sort_values(["score", "tiebreak_j"], ascending=[False, True])
                else:
                    df_attn = df_attn.sort_values(["score"], ascending=[False])
            elif sort_key == "rank â†‘" and "rank" in df_attn.columns:
                df_attn = df_attn.sort_values(["rank"], ascending=[True])
            # "ä¿æŒåŸæ–‡ä»¶é¡ºåº" å°±ä¸åŠ¨

            # é¢„è§ˆ + å¯¼å‡º/å¤åˆ¶ï¼Œè¡Œä¸ºä¸"æ’å"é¡µå°½é‡ä¸€è‡´
            st.divider()
            with st.container(border=True):
                rows_eff = int(topn_attn)
                st.markdown("**å¼ºåº¦æ¦œ Top-N é¢„è§ˆ**")
                st.dataframe(df_attn.head(rows_eff), width='stretch', height=420)

                # TXT å¤åˆ¶ï¼ˆæŒ‰ä½ çš„å¯¼å‡ºåå¥½ï¼‰
                if "ts_code" in df_attn.columns:
                    codes = df_attn["ts_code"].astype(str).head(rows_eff).tolist()
                    txt = _codes_to_txt(
                        codes,
                        st.session_state["export_pref"]["style"],
                        st.session_state["export_pref"]["with_suffix"]
                    )
                    copy_txt_button(txt, label="å¤åˆ¶ä»¥ä¸Š", key=f"copy_attn_{ref_attn}")

        # --- è½»é‡ï¼šå‰å‡ æ—¥ Top-K æ‰«æï¼ˆåªçœ‹ Topï¼Œä¸ç®—å¼ºåº¦ï¼‰ ---
        with st.expander("å‰å‡ æ—¥ Top-K æ‰«æï¼ˆè½»é‡ï¼‰", expanded=True):
            # â€”â€” å‚æ•°åŒº â€”â€”
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                end_use = st.text_input("è§‚å¯Ÿæ—¥ï¼ˆYYYYMMDDï¼‰", value=_get_latest_date_from_database() or "", key="lite_end")
            with c2:
                lookback_days = st.number_input("å›çœ‹å¤©æ•° Dï¼ˆä¸å«ä»Šå¤©ï¼‰", min_value=1, max_value=60, value=3, key="lite_D")
            with c3:
                k_min = st.number_input("K æœ€å°ï¼ˆå«ï¼‰", min_value=1, max_value=10000, value=1, key="lite_kmin")
            with c4:
                k_max = st.number_input("K æœ€å¤§ï¼ˆå«ï¼‰", min_value=1, max_value=10000, value=cfg_int("SC_TOP_K", 50), key="lite_kmax")

            c5, c6, c7 = st.columns(3)
            with c5:
                hit_mode = st.selectbox(
                    "å‘½ä¸­å£å¾„",
                    ["ä¸ä»Šå¤©Topäº¤é›†", "ç´¯è®¡ä¸Šæ¦œæ¬¡æ•°â‰¥N", "è¿ç»­ä¸Šæ¦œå¤©æ•°â‰¥N"],
                    index=0, key="lite_mode"
                )
            with c6:
                n_th = st.number_input("Nï¼ˆé˜ˆå€¼ï¼‰", min_value=1, max_value=60, value=2, key="lite_N",
                                    disabled=(hit_mode == "ä¸ä»Šå¤©Topäº¤é›†"))
            with c7:
                today_topk = st.number_input("ä»Šå¤©å¯¹æ¯” Top-K", min_value=1, max_value=5000,
                                            value=cfg_int("SC_TOP_K", 50), key="lite_todayK",
                                            disabled=(hit_mode != "ä¸ä»Šå¤©Topäº¤é›†"))

            limit = st.number_input("è¾“å‡ºæ¡æ•°ä¸Šé™", min_value=5, max_value=2000, value=200, key="lite_limit")

            go = st.button("è®¡ç®—ï¼ˆè½»é‡ Top-Kï¼‰", width='stretch', key="btn_lite_calc")

            if go:
                try:
                    days = _cached_trade_dates(DATA_ROOT, API_ADJ) or []
                    if not days:
                        st.warning("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚"); st.stop()
                    # è§‚å¯Ÿæ—¥å¤„ç†ï¼šè‹¥æ‰‹å¡«ä¸åœ¨äº¤æ˜“æ—¥é‡Œï¼Œå–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥
                    if not end_use or end_use not in days:
                        end_idx = len(days) - 1
                        end = days[end_idx]
                        if end_use and end_use not in days:
                            st.caption(f"è§‚å¯Ÿæ—¥ä¸åœ¨äº¤æ˜“æ—¥å†å†…ï¼Œå·²æ”¹ç”¨æœ€è¿‘äº¤æ˜“æ—¥ï¼š{end}")
                    else:
                        end_idx = days.index(end_use)
                        end = end_use
                    if end_idx <= 0:
                        st.info("è§‚å¯Ÿæ—¥å‰æ²¡æœ‰æ›´æ—©äº¤æ˜“æ—¥å¯ç»Ÿè®¡ã€‚"); st.stop()

                    # å›çœ‹çª—å£ï¼ˆä¸å«ä»Šå¤© endï¼‰
                    D = int(lookback_days)
                    start_idx = max(0, end_idx - D)
                    win_days = days[start_idx:end_idx]  # t-D ~ t-1

                    # K èŒƒå›´æ ¡æ­£
                    k1, k2 = int(min(k_min, k_max)), int(max(k_min, k_max))

                    # â€”â€” æ±‡æ€»å‰ D æ—¥ Top-Kï¼ˆKâˆˆ[k1,k2]ï¼‰â€”â€”
                    occ = {}             # ç´¯è®¡å‘½ä¸­æ¬¡æ•°
                    best_rank = {}       # çª—å£å†…æœ€å¥½åæ¬¡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
                    last_seen = {}       # æœ€è¿‘å‡ºç°æ—¥
                    day_index = {d:i for i,d in enumerate(win_days)}   # ä¾¿äºç®—è¿ç»­
                    appear_idx = {}      # ts_code -> å‡ºç°çš„æ—¥åºå·åˆ—è¡¨

                    for d in win_days:
                        p = _path_top(d)
                        if not p.exists() or p.stat().st_size == 0:
                            continue
                        df = _read_df(p, dtype={"ts_code": str})
                        if df is None or df.empty:
                            continue
                        if "rank" not in df.columns:
                            df = df.reset_index(drop=True)
                            df["rank"] = np.arange(1, len(df) + 1)
                        # åªå– K èŒƒå›´
                        df = df[(df["rank"] >= k1) & (df["rank"] <= k2)]
                        for ts, rk in zip(df["ts_code"].astype(str), df["rank"].astype(int)):
                            occ[ts] = occ.get(ts, 0) + 1
                            best_rank[ts] = min(best_rank.get(ts, 10**9), rk)
                            last_seen[ts] = d if (ts not in last_seen or d > last_seen[ts]) else last_seen[ts]
                            appear_idx.setdefault(ts, []).append(day_index[d])

                    # è¿ç»­å¤©æ•°ï¼ˆçª—å£å†…çš„æœ€å¤§è¿ç»­æ®µï¼‰
                    max_streak = {}
                    for ts, idxs in appear_idx.items():
                        idxs = sorted(set(idxs))
                        if not idxs:
                            max_streak[ts] = 0
                            continue
                        best = cur = 1
                        for a, b in zip(idxs, idxs[1:]):
                            if b == a + 1:
                                cur += 1
                                best = max(best, cur)
                            else:
                                cur = 1
                        max_streak[ts] = best

                    # æ±‡æ€» DataFrameï¼ˆåªå«åœ¨çª—å£å†…å‡ºç°è¿‡çš„ï¼‰
                    rows = []
                    for ts in sorted(occ.keys()):
                        rows.append({
                            "ts_code": ts,
                            "prev_hits": int(occ.get(ts, 0)),
                            "max_streak": int(max_streak.get(ts, 0)),
                            "best_rank_prev": int(best_rank.get(ts, 10**9)),
                            "last": last_seen.get(ts, None),
                        })
                    df_prev = pd.DataFrame(rows).sort_values(
                        ["prev_hits","best_rank_prev","ts_code"], ascending=[False, True, True]
                    ).reset_index(drop=True)

                    # â€”â€” å‘½ä¸­è®¡ç®— â€”â€” 
                    if hit_mode == "ä¸ä»Šå¤©Topäº¤é›†":
                        p_today = _path_top(end)
                        if not p_today.exists() or p_today.stat().st_size == 0:
                            st.info(f"{end} çš„ Top æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚"); st.stop()
                        df_today = _read_df(p_today, dtype={"ts_code": str})
                        if df_today is None or df_today.empty:
                            st.info(f"{end} çš„ Top æ–‡ä»¶è¯»å–ä¸ºç©ºã€‚"); st.stop()
                        if "rank" not in df_today.columns:
                            df_today = df_today.reset_index(drop=True)
                            df_today["rank"] = np.arange(1, len(df_today) + 1)
                        df_today = df_today.sort_values("rank").head(int(today_topk))
                        today_set = set(df_today["ts_code"].astype(str))
                        hit = df_prev[df_prev["ts_code"].astype(str).isin(today_set)].copy()
                        hit = hit.merge(
                            df_today[["ts_code","rank"]].rename(columns={"rank":"today_rank"}),
                            on="ts_code", how="left"
                        ).sort_values(
                            ["prev_hits","today_rank","best_rank_prev","ts_code"],
                            ascending=[False, True, True, True]
                        ).head(int(limit))
                        st.markdown(
                            f"**çª—å£ï¼š{win_days[0] if win_days else 'â€”'} ~ {win_days[-1] if win_days else 'â€”'}ï¼ˆä¸å«ä»Šå¤© {end}ï¼‰ï½œKâˆˆ[{k1},{k2}]ï¼Œä»Šå¤©å¯¹æ¯” Top-K={int(today_topk)}**"
                        )
                        st.markdown("**å‘½ä¸­ï¼šä¸ä»Šå¤© Top äº¤é›†ï¼ˆå»¶ç»­/å†ä¸Šæ¦œï¼‰**")
                        if hit.empty:
                            st.caption("æ— å‘½ä¸­ã€‚")
                        else:
                            st.dataframe(hit, width='stretch', height=360)
                            # å¤åˆ¶ä»£ç 
                            codes = hit["ts_code"].astype(str).tolist()
                            txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"],
                                                st.session_state["export_pref"]["with_suffix"])
                            copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶å‘½ä¸­ä»£ç ", key=f"copy_lite_inter_{end}")

                    elif hit_mode == "ç´¯è®¡ä¸Šæ¦œæ¬¡æ•°â‰¥N":
                        hit = df_prev[df_prev["prev_hits"] >= int(n_th)].copy()
                        hit = hit.sort_values(
                            ["prev_hits","best_rank_prev","ts_code"],
                            ascending=[False, True, True]
                        ).head(int(limit))
                        st.markdown(
                            f"**çª—å£ï¼š{win_days[0] if win_days else 'â€”'} ~ {win_days[-1] if win_days else 'â€”'}ï¼ˆä¸å«ä»Šå¤© {end}ï¼‰ï½œKâˆˆ[{k1},{k2}]**"
                        )
                        st.markdown(f"**å‘½ä¸­ï¼šç´¯è®¡ä¸Šæ¦œæ¬¡æ•° â‰¥ {int(n_th)}**")
                        if hit.empty:
                            st.caption("æ— å‘½ä¸­ã€‚")
                        else:
                            st.dataframe(hit, width='stretch', height=360)
                            codes = hit["ts_code"].astype(str).tolist()
                            txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"],
                                                st.session_state["export_pref"]["with_suffix"])
                            copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶å‘½ä¸­ä»£ç ", key=f"copy_lite_cnt_{end}")

                    else:  # è¿ç»­ä¸Šæ¦œå¤©æ•°â‰¥N
                        hit = df_prev[df_prev["max_streak"] >= int(n_th)].copy()
                        hit = hit.sort_values(
                            ["max_streak","best_rank_prev","ts_code"],
                            ascending=[False, True, True]
                        ).head(int(limit))
                        st.markdown(
                            f"**çª—å£ï¼š{win_days[0] if win_days else 'â€”'} ~ {win_days[-1] if win_days else 'â€”'}ï¼ˆä¸å«ä»Šå¤© {end}ï¼‰ï½œKâˆˆ[{k1},{k2}]**"
                        )
                        st.markdown(f"**å‘½ä¸­ï¼šè¿ç»­ä¸Šæ¦œå¤©æ•° â‰¥ {int(n_th)}**")
                        if hit.empty:
                            st.caption("æ— å‘½ä¸­ã€‚")
                        else:
                            st.dataframe(hit, width='stretch', height=360)
                            codes = hit["ts_code"].astype(str).tolist()
                            txt = _codes_to_txt(codes, st.session_state["export_pref"]["style"],
                                                st.session_state["export_pref"]["with_suffix"])
                            copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶å‘½ä¸­ä»£ç ", key=f"copy_lite_streak_{end}")

                except Exception as e:
                    st.error(f"è®¡ç®—å¤±è´¥ï¼š{e}")

            # # CSV ä¸‹è½½ï¼ˆTop-Nï¼‰
            # st.download_button(
            #     "â¬‡ï¸ å¯¼å‡º Top-Nï¼ˆCSVï¼‰",
            #     data=df_attn.head(rows_eff).to_csv(index=False).encode("utf-8-sig"),
            #     file_name=f"attention_top{rows_eff}_{ref_attn}.csv",
            #     width='stretch',
            #     key=f"dl_attn_{ref_attn}"
            # )

    # ================== é€‰è‚¡ ==================
    with tab_screen:
        st.subheader("é€‰è‚¡")

        # === ç»Ÿä¸€å‚è€ƒæ—¥ & èŒƒå›´ ===
        c_top1, c_top2 = st.columns([1,1])
        with c_top1:
            refD_unified = st.text_input("å‚è€ƒæ—¥ï¼ˆYYYYMMDDï¼Œç•™ç©º=è‡ªåŠ¨æœ€æ–°ï¼‰", value=st.session_state.get("screen_refD",""), key="screen_refD")
        with c_top2:
            uni_choice = st.selectbox("é€‰è‚¡èŒƒå›´", ["å…¨å¸‚åœº","ä»…ç™½åå•","ä»…é»‘åå•","ä»…ç‰¹åˆ«å…³æ³¨æ¦œ"], index=0, key="screen_uni_choice")
        _uni_map = {"å…¨å¸‚åœº":"all", "ä»…ç™½åå•":"white", "ä»…é»‘åå•":"black", "ä»…ç‰¹åˆ«å…³æ³¨æ¦œ":"attention"}

        # ========== 1) è¡¨è¾¾å¼ç­›é€‰ ==========
        with st.form("expression_screening_form"):
            st.markdown("### è¡¨è¾¾å¼ç­›é€‰")
            exp = st.text_input("è¡¨è¾¾å¼ï¼ˆç¤ºä¾‹ï¼šCLOSE>MA(CLOSE,20) AND VOL>MA(VOL,5)ï¼‰", value=st.session_state.get("screen_expr",""), key="screen_expr")
            c1, c2, c3, c4, c5, c6 = st.columns([1,1,1,1,1,1])
            with c1:
                level = st.selectbox("æ—¶é—´çº§åˆ«", ["D","W","M"], index=0, key="screen_level")
            with c2:
                window = st.number_input("çª—å£é•¿åº¦", min_value=1, max_value=500, value=30, key="screen_window")
            with c3:
                scope_logic = st.selectbox("å‘½ä¸­èŒƒå›´(scope)", ["LAST","ANY","ALL","COUNT>=k","CONSEC>=m","ANY_n","ALL_n"], index=0, key="screen_scope_logic")
            with c4:
                n_k_m = st.number_input("k/m/n(ç‰¹å®šé€‰æ‹©æ‰ç”Ÿæ•ˆ)", min_value=1, max_value=500, value=3, key="screen_nkm")
            with c5:
                tiebreak_expr = st.selectbox("åŒåˆ†æ’åº", ["none", "kdj_j_asc"], index=1, key="screen_tiebreak_expr")
            with c6:
                run_btn = st.form_submit_button("è¿è¡Œç­›é€‰", width='stretch')

        if run_btn:
            logger.info(f"ç”¨æˆ·ç‚¹å‡»è¿è¡Œç­›é€‰: è¡¨è¾¾å¼={exp[:50]}..., çº§åˆ«={level}, çª—å£={window}, èŒƒå›´={scope_logic}")
            try:
                if not exp.strip():
                    st.warning("è¯·å…ˆè¾“å…¥è¡¨è¾¾å¼ã€‚")
                else:
                    # ç»„è£… scope
                    scope = scope_logic
                    if scope_logic.startswith("COUNT"):
                        scope = f"COUNT>={int(n_k_m)}"
                    elif scope_logic.startswith("CONSEC"):
                        scope = f"CONSEC>={int(n_k_m)}"
                    elif scope_logic == "ANY_n":
                        scope = f"ANY_{int(n_k_m)}"
                    elif scope_logic == "ALL_n":
                        scope = f"ALL_{int(n_k_m)}"

                    df_sel = run_se_screen_in_bg(
                        when_expr=exp.strip(),
                        ref_date=(refD_unified.strip() or None),
                        timeframe=level,
                        window=_safe_int(window, 30),
                        scope=scope,
                        universe=_uni_map.get(uni_choice,"all"),
                        write_white=False,
                        write_black_rest=False,
                        return_df=True,
                    )
                    if df_sel is None or df_sel.empty:
                        st.info("æ— å‘½ä¸­ã€‚")
                    else:
                        # ç»“æœå·²ç»æŒ‰å¾—åˆ†æ’åºï¼Œç›´æ¥æ˜¾ç¤º
                        st.caption(f"å‘½ä¸­ {len(df_sel)} åªï¼›å‚è€ƒæ—¥ï¼š{(df_sel['ref_date'].iloc[0] if 'ref_date' in df_sel.columns and len(df_sel)>0 else (refD_unified or 'è‡ªåŠ¨'))}")
                        if 'score' in df_sel.columns:
                            st.caption("å·²æŒ‰å¾—åˆ†æ’åºï¼ˆé™åºï¼‰ï¼ŒåŒåˆ†æ—¶æŒ‰Jå€¼å‡åº")
                        st.dataframe(df_sel, width='stretch', height=480)
                        # å¯¼å‡º TXTï¼ˆä»£ç ï¼‰
                        if "ts_code" in df_sel.columns:
                            txt = _codes_to_txt(df_sel["ts_code"].astype(str).tolist(),
                                                st.session_state["export_pref"]["style"],
                                                st.session_state["export_pref"]["with_suffix"])
                            copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶ä»¥ä¸Šï¼ˆæŒ‰å½“å‰é¢„è§ˆï¼‰", key=f"copy_screen_expr_{refD_unified or 'auto'}")
            except Exception as e:
                st.error(f"ç­›é€‰å¤±è´¥ï¼š{e}")

        st.divider()

        # ========== 2) æŒ‰è§¦å‘è§„åˆ™ç­›é€‰ï¼ˆå½“æ—¥å…¨å¸‚åœºï¼Œå¤šé€‰ï¼‰ ==========
        with st.form("rule_screening_form"):
            st.markdown("### æŒ‰è§¦å‘è§„åˆ™ç­›é€‰ï¼ˆå½“æ—¥å…¨å¸‚åœºï¼Œå¤šé€‰ï¼‰")
            st.caption("è¯´æ˜ï¼šè¯»å–å½“æ—¥ details æ•°æ®ï¼›æŒ‰æ‰€é€‰è§„åˆ™ååˆ¤æ–­ï¼šåªè¦ç­–ç•¥è§¦å‘ï¼ˆok=Trueï¼‰å°±è§†ä¸ºå‘½ä¸­ï¼›æ”¯æŒ\"ä»»ä¸€/å…¨éƒ¨\"èšåˆã€‚")
            # è§„åˆ™åæ¥è‡ª se.SC_RULESï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            rule_names = _get_rule_names()
            picked = st.multiselect("è§„åˆ™åï¼ˆå¯å¤šé€‰ï¼‰", options=rule_names, default=[], key="detail_multi_rules")
            agg_mode = st.radio("å‘½ä¸­é€»è¾‘", ["ä»»ä¸€å‘½ä¸­ï¼ˆORï¼‰","å…¨éƒ¨å‘½ä¸­ï¼ˆANDï¼‰"], index=0, horizontal=True, key="detail_hit_mode")
            cA, cB, cC = st.columns([1,1,1])
            with cA:
                limit_n = st.number_input("æœ€å¤šæ˜¾ç¤º/å¯¼å‡º N æ¡", min_value=10, max_value=5000, value=200, step=10, key="detail_limit_n")
            with cB:
                tiebreak_rule = st.selectbox("åŒåˆ†æ’åº", ["none", "kdj_j_asc"], index=1, key="screen_tiebreak_rule")
            with cC:
                run_detail = st.form_submit_button("ç­›é€‰å½“æ—¥å‘½ä¸­æ ‡çš„", width='stretch')

        if run_detail:
            # è‡ªåŠ¨å¯ç”¨æ•°æ®åº“è¯»å–ï¼ˆå’Œä¸ªè‚¡è¯¦æƒ…é‡Œçš„è§£é”é€»è¾‘ä¸€æ ·ï¼‰
            if not is_details_db_reading_enabled():
                st.session_state["details_db_reading_enabled"] = True
            
            ref_real = refD_unified.strip() or _get_latest_date_from_files() or ""
            if not ref_real:
                st.error("æœªèƒ½ç¡®å®šå‚è€ƒæ—¥ã€‚")
            elif not picked:
                st.warning("è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªè§„åˆ™åã€‚")
            else:
                rows = []
                try:
                    # æ£€æŸ¥æ˜¯å¦å…è®¸è¯»å–æ•°æ®åº“ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°ï¼‰
                    db_reading_enabled = is_details_db_reading_enabled()
                    
                    # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢ï¼ˆåªæœ‰å½“db_reading_enabledä¸ºTrueä¸”æ•°æ®åº“å¯ç”¨æ—¶æ‰è¯»å–æ•°æ®åº“ï¼‰
                    if db_reading_enabled and is_details_db_available():
                        # ä½¿ç”¨ database_manager æŸ¥è¯¢è¯¦æƒ…
                        logger.info("[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (æŸ¥è¯¢è‚¡ç¥¨è¯¦æƒ…ç”¨äºUIæ˜¾ç¤º)")
                        manager = get_database_manager()
                        if manager:
                            # ä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°è·å–detailsæ•°æ®åº“è·¯å¾„ï¼ˆåŒ…å«å›é€€é€»è¾‘ï¼‰
                            details_db_path = get_details_db_path_with_fallback()
                            if details_db_path:
                                sql = "SELECT * FROM stock_details WHERE ref_date = ?"
                                df_all = manager.execute_sync_query(details_db_path, sql, [ref_real], timeout=30.0)
                            else:
                                df_all = pd.DataFrame()
                        else:
                            df_all = pd.DataFrame()
                        
                        if not df_all.empty:
                            for _, row in df_all.iterrows():
                                ts2 = str(row.get("ts_code", "")).strip()
                                if not ts2:
                                    continue
                                
                                # ä½¿ç”¨ç»Ÿä¸€çš„ _load_detail_json å‡½æ•°è·å–æ•°æ®
                                data = _load_detail_json(str(ref_real), ts2)
                                if not data:
                                    continue
                                
                                # ä»ç»Ÿä¸€æ ¼å¼ä¸­æå–æ•°æ®
                                summary = data.get("summary", {})
                                sc = float(summary.get("score", 0.0))
                                rules = data.get("rules", [])
                                
                                names_today = set()
                                for rr in rules:
                                    # åªè¦ç­–ç•¥è§¦å‘ï¼ˆok=Trueï¼‰ï¼Œå°±è§†ä¸ºå‘½ä¸­ï¼Œæ— éœ€æ£€æŸ¥addå­—æ®µ
                                    # æˆ–è€…add>0ä¹Ÿè§†ä¸ºå‘½ä¸­ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
                                    ok_val = rr.get("ok")
                                    add_val = rr.get("add")
                                    if bool(ok_val) or (add_val is not None and float(add_val) > 0.0):
                                        n = rr.get("name")
                                        if n: names_today.add(str(n))
                                
                                if names_today:
                                    if agg_mode.startswith("ä»»ä¸€"):
                                        hit = any((n in names_today) for n in picked)
                                    else:
                                        hit = all((n in names_today) for n in picked)
                                    if hit:
                                        rows.append({"ts_code": ts2, "score": sc})
                    
                    # å›é€€åˆ°JSONæ–‡ä»¶æŸ¥è¯¢
                    else:
                        ddir = DET_DIR / str(ref_real)
                        allow_set = None
                        if ddir.exists():
                            for p in ddir.glob("*.json"):
                                try:
                                    j = json.loads(p.read_text(encoding="utf-8-sig"))
                                except Exception:
                                    continue
                                ts2 = str(j.get("ts_code","")).strip()
                                if not ts2:
                                    continue
                                if (allow_set is not None) and (ts2 not in allow_set):
                                    continue
                                sm = j.get("summary") or {}
                                sc = float(sm.get("score", 0.0))
                                names_today = set()
                                for rr in (j.get("rules") or []):
                                    # åªè¦ç­–ç•¥è§¦å‘ï¼ˆok=Trueï¼‰ï¼Œå°±è§†ä¸ºå‘½ä¸­ï¼Œæ— éœ€æ£€æŸ¥addå­—æ®µ
                                    # æˆ–è€…add>0ä¹Ÿè§†ä¸ºå‘½ä¸­ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
                                    ok_val = rr.get("ok")
                                    add_val = rr.get("add")
                                    if bool(ok_val) or (add_val is not None and float(add_val) > 0.0):
                                        n = rr.get("name")
                                        if n: names_today.add(str(n))
                                if names_today:
                                    if agg_mode.startswith("ä»»ä¸€"):
                                        hit = any((n in names_today) for n in picked)
                                    else:
                                        hit = all((n in names_today) for n in picked)
                                    if hit:
                                        rows.append({"ts_code": ts2, "score": sc})
                    
                    df_hit = pd.DataFrame(rows)
                    if df_hit.empty:
                        st.info("æœªç­›åˆ°å‘½ä¸­æ ‡çš„ã€‚")
                    else:
                        # åº”ç”¨Tie-breakæ’åº
                        df_hit_sorted = _apply_tiebreak_sorting(df_hit, tiebreak_rule)
                        n = int(limit_n)
                        df_show = df_hit_sorted.head(n)
                        st.caption(f"å‘½ä¸­ {len(df_hit_sorted)} åªï¼›æ˜¾ç¤ºå‰ {len(df_show)} åªï¼›å‚è€ƒæ—¥ï¼š{ref_real}")
                        st.dataframe(df_show, width='stretch', height=420)
                        # å¯¼å‡º TXT
                        if "ts_code" in df_show.columns:
                            txt = _codes_to_txt(df_show["ts_code"].astype(str).tolist(),
                                                st.session_state["export_pref"]["style"],
                                                st.session_state["export_pref"]["with_suffix"])
                            copy_txt_button(txt, label="ğŸ“‹ å¤åˆ¶ä»¥ä¸Šï¼ˆæŒ‰å½“å‰é¢„è§ˆï¼‰", key=f"copy_screen_rule_{ref_real}")
                except Exception as e:
                    st.error(f"è¯»å–æ˜ç»†å¤±è´¥ï¼š{e}")

    # ================== å·¥å…·ç®± ==================
    with tab_tools:
        st.subheader("å·¥å…·ç®±")
        colA, colB = st.columns(2)

        with colA:
            st.markdown("**è‡ªåŠ¨è¡¥ç®—æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥**")
            n_back = st.number_input("å¤©æ•° N", min_value=1, max_value=100, value=20)
            inc_today = st.checkbox("åŒ…å«å‚è€ƒæ—¥å½“å¤©", value=True,
                                    help="å‹¾é€‰åçª—å£åŒ…å«å‚è€ƒæ—¥ï¼ˆä¾‹å¦‚ N=5 â†’ [ref-(N-1), ref]ï¼›æœªå‹¾é€‰åˆ™ [ref-N, ref-1]ï¼‰")
            do_force = st.checkbox("å¼ºåˆ¶é‡å»ºï¼ˆè¦†ç›–å·²æœ‰ï¼‰", value=False,
                                help="è‹¥ä¹‹å‰å¤±è´¥ç•™ä¸‹äº† 0 å­—èŠ‚æ–‡ä»¶æˆ–æƒ³é‡ç®—ï¼Œå‹¾é€‰æ­¤é¡¹ã€‚")

            go_fill = st.button("æ‰§è¡Œè‡ªåŠ¨è¡¥ç®—", width='stretch')
            if go_fill:
                try:
                    if hasattr(se, "backfill_prev_n_days"):
                        out = se.backfill_prev_n_days(n=int(n_back), include_today=bool(inc_today), force=bool(do_force))
                        st.success(f"å·²å¤„ç†ï¼š{out}")
                    else:
                        st.warning("æœªæ£€æµ‹åˆ° backfill_prev_n_daysã€‚")
                except Exception as e:
                    st.error(f"è¡¥ç®—å¤±è´¥ï¼š{e}")

        with colB:
            st.markdown("**è¡¥é½ç¼ºå¤±çš„ All æ’åæ–‡ä»¶**")
            # start = st.text_input("èµ·å§‹æ—¥ YYYYMMDD", value="")
            start = st.text_input("èµ·å§‹æ—¥ YYYYMMDD", value="", key="tools_fix_start")
            end = st.text_input("ç»“æŸæ—¥ YYYYMMDD", value="", key="tools_fix_end")
            do_force_fix = st.checkbox("å¼ºåˆ¶é‡å»ºï¼ˆè¦†ç›–å·²æœ‰ï¼‰", value=False)
            go_fix = st.button("è¡¥é½ç¼ºå¤±", width='stretch')
            if go_fix and start and end:
                try:
                    if hasattr(se, "backfill_missing_ranks"):                   
                        out = se.backfill_missing_ranks(start, end, force=bool(do_force_fix))
                        st.success(f"å·²è¡¥é½ï¼š{out}")
                    else:
                        st.warning("æœªæ£€æµ‹åˆ° backfill_missing_ranksã€‚")
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥ï¼š{e}")
        st.markdown("---")
        with st.expander("æŸ¥çœ‹å·²æœ‰æ•°æ®ï¼ˆTop / All / Details / æ—¥å†ï¼‰", expanded=True):
            if "scan_inventory_loaded" not in st.session_state:
                st.session_state["scan_inventory_loaded"] = False
            col0, col1 = st.columns([1,3])
            with col0:
                do_scan = st.button("åŠ è½½/åˆ·æ–°åˆ—è¡¨", key="btn_scan_inventory", width='stretch')
                if do_scan:
                    st.session_state["scan_inventory_loaded"] = True
            if not st.session_state["scan_inventory_loaded"]:
                st.info("ï¼ˆé¦–æ¬¡è¿›å…¥ä¸æ‰«æç£ç›˜ï¼Œç‚¹å‡»ä¸Šæ–¹ **åŠ è½½/åˆ·æ–°åˆ—è¡¨** æ‰è¯»å–æ–‡ä»¶æ¸…å•ã€‚ï¼‰")
            if st.session_state["scan_inventory_loaded"]:
                try:
                    all_files = sorted(ALL_DIR.glob("score_all_*.csv"))
                    top_files = sorted(TOP_DIR.glob("score_top_*.csv"))
                    det_dirs  = sorted([p for p in DET_DIR.glob("*") if p.is_dir()])

                    all_dates = [p.stem.replace("score_all_", "") for p in all_files]
                    top_dates = [p.stem.replace("score_top_", "") for p in top_files]
                    det_dates = [p.name for p in det_dirs]

                    zero_all = [p.name for p in all_files if p.stat().st_size == 0]
                    zero_top = [p.name for p in top_files if p.stat().st_size == 0]

                    cov_min = min(all_dates) if all_dates else ""
                    cov_max = max(all_dates) if all_dates else ""

                    # äº¤æ˜“æ—¥æ—¥å†ï¼ˆè‹¥å­˜åœ¨åˆ™ç”¨äºå¯¹æ¯”ç¼ºå¤±ï¼‰
                    missing: list[str] = []
                    try:
                        trade_dates = get_trade_dates() or []
                        if trade_dates and cov_min and cov_max:
                            rng = [d for d in trade_dates if cov_min <= d <= cov_max]
                            aset = set(all_dates)
                            missing = [d for d in rng if d not in aset]
                    except Exception:
                        trade_dates = []

                    col1, col2, col3, col4 = st.columns(4)
                    with col1: st.metric("All æ–‡ä»¶æ•°", len(all_files))
                    with col2: st.metric("Top æ–‡ä»¶æ•°", len(top_files))
                    with col3: st.metric("Details æ—¥æœŸç›®å½•", len(det_dirs))
                    with col4: st.metric("0 å­—èŠ‚æ–‡ä»¶", len(zero_all) + len(zero_top))

                    if cov_min:
                        st.caption(f"All è¦†ç›–åŒºé—´ï¼š{cov_min} ~ {cov_max}ï¼ˆç¼ºå¤± {len(missing)} å¤©ï¼‰")
                    else:
                        st.caption("All ç›®å½•ä¸ºç©ºã€‚")

                    if zero_all or zero_top:
                        names = zero_all[:8] + zero_top[:8]
                        st.warning("æ£€æµ‹åˆ° 0 å­—èŠ‚æ–‡ä»¶ï¼ˆå¯ç”¨â€œå¼ºåˆ¶é‡å»ºâ€è¦†ç›–ï¼‰ï¼š\n" + "ï¼Œ".join(names) + (" â€¦â€¦" if len(zero_all)+len(zero_top) > len(names) else ""))
                    colL, colR = st.columns([1, 2])
                    with colL:
                        kind = st.radio("æ•°æ®ç±»å‹", ["All æ’å", "Top æ’å", "Details"], horizontal=True, key="view_kind")
                        if kind == "All æ’å":
                            cand = all_dates
                        elif kind == "Top æ’å":
                            cand = top_dates
                        else:
                            cand = det_dates
                        sel_date = st.selectbox("é€‰æ‹©æ—¥æœŸï¼ˆå€’åºï¼‰", cand[::-1] if cand else [], key="view_date") if cand else None
                        show_missing = st.checkbox("æ˜¾ç¤ºç¼ºå¤±æ—¥æœŸï¼ˆåŸºäºäº¤æ˜“æ—¥å†ï¼‰", value=False, disabled=not missing)
                    with colR:
                        if sel_date:
                            if kind == "All æ’å":
                                p = _path_all(sel_date)
                                if p.exists() and p.stat().st_size > 0:
                                    st.dataframe(_read_df(p).head(200), width='stretch', height=360)
                                else:
                                    st.info("è¯¥æ—¥ All æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
                            elif kind == "Top æ’å":
                                p = _path_top(sel_date)
                                if p.exists() and p.stat().st_size > 0:
                                    st.dataframe(_read_df(p).head(200), width='stretch', height=360)
                                else:
                                    st.info("è¯¥æ—¥ Top æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
                            else:
                                pdir = DET_DIR / sel_date
                                if pdir.exists():
                                    st.info(f"{sel_date} å…±æœ‰ {len(list(pdir.glob('*.json')))} ä¸ªè¯¦æƒ…æ–‡ä»¶ã€‚")
                                else:
                                    st.info("è¯¥æ—¥æ²¡æœ‰ Details ç›®å½•ã€‚")

                    if show_missing and missing:
                        st.markdown("**ç¼ºå¤±æ—¥æœŸï¼ˆç›¸å¯¹ All è¦†ç›–åŒºé—´ï¼‰**")
                        txt = " ".join(missing[:200]) + (" ..." if len(missing) > 200 else "")
                        st.code(txt)
                except Exception as e:
                    st.error(f"æ‰«æå¤±è´¥ï¼š{e}")

    # ================== ç»„åˆæ¨¡æ‹Ÿ / æŒä»“ ==================
    with tab_port:
        st.subheader("ç»„åˆæ¨¡æ‹Ÿ / æŒä»“")
        from stats_core import PortfolioManager
        pm = PortfolioManager()

        # â€”â€” å…¨å±€é…ç½®ï¼ˆç”¨äºæ–°å»ºç»„åˆçš„é»˜è®¤å€¼ï¼‰ â€”â€”
        with st.expander("å…¨å±€é…ç½®ï¼ˆé»˜è®¤ç”¨äºæ–°å»ºç»„åˆï¼›æ¥è‡ª config.PF_*ï¼‰", expanded=True):
            colA, colB, colC, colD = st.columns(4)
            with colA:
                st.text_input("è´¦æœ¬åç§°", value=cfg_str("PF_LEDGER_NAME", "è´¦æœ¬1"), key="pf_ledger")
                st.number_input("åˆå§‹èµ„é‡‘ï¼ˆæ€»é¢ï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_INIT_CASH", 1_000_000.0)), key="pf_init_cash")
            with colB:
                st.number_input("åˆå§‹å¯ç”¨èµ„é‡‘", min_value=0.0, value=float(getattr(cfg, "PF_INIT_AVAILABLE", getattr(cfg, "PF_INIT_CASH", 1_000_000.0))), key="pf_init_avail")
                st.selectbox("æˆäº¤ä»·å£å¾„", ["next_open","close"], index=(0 if cfg_str("PF_TRADE_PRICE_MODE","next_open")=="next_open" else 1), key="pf_pxmode")
            with colC:
                st.number_input("ä¹°å…¥è´¹ç‡ï¼ˆbpï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_FEE_BPS_BUY", 15.0)), key="pf_fee_buy")
                st.number_input("å–å‡ºè´¹ç‡ï¼ˆbpï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_FEE_BPS_SELL", 15.0)), key="pf_fee_sell")
            with colD:
                st.number_input("æœ€ä½è´¹ç”¨ï¼ˆå…ƒï¼‰", min_value=0.0, value=float(getattr(cfg, "PF_MIN_FEE", 0.0)), key="pf_min_fee")
            st.caption("ä»¥ä¸Šä¸ºé»˜è®¤å€¼ï¼›æ–°å»ºç»„åˆæ—¶ä¼šå¸¦å…¥ï¼ˆæ¯ä¸ªç»„åˆå¯è¦†ç›–ï¼‰ã€‚")

        # â€”â€” æ–°å»º/é€‰æ‹©ç»„åˆ â€”â€”
        col1, col2 = st.columns([1,2])
        with col1:
            st.markdown("**æ–°å»ºç»„åˆ**")
            new_name = st.text_input("åç§°", value=st.session_state.get("pf_ledger","default"))
            if st.button("åˆ›å»ºç»„åˆ", width='stretch'):
                pid = pm.create_portfolio(
                    name=new_name,
                    init_cash=float(st.session_state["pf_init_cash"]),
                    init_available=float(st.session_state["pf_init_avail"]),
                    trade_price_mode=str(st.session_state["pf_pxmode"]),
                    fee_bps_buy=float(st.session_state["pf_fee_buy"]),
                    fee_bps_sell=float(st.session_state["pf_fee_sell"]),
                    min_fee=float(st.session_state["pf_min_fee"]),
                )
                st.success(f"å·²åˆ›å»ºï¼š{new_name}ï¼ˆid={pid}ï¼‰")

        with col2:
            st.markdown("**å½“å‰ç»„åˆ**")
            ports = pm.list_portfolios()
                # st.stop()
            # ä»¥ name æ’åº
            ports_items = sorted(list(ports.items()), key=lambda kv: kv[1].name) if ports else []
            if not ports_items:
                st.info("æš‚æ— ç»„åˆï¼Œè¯·å…ˆåˆ›å»ºã€‚")
                cur_pid, cur_pf = None, None
                st.session_state['cur_pid'] = None
                st.session_state['cur_pf'] = None
                st.session_state['cur_pid'] = cur_pid
                st.session_state['cur_pf'] = cur_pf
            else:
                names = [f"{p.name} ({pid[:6]})" for pid, p in ports_items]
                sel = st.selectbox("é€‰æ‹©ç»„åˆ", options=list(range(len(ports_items))), format_func=lambda i: names[i], index=0)
                cur_pid, cur_pf = ports_items[sel]
                st.session_state['cur_pid'] = cur_pid
                st.session_state['cur_pf'] = cur_pf

        st.divider()

        # â€”â€” å½•å…¥æˆäº¤ï¼ˆä»·æ ¼å‚è€ƒåŒºé—´ï¼‰ â€”â€”
        st.markdown("**å½•å…¥æˆäº¤ï¼ˆå¸¦å‚è€ƒä»·åŒºé—´ï¼‰**")
        colx, coly, colz, colw = st.columns([1.2, 1.2, 1.2, 2])
        with colx:
            side = st.selectbox("æ–¹å‘", ["BUY","SELL"], index=0)
        with coly:
            d_exec = st.text_input("æˆäº¤æ—¥ï¼ˆYYYYMMDDï¼‰", value=_get_latest_date_from_database() or "")
        with colz:
            ts = st.text_input("ä»£ç ", value="")
        # è¯»å–å½“æ—¥ O/H/L/C ä½œä¸ºå‚è€ƒ
        ref_low = ref_high = px_open = px_close = None
        try:
            ts_norm = normalize_ts(ts) if ts else ""
            if ts_norm and d_exec:
                try:
                    from config import DATA_ROOT, UNIFIED_DB_PATH
                    db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                    df_one = query_stock_data(
                        db_path=db_path,
                        ts_code=ts_norm,
                        start_date=d_exec,
                        end_date=d_exec,
                        adj_type="qfq"
                    )
                except:
                    # å›é€€åˆ°ç›´æ¥æŸ¥è¯¢
                    from config import DATA_ROOT, UNIFIED_DB_PATH
                    db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
                    logger.info(f"[æ•°æ®åº“è¿æ¥] å¼€å§‹è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ (å›é€€æŸ¥è¯¢Kçº¿æ•°æ®: {ts_norm}, {d_exec})")
                    manager = get_database_manager()
                    sql = "SELECT open,high,low,close FROM stock_data WHERE ts_code = ? AND trade_date = ?"
                    df_one = manager.execute_sync_query(db_path, sql, [ts_norm, d_exec], timeout=30.0)
                if df_one is not None and not df_one.empty:
                    row = df_one.iloc[-1]
                    px_open = float(row.get("open", float("nan")))
                    px_close = float(row.get("close", float("nan")))
                    ref_low  = float(row.get("low", float("nan")))
                    ref_high = float(row.get("high", float("nan")))
        except Exception:
            pass
        with colw:
            st.write({"open": px_open, "close": px_close, "low": ref_low, "high": ref_high})

        colq, colp = st.columns([1.2, 1.8])
        with colq:
            qty = st.number_input("æ•°é‡ï¼ˆè‚¡ï¼‰", min_value=0, value=0, step=100)
        with colp:
            price_mode = st.radio("æˆäº¤ä»·æ¥æº", ["æŒ‰å£å¾„è‡ªåŠ¨","è‡ªå®šä¹‰ä»·æ ¼"], index=0, horizontal=True)
            if price_mode == "è‡ªå®šä¹‰ä»·æ ¼":
                price = st.number_input("æˆäº¤ä»·ï¼ˆç•™ç©ºåˆ™ç”¨å£å¾„ä»·ï¼‰", min_value=0.0, value=float(px_close or px_open or 0.0), step=0.01)
            else:
                price = None

        if cur_pf and st.button("è®°å½•æˆäº¤", width='stretch', key="btn_rec_trade"):
            try:
                pm.record_trade(pid=cur_pid, date=str(d_exec), ts_code=str(ts_norm), side=str(side), qty=int(qty),
                                price_mode=(None if price is not None else cur_pf.trade_price_mode),
                                price=(None if price is None else float(price)), note="manual")
                st.success("å·²è®°å½•")
            except Exception as e:
                st.error(f"è®°å½•å¤±è´¥ï¼š{e}")

        st.divider()

        # â€”â€” è§‚å¯Ÿæ—¥ä¼°å€¼ / å‡€å€¼ â€”â€”
        st.markdown("**è§‚å¯Ÿæ—¥æ”¶ç›Šä¸æŒä»“ä¼°å€¼**")
        obs = st.text_input("è§‚å¯Ÿæ—¥ï¼ˆYYYYMMDDï¼›é»˜è®¤=æœ€æ–°äº¤æ˜“æ—¥ï¼‰", value=_get_latest_date_from_database() or "")
        if obs and cur_pf:
            # å›æ”¾ä¼°å€¼ï¼ˆä»ç»„åˆåˆ›å»ºæ—¥è‡³è§‚å¯Ÿæ—¥ï¼‰
            # æˆ‘ä»¬ç”¨ read_nav() è¯»å–ç»“æœ
            try:
                # æ‰§è¡Œä¼°å€¼
                # pm.reprice_and_nav(cur_pid, date_start="19000101", date_end=str(obs), benchmarks=())
                tr = pm.read_trades(cur_pid)
                if tr is not None and not tr.empty:
                    # ç»„åˆé¦–ç¬”æˆäº¤æ—¥
                    first_trade = str(pd.to_datetime(tr["date"].astype(str), errors="coerce").dt.strftime("%Y%m%d").min())
                    # èµ·ç‚¹ = é¦–ç¬”æˆäº¤æ—¥å‰ä¸€ä¸ªâ€œäº¤æ˜“æ—¥â€
                    date_start_use = _prev_trade_date(first_trade, 1)
                else:
                    # æ²¡æœ‰æˆäº¤è®°å½•å°±ä»è§‚å¯Ÿæ—¥å¼€å§‹ï¼ˆé¿å…ä»è¿œå¤èµ·ç®—ï¼‰
                    date_start_use = str(obs)

                pm.reprice_and_nav(
                    cur_pid,
                    date_start=str(date_start_use),
                    date_end=str(obs),
                    benchmarks=(),
                )
                nav_df = pm.read_nav(cur_pid)
                pos_df = pm.read_positions(cur_pid)
            except Exception as e:
                st.error(f"ä¼°å€¼å¤±è´¥ï¼š{e}")
                nav_df, pos_df = pd.DataFrame(), pd.DataFrame()
            if not nav_df.empty:
                row = nav_df.iloc[-1]
                if not pos_df.empty and "date" in pos_df.columns:
                    cur_pos = pos_df[pos_df["date"] == str(obs)].copy()
                    if not cur_pos.empty:
                        st.markdown("**å½“å‰æŒä»“**")
                        show_cols = [c for c in ["ts_code","qty","cost","mkt_price","mkt_value","unreal_pnl"] if c in cur_pos.columns]
                        cur_pos = cur_pos[show_cols].sort_values("mkt_value", ascending=False)
                        st.dataframe(cur_pos, width='stretch', height=300)
                    else:
                        st.caption("è§‚å¯Ÿæ—¥æ— æŒä»“è®°å½•ã€‚")
                st.metric("ç»„åˆå¸‚å€¼", f"{(row.get('nav',1.0) * float(cur_pf.init_cash)):.0f}")
                st.metric("åŒºé—´æ”¶ç›Šç‡", f"{(row.get('nav',1.0) - 1.0):.2%}")
                cols = [c for c in ["date","cash","position_mv","nav","ret_d","max_dd"] if c in nav_df.columns]
                st.dataframe(nav_df[cols].tail(5), width='stretch')
                st.markdown("**å‡€å€¼æ›²çº¿ï¼ˆNAVï¼‰**")
                try:
                    st.line_chart(nav_df.set_index("date")["nav"])
                except Exception:
                    pass
            else:
                st.caption("æš‚æ— å‡€å€¼æ•°æ®ï¼ˆå¯èƒ½è¿˜æœªæœ‰æˆäº¤æˆ–è¡Œæƒ…æ•°æ®ç¼ºå¤±ï¼‰")

    # ================== ç»Ÿè®¡ï¼ˆæ™®é€šé¡µç­¾ï¼‰ ==================
    with tab_stats:
        st.subheader("ç»Ÿè®¡")
        sub_tabs = st.tabs(["è·Ÿè¸ªï¼ˆTrackingï¼‰", "å¼‚åŠ¨ï¼ˆSurgeï¼‰", "å…±æ€§ï¼ˆCommonalityï¼‰"])

        # --- Tracking ---
        with sub_tabs[0]:
            refT = st.text_input("å‚è€ƒæ—¥", value="", key="ref_1")
            # å‚è€ƒæ—¥/å›çœ‹çª—å£çš„æç¤ºï¼šå‘Šè¯‰ç”¨æˆ· t-n æ˜¯å“ªå¤©
            _back_choices = [1, 3, 5, 10, 20]
            _hint_text, _n2d = _from_last_hints(_back_choices)
            if _hint_text:
                st.caption("æŒ‰æœ€æ–°äº¤æ˜“æ—¥å›æ¨ï¼š " + _hint_text)

            wins = st.text_input("æœªæ¥æ”¶ç›Šçª—å£Nï¼ˆå¤©ï¼Œé€—å·åˆ†éš”ï¼‰", value="1,2,3,5,10,20")
            bench = st.text_input("å¯¹æ¯”æŒ‡æ•°åŸºå‡†ä»£ç ï¼ˆé€—å·ï¼Œå¯ç•™ç©ºï¼‰", value="")
            retrosT = st.text_input("é™„åŠ å›çœ‹å¤©æ•°", value="1,3,5")
            only_detail = st.checkbox("ä»…å¯¼å‡ºæ˜ç»†ï¼ˆä¸æ˜¾ç¤ºå‡å€¼/æ ‡å‡†å·®/èƒœç‡/åˆ†ä½æ•°æ±‡æ€»ï¼‰", value=True)
            gb_board = st.checkbox("åˆ†æ¿å—æ±‡æ€»", value=True)

            # === è·Ÿè¸ªå¢å¼ºï¼šå‰æ—¥æ’è¡Œ / åå• / æŒ‡æ ‡æ˜¯å¦è§¦å‘ / åç»­æ¶¨å¹… ===
            with st.expander("å¯é€‰ï¼šé€‰æ‹©è¦æ‰“å‹¾çš„æŒ‡æ ‡ï¼ˆæ¥è‡ªæ‰“åˆ†è§„åˆ™ï¼›ä»…ç”¨äºæ‰“å‹¾ï¼Œä¸å½±å“æ ·æœ¬ï¼‰", expanded=True):
                import scoring_core as se
                # è§„åˆ™ååˆ—è¡¨ï¼ˆå»é‡ï¼‰
                try:
                    rule_names = [str(r.get("name") or f"RULE_{i}") for i, r in enumerate(getattr(se, "SC_RULES", []) or [])]
                    rule_names = sorted(list(dict.fromkeys(rule_names)))
                except Exception:
                    rule_names = []
                track_rule_names = st.multiselect("æŒ‡æ ‡ï¼ˆå¯å¤šé€‰ï¼‰", options=rule_names, default=[])
                track_max_json = st.number_input("æœ€å¤šè¯»å–æ˜ç»†JSONï¼ˆæŒ‰å½“æ—¥æ’åæ’åºï¼‰", min_value=50, max_value=5000, value=300, step=50, key="track_max_json")


            if st.button("ç”Ÿæˆè·Ÿè¸ªè¡¨ï¼ˆå«å‰æ—¥æ’è¡Œ/åå•/æŒ‡æ ‡å‹¾é€‰/åç»­æ¶¨å¹…ï¼‰", key="btn_run_tracking", width='stretch'):
                try:
                    from stats_core import run_tracking
                    import scoring_core as se
                    # 1) åŸºç¡€ tracking æ˜ç»†
                    wlist = [int(x) for x in wins.split(",") if x.strip().isdigit()]
                    blist = [s.strip() for s in bench.split(",") if s.strip()] or None
                    rlist = [int(x) for x in retrosT.split(",") if x.strip().isdigit()]
                    tr2 = run_tracking(
                        refT, wlist, benchmarks=blist, score_df=None,
                        group_by_board=gb_board, save=True,
                        retro_days=rlist, do_summary=(not only_detail)
                    )
                    detail = tr2.detail.copy()

                    # 2) åˆå¹¶å‰æ—¥ rank
                    prev = _prev_ref_date(refT)
                    if prev:
                        df_prev = _read_df(_path_all(prev), usecols=["ts_code","rank"])
                        if df_prev is not None and len(df_prev) > 0:
                            df_prev = df_prev.rename(columns={"rank":"rank_tminus_1"})
                            detail = detail.merge(df_prev, on="ts_code", how="left")

                    # 3) åˆå¹¶åå•ï¼ˆç™½/é»‘/ç‰¹åˆ«å…³æ³¨ï¼‰
                    try:
                        whites = set(se._read_cache_list_codes(refT, "whitelist")) if hasattr(se, "_read_cache_list_codes") else set()
                        blacks = set(se._read_cache_list_codes(refT, "blacklist")) if hasattr(se, "_read_cache_list_codes") else set()
                        attns  = set(se._load_attention_codes(refT)) if hasattr(se, "_load_attention_codes") else set()
                        detail["in_whitelist"] = detail["ts_code"].astype(str).map(lambda c: c in whites)
                        detail["in_blacklist"] = detail["ts_code"].astype(str).map(lambda c: c in blacks)
                        detail["in_attention"] = detail["ts_code"].astype(str).map(lambda c: c in attns)
                    except Exception:
                        for c in ("in_whitelist","in_blacklist","in_attention"):
                            detail[c] = False

                    # 4) æŒ‡æ ‡æ˜¯å¦è§¦å‘ï¼ˆæ¥è‡ªæ’åè§„åˆ™ï¼‰
                    try:
                        import scoring_core as se
                        sel_rules = track_rule_names if isinstance(track_rule_names, list) else []
                        hit_cols = [f"hit:{name}" for name in sel_rules]
                        for col in hit_cols:
                            detail[col] = False
                        if sel_rules:
                            pick_n = int(track_max_json) if "track_max_json" in locals() else 300
                            head_codes = detail.sort_values(["rank"]).head(pick_n)["ts_code"].astype(str).tolist()
                            def _read_hits_one(ts):
                                obj = _load_detail_json(str(refT), str(ts))
                                res = {}
                                if not obj:
                                    return res
                                rules = obj.get("rules") or []
                                for rr in rules:
                                    nm = str(rr.get("name") or "")
                                    if nm in sel_rules:
                                        res[nm] = bool(rr.get("ok", False))
                                return res
                            for ts in head_codes:
                                hits_map = _read_hits_one(ts)
                                for nm in sel_rules:
                                    col = f"hit:{nm}"
                                    if nm in hits_map:
                                        detail.loc[detail["ts_code"].astype(str) == ts, col] = bool(hits_map[nm])
                    except Exception:
                        pass

                    # 5) å±•ç¤ºæ‰€éœ€åˆ—
                    show_cols = [c for c in [
                        "ts_code","rank","rank_tminus_1",
                        "in_whitelist","in_blacklist","in_attention",
                        *[c for c in detail.columns if str(c).startswith("hit:")],
                        *[c for c in detail.columns if c.startswith("ret_fwd_")]
                    ] if c in detail.columns]
                    detail_fmt2 = _fmt_retcols_percent(detail)
                    st.dataframe(detail_fmt2[show_cols].sort_values(["rank"]).reset_index(drop=True),
                                width='stretch', height=460)
                    st.caption("ret_fwd_N = æœªæ¥ N æ—¥æ¶¨å¹…ï¼ˆTracking å·²è®¡ç®—ï¼‰ï¼›åå•åˆ—æ¥è‡ª cache/attentionï¼›hit:<è§„åˆ™å> ä¸ºæ‰€é€‰æ’åè§„åˆ™åœ¨å‚è€ƒæ—¥æ˜¯å¦è§¦å‘ã€‚")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

        # --- Surge ---
        with sub_tabs[1]:
            refS = st.text_input("å‚è€ƒæ—¥", value=_get_latest_date_from_files() or "", key="surge_ref")
            mode = st.selectbox("æ¦œå•å£å¾„", ["today","rolling"], index=1, key="surge_mode")
            rolling_days = st.number_input("rollingæ¨¡å¼ç»Ÿè®¡å¤©æ•°", min_value=2, max_value=20, value=5, key="surge_rolling")
            sel_type = st.selectbox("é€‰æ ·", ["top_n","top_pct"], index=0, key="surge_sel_type")
            sel_val = st.number_input("é˜ˆå€¼ï¼ˆNæˆ–%ï¼‰", min_value=1, max_value=1000, value=200, key="surge_sel_val")
            retros = st.text_input("å›çœ‹å¤©æ•°é›†åˆï¼ˆé€—å·ï¼‰", value="1,2,3,4,5", key="surge_retros")
            split_label = st.selectbox("åˆ†ç»„å£å¾„", ["600/000/ç§‘åˆ›åŒ—(3ç»„)", "ä¸»vså…¶ä»–", "å„æ¿å—"], index=0, key="surge_split_label")
            split = {"600/000/ç§‘åˆ›åŒ—(3ç»„)":"combo3", "ä¸»vså…¶ä»–":"main_vs_others", "å„æ¿å—":"per_board"}[split_label]

            with st.expander("å¯é€‰ï¼šå¯¹å½“æ—¥æ ·æœ¬æŒ‰è§„åˆ™æ‰“å‹¾ï¼ˆæ¥è‡ªæ’åè§„åˆ™ï¼‰", expanded=False):
                import scoring_core as se
                try:
                    rule_names = [str(r.get("name") or f"RULE_{i}") for i, r in enumerate(getattr(se, "SC_RULES", []) or [])]
                    rule_names = sorted(list(dict.fromkeys(rule_names)))
                except Exception:
                    rule_names = []
                surge_rule_names = st.multiselect("æŒ‡æ ‡ï¼ˆå¯å¤šé€‰ï¼‰", options=rule_names, default=[] if rule_names else [], key="surge_rule_names")
                surge_max_json = st.number_input("æœ€å¤šè¯»å–æ˜ç»†JSONï¼ˆä»…å¯¹æ ·æœ¬å†…è‚¡ç¥¨ï¼‰", min_value=50, max_value=5000, value=100, step=50, key="surge_max_json")

            if st.button("è¿è¡Œ Surge", key="btn_run_surge", width='stretch'):
                with st.spinner("ç”Ÿæˆ Surge æ¦œå•ä¸­â€¦"):
                    try:
                        from stats_core import run_surge
                        rlist = [int(x) for x in (retros or "").split(",") if x.strip().isdigit()]
                        sr = run_surge(
                            ref_date=str(refS).strip(),
                            mode=mode,
                            rolling_days=int(rolling_days),
                            selection={"type": sel_type, "value": int(sel_val)},
                            retro_days=rlist,
                            split=split,
                            score_df=None,
                            save=True,
                        )
                        table = sr.table.copy()

                        # å‘½ä¸­æ‰“å‹¾ï¼ˆå¯é€‰ï¼‰
                        if surge_rule_names:
                            codes2 = table["ts_code"].astype(str).unique().tolist()
                            if mode == "today":
                                obs_date = _prev_trade_date(str(refS), 1)  # t-1
                            else:
                                first_date = _pick_trade_dates(str(refS), int(rolling_days))[0]  # t-K
                                obs_date = _prev_trade_date(first_date, 1)                      # t-K-1
                            st.caption(f"å‘½ä¸­å£å¾„ï¼šä½¿ç”¨ã€{obs_date}ã€çš„ details ä½œä¸ºâ€œå¯åŠ¨å‰â€åˆ¤æ–­ã€‚")

                            # é¢„åˆ›å»ºåˆ—
                            for nm in surge_rule_names:
                                table[f"hit:{nm}"] = False

                            # è¯»å– JSONï¼ˆé™é¢ï¼‰
                            for ts in codes2[:int(surge_max_json)]:
                                obj = _load_detail_json(str(obs_date), str(ts)) or {}
                                rules = obj.get("rules") or []
                                hits_map = {
                                    str(rr.get("name") or ""): (
                                        # åªè¦ç­–ç•¥è§¦å‘ï¼ˆok=Trueï¼‰ï¼Œå°±è§†ä¸ºå‘½ä¸­ï¼Œæ— éœ€æ£€æŸ¥addå­—æ®µ
                                        # æˆ–è€…add>0ä¹Ÿè§†ä¸ºå‘½ä¸­ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
                                        bool(rr.get("ok")) 
                                        or (rr.get("add") is not None and float(rr.get("add", 0.0)) > 0.0)
                                    )
                                    for rr in rules
                                }
                                for nm in surge_rule_names:
                                    col = f"hit:{nm}"
                                    if nm in hits_map:
                                        table.loc[table["ts_code"].astype(str) == ts, col] = bool(hits_map[nm])

                    except Exception as e:
                        st.error(f"Surge å¤±è´¥ï¼š{e}")
                    else:
                        table_fmt = _fmt_retcols_percent(table)
                        st.dataframe(table_fmt, width='stretch', height=420)
                        st.caption("å„åˆ†ç»„æ–‡ä»¶å·²å†™å…¥ output/surge_lists/<ref>/ ã€‚")

        
        # --- Commonality ---
        with sub_tabs[2]:
            refC = st.text_input("å‚è€ƒæ—¥", value=_get_latest_date_from_files() or "", key="common_ref")
            retrosC = st.text_input("ç»Ÿè®¡å‰ n æ—¥é›†åˆï¼ˆè§‚å¯Ÿæ—¥å‰ç§» dï¼Œé€—å·ï¼‰", value="1,3,5")
            modeC = st.selectbox("æ¨¡å¼", ["rolling","today"], index=0, key="mode_2")
            rollingC = st.number_input("rolling å¤©æ•°", min_value=2, max_value=20, value=5, key="rolling_2")
            selC = st.number_input("æ ·æœ¬ Top-N", min_value=10, max_value=1000, value=200)
            splitC = st.selectbox("åˆ†ç»„å£å¾„", ["main_vs_others","per_board"], index=0, key="split_2")
            bg = st.selectbox("èƒŒæ™¯é›†", ["all","same_group"], index=0)
            countStrat = st.checkbox("ç»Ÿè®¡æ¯ä¸ªç­–ç•¥çš„è§¦å‘æ¬¡æ•°ï¼ˆç­–ç•¥åˆ†æï¼‰", value=True)
            scopeC = st.selectbox("è§¦å‘ç»Ÿè®¡èŒƒå›´", ["ä»…æ ·æœ¬(å¤§æ¶¨)","åŒç»„å…¨ä½“","ä¸¤è€…å¯¹æ¯”"], index=0, help="ä»…æ ·æœ¬ï¼šåªçœ‹å¤§æ¶¨ç¥¨ï¼›åŒç»„å…¨ä½“ï¼šæ ·æœ¬+åŒç»„éæ ·æœ¬ï¼›ä¸¤è€…å¯¹æ¯”ï¼šåŒæ—¶è¾“å‡ºä¸¤ä¸ªå£å¾„")
            w_en = st.checkbox("å¯¹å¤§æ¶¨æ ·æœ¬åŠ æƒï¼ˆç”¨äºâ€œåŒç»„å…¨ä½“/ä¸¤è€…å¯¹æ¯”â€å£å¾„ï¼‰", value=False)
            w_pos = st.slider("æ ·æœ¬æƒé‡", min_value=1.0, max_value=5.0, value=2.0, step=0.5, help="ä»…åœ¨â€œåŒç»„å…¨ä½“/ä¸¤è€…å¯¹æ¯”â€ä¸‹ç”Ÿæ•ˆ")

            if st.button("è¿è¡Œ Commonality", width='stretch'):
                try:
                    from stats_core import run_commonality
                    rlist = [int(x) for x in retrosC.split(",") if x.strip().isdigit()]
                    cr = run_commonality(
                        ref_date=refC,
                        retro_day=(rlist[0] if rlist else 1),
                        retro_days=rlist,
                        mode=modeC,
                        rolling_days=int(rollingC),
                        selection={"type":"top_n","value":int(selC)},
                        split=splitC,
                        background=bg,
                        save=True,
                        count_strategy=countStrat,
                        count_strategy_scope=("pos" if scopeC=="ä»…æ ·æœ¬(å¤§æ¶¨)" else ("group" if scopeC=="åŒç»„å…¨ä½“" else "both")),
                        strategy_pos_weight=(float(w_pos) if w_en else 1.0),
                    )

                    if countStrat:
                        trig = None
                        if isinstance(cr.reports, dict):
                            trig = cr.reports.get("strategy_triggers")
                            if trig is None:
                                ks = [k for k in cr.reports if str(k).startswith("strategy_triggers__")]
                                if ks:
                                    trig = pd.concat([cr.reports[k] for k in ks if hasattr(cr.reports[k], "copy")], ignore_index=True, sort=False)
                        if isinstance(trig, pd.DataFrame) and not trig.empty:
                            if "trigger_count" not in trig.columns:
                                for alt in ("count","n","num"):
                                    if alt in trig.columns:
                                        trig = trig.rename(columns={alt: "trigger_count"})
                                        break
                                else:
                                    trig["trigger_count"] = 0
                            order_cols = [c for c in ["obs_date","scope","trigger_weighted","trigger_count","name"] if c in trig.columns]
                            if order_cols:
                                trig = trig.sort_values(order_cols, ascending=[True, True, False, False, True][:len(order_cols)])
                            st.dataframe(trig, width='stretch', height=420)

                            # â€”â€” å¯¹æ¯”è§†å›¾ â€”â€”
                            show_pivot = st.checkbox("æŒ‰ç»„/å£å¾„å¯¹æ¯”ï¼ˆé€è§†è¡¨ï¼‰", value=True)
                            if show_pivot:
                                
                                # æŒ‡æ ‡æ˜ å°„ï¼šæ”¹æˆã€Œè‹±æ–‡ -> ä¸­æ–‡ã€æ›´ç¨³
                                _metric_map = {
                                    "trigger_count": "è§¦å‘æ¬¡æ•°",
                                    "coverage": "è¦†ç›–ç‡",
                                    "trigger_weighted": "åŠ æƒè§¦å‘æ¬¡æ•°",
                                    "coverage_weighted": "åŠ æƒè¦†ç›–ç‡",
                                }
                                options_en = [en for en in _metric_map if en in trig.columns]

                                # â€”â€” æŒä¹…åŒ–å½“å‰é€‰æ‹©ï¼ˆæŒ‰è‹±æ–‡åˆ—åï¼‰â€”â€”
                                _pref_key = "pivot_metric_en"
                                default_en = "coverage_weighted" if "coverage_weighted" in options_en else (options_en[0] if options_en else None)
                                if default_en is not None:
                                    if _pref_key not in st.session_state or st.session_state[_pref_key] not in options_en:
                                        st.session_state[_pref_key] = default_en

                                # é€‰æ‹©æ¡†ï¼šæ˜¾ç¤ºä¸­æ–‡ï¼Œå€¼ä¸ºè‹±æ–‡
                                metric_en = st.selectbox(
                                    "é€‰æ‹©å¯¹æ¯”æŒ‡æ ‡",
                                    options_en,
                                    key=_pref_key,
                                    format_func=lambda en: _metric_map.get(en, en),
                                )

                                # åç»­ç”¨ metric_en ç›´æ¥åšé€è§†ï¼›è‹¥éœ€è¦ä¸­æ–‡åå¯ç”¨ï¼š
                                pick_metric_cn = _metric_map.get(metric_en, metric_en)
                                pick_metric = metric_en

                                scopes_avail = sorted(trig["scope"].dropna().unique().tolist()) if "scope" in trig.columns else []
                                scope_pick = st.selectbox("é€‰æ‹©å£å¾„", options=(scopes_avail or ["pos"]), index=0, key="pivot_scope")
                                dfp = trig.copy()
                                if "scope" in dfp.columns and scope_pick in scopes_avail:
                                    dfp = dfp[dfp["scope"]==scope_pick]
                                if "group" in dfp.columns:
                                    pv = dfp.pivot_table(index="name", columns="group", values=pick_metric, aggfunc="max")
                                    st.dataframe(pv, width='stretch', height=420)

                        # â€”â€” æ¯ç¥¨å‘½ä¸­æ¡æ•°åˆ†å¸ƒ â€”â€”
                        ks_hist_single = [k for k in (cr.reports.keys() if isinstance(cr.reports, dict) else []) if str(k).startswith("hits_histogram_single__")]
                        ks_hist_each   = [k for k in (cr.reports.keys() if isinstance(cr.reports, dict) else []) if str(k).startswith("hits_histogram_each__")]
                        if ks_hist_single:
                            st.markdown("**å•æ¬¡å‹ï¼ˆANY/LAST ç­‰ï¼‰å‘½ä¸­æ¡æ•°åˆ†å¸ƒ**")
                            hist_single = pd.concat([cr.reports[k] for k in ks_hist_single], ignore_index=True, sort=False)
                            scopes_hist = sorted(hist_single["scope"].dropna().unique().tolist()) if "scope" in hist_single.columns else []
                            scope_show = st.selectbox("é€‰æ‹©å£å¾„ï¼ˆå•æ¬¡å‹ï¼‰", options=(scopes_hist or ["pos"]), index=0, key="hist_scope_single")
                            show = hist_single[hist_single["scope"]==scope_show] if scopes_hist else hist_single
                            if not show.empty:
                                pv2 = show.pivot_table(index="n_single_rules_hit", columns="group", values="ratio", aggfunc="max")
                                st.dataframe(pv2, width='stretch', height=280)
                        if ks_hist_each:
                            st.markdown("**å¤šæ¬¡å‹ï¼ˆEACHï¼‰å‘½ä¸­æ¡æ•°åˆ†å¸ƒ**")
                            hist_each = pd.concat([cr.reports[k] for k in ks_hist_each], ignore_index=True, sort=False)
                            scopes_hist2 = sorted(hist_each["scope"].dropna().unique().tolist()) if "scope" in hist_each.columns else []
                            scope_show2 = st.selectbox("é€‰æ‹©å£å¾„ï¼ˆå¤šæ¬¡å‹ï¼‰", options=(scopes_hist2 or ["pos"]), index=0, key="hist_scope_each")
                            show2 = hist_each[hist_each["scope"]==scope_show2] if scopes_hist2 else hist_each
                            if not show2.empty:
                                pv3 = show2.pivot_table(index="n_each_rules_hit", columns="group", values="ratio", aggfunc="max")
                                st.dataframe(pv3, width='stretch', height=280)


                    st.caption("åˆ†æé›†/æŠ¥å‘Šå·²å†™å…¥ output/commonality/<ref>/ ï¼ˆåŒ…æ‹¬ strategy_triggers__*.parquet, hits_by_stock__*.parquet, hits_histogram__*.parquetï¼‰ã€‚")

                except Exception as e:
                    st.error(f"Commonality å¤±è´¥ï¼š{e}")

    # ================== æ•°æ®ç®¡ç† ==================
    with tab_data_view:
        st.subheader("æ•°æ®ç®¡ç†")
        
        # ===== æ•°æ®åº“åŸºç¡€æ£€æŸ¥å’Œä¸‹è½½æŒ‰é’® =====
        # å»¶è¿Ÿå¯¼å…¥ download æ¨¡å—
        dl = _lazy_import_download()
        if dl is None:
            st.error("æ— æ³•å¯¼å…¥ download æ¨¡å—")
        else:
            # è·å–åŸºç¡€é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨configï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨downloadæ¨¡å—çš„é»˜è®¤å€¼ï¼‰
            base = str(getattr(cfg, "DATA_ROOT", "./data"))
            api_adj = str(getattr(cfg, "API_ADJ", getattr(dl, "API_ADJ", "qfq"))).lower()
            
            # ä¸‹è½½é…ç½®é¡¹
            st.markdown("#### æ•°æ®ä¸‹è½½é…ç½®")
            with st.expander("ä¸‹è½½å‚æ•°é…ç½®", expanded=False):
                c1, c2, c3 = st.columns(3)
                with c1:
                    # ä»configè·å–é»˜è®¤å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨downloadæ¨¡å—çš„å€¼
                    start_default = str(getattr(cfg, "START_DATE", getattr(dl, "START_DATE", "20200101")))
                    start_use = st.text_input("èµ·å§‹æ—¥ START_DATE (YYYYMMDD)", value=start_default, key="dl_start_date")
                    
                    end_default_cfg = getattr(cfg, "END_DATE", "today")
                    if str(end_default_cfg).strip().lower() == "today":
                        end_default = "today"
                    else:
                        end_default = str(end_default_cfg)
                    end_input = st.text_input("ç»“æŸæ—¥ END_DATE ('today' æˆ– YYYYMMDD)", value=end_default, key="dl_end_date")
                    
                    assets_default = list(getattr(cfg, "ASSETS", getattr(dl, "ASSETS", ["stock", "index"]))) or ["stock", "index"]
                    assets = st.multiselect("èµ„äº§ ASSETS", ["stock", "index"], default=assets_default, key="dl_assets")
                
                with c2:
                    api_adj_options = ["qfq", "hfq", "raw"]
                    api_adj_index = api_adj_options.index(api_adj) if api_adj in api_adj_options else 0
                    api_adj = st.selectbox("å¤æƒ API_ADJ", api_adj_options, index=api_adj_index, key="dl_api_adj").lower()
                    
                    fast_threads_default = int(getattr(cfg, "FAST_INIT_THREADS", getattr(dl, "FAST_INIT_THREADS", 16)))
                    fast_threads = st.number_input("FAST_INIT å¹¶å‘", min_value=1, max_value=64, value=fast_threads_default, key="dl_fast_threads")
                    
                    inc_threads_default = int(getattr(cfg, "STOCK_INC_THREADS", getattr(dl, "STOCK_INC_THREADS", 16)))
                    inc_threads = st.number_input("å¢é‡ä¸‹è½½çº¿ç¨‹", min_value=1, max_value=64, value=inc_threads_default, key="dl_inc_threads")
                
                with c3:
                    ind_workers_default = int(getattr(cfg, "INC_RECALC_WORKERS", getattr(dl, "INC_RECALC_WORKERS", 32)))
                    ind_workers = st.number_input("æŒ‡æ ‡é‡ç®—çº¿ç¨‹(å¯é€‰)", min_value=0, max_value=128, value=ind_workers_default, key="dl_ind_workers")
                    
                    st.caption(f"æ•°æ®æ ¹ç›®å½•: {base}")
            
            # å¤„ç†ç»“æŸæ—¥æœŸ
            end_use = _today_str() if str(end_input).strip().lower() == "today" else str(end_input).strip()
            start_use = str(start_use).strip()
            
            # åº”ç”¨å‚æ•°
            _apply_overrides(base, assets, start_use, end_use, api_adj, int(fast_threads), int(inc_threads), int(ind_workers) if ind_workers else None)
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            latest = _latest_trade_date(base, api_adj)
            if latest:
                st.caption(f"å½“å‰ {api_adj} æœ€è¿‘äº¤æ˜“æ—¥ï¼š{latest}")
            
            # ä¸‹è½½æŒ‰é’®
            run_download = st.button("ğŸš€ è¿è¡Œä¸‹è½½", width='stretch', type="primary", key="run_download_btn")
            
            if run_download:
                logger.info(f"ç”¨æˆ·ç‚¹å‡»è¿è¡Œä¸‹è½½: èµ·å§‹æ—¥æœŸ={start_use}, ç»“æŸæ—¥æœŸ={end_use}")
                try:
                    # ç›´æ¥è°ƒç”¨downloadæ¨¡å—ï¼Œè®©å®ƒè‡ªå·±åˆ¤æ–­æ˜¯å¦ä¸ºå¢é‡
                    steps = [
                        "å‡†å¤‡ç¯å¢ƒ",
                        "æ•°æ®ä¸‹è½½ï¼ˆè‡ªåŠ¨åˆ¤æ–­é¦–æ¬¡/å¢é‡ï¼‰",
                        "æ¸…ç†ä¸æ ¡éªŒ",
                    ]
                    sp = Stepper("æ•°æ®ä¸‹è½½", steps, key_prefix="dl_auto")
                    sp.start()
                    sp.step("å‡†å¤‡ç¯å¢ƒ")
                    sp.step("æ•°æ®ä¸‹è½½ï¼ˆè‡ªåŠ¨åˆ¤æ–­é¦–æ¬¡/å¢é‡ï¼‰")
                    
                    # è°ƒç”¨downloadæ¨¡å—çš„ä¸»å‡½æ•°ï¼Œè®©å®ƒè‡ªå·±åˆ¤æ–­
                    dl = _lazy_import_download()
                    if dl is not None:
                        results = dl.download_data(
                            start_date=start_use,
                            end_date=end_use,
                            adj_type=api_adj,
                            assets=assets,
                            threads=int(inc_threads),
                            enable_warmup=True,
                            enable_adaptive_rate_limit=True
                        )
                        # æ˜¾ç¤ºä¸‹è½½ç»“æœ
                        for asset_type, stats in results.items():
                            st.success(f"{asset_type}: æˆåŠŸ={stats.success_count}, ç©ºæ•°æ®={stats.empty_count}, å¤±è´¥={stats.error_count}")
                    
                    sp.step("æ¸…ç†ä¸æ ¡éªŒ")
                    sp.finish(True, "ä¸‹è½½å®Œæˆ")
                except Exception as e:
                    st.error(f"ä¸‹è½½å¤±è´¥ï¼š{e}")
            
            st.divider()
        
        # ===== æ•°æ®æµè§ˆï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰ =====
        st.markdown("#### æ•°æ®æµè§ˆ")
        st.info("ç”¨äºå¯è§†åŒ–è¯»å–æ•°æ®åº“åŸæ•°æ®")
        
        # æ•°æ®æºé€‰æ‹©
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æº",
            ["Detailsæ•°æ®åº“", "è‚¡ç¥¨åŸæ•°æ®"],
            horizontal=True,
            help="Details: å­˜å‚¨è¯„åˆ†è¯¦æƒ…æ•°æ® | è‚¡ç¥¨åŸæ•°æ®: å­˜å‚¨è‚¡ç¥¨è¡Œæƒ…å’ŒæŒ‡æ ‡æ•°æ®"
        )
        
        if data_source == "Detailsæ•°æ®åº“":
            # Detailsæ•°æ®åº“æŸ¥çœ‹
            try:
                from database_manager import (
                    query_details_by_date,
                    query_details_by_stock,
                    query_details_top_stocks,
                    query_details_score_range,
                    query_details_recent_dates,
                    get_details_table_info,
                    get_details_db_path_with_fallback,
                    is_details_db_available
                )
                import os
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å‡½æ•°è·å–detailsæ•°æ®åº“è·¯å¾„ï¼ˆåŒ…å«å›é€€é€»è¾‘ï¼‰
                db_path = get_details_db_path_with_fallback()
                
                if not db_path or not is_details_db_available():
                    st.warning(f"Detailsæ•°æ®åº“ä¸å¯ç”¨: {db_path if db_path else 'è·¯å¾„è·å–å¤±è´¥'}")
                else:
                    # â€”â€” æ•°æ®åº“æŸ¥è¯¢æ§åˆ¶æŒ‰é’® â€”â€”
                    data_view_db_enabled = st.session_state.get("data_view_db_enabled", False)
                    col_db_ctrl1, col_db_ctrl2 = st.columns([3, 1])
                    with col_db_ctrl1:
                        if data_view_db_enabled:
                            st.success("âœ… æ•°æ®åº“æŸ¥è¯¢å·²å¯ç”¨ï¼ˆå¯ä»¥æŸ¥è¯¢æ•°æ®åº“ï¼‰")
                        else:
                            st.info("â„¹ï¸ æ•°æ®åº“æŸ¥è¯¢æœªå¯ç”¨ï¼ˆç‚¹å‡»æŒ‰é’®åæ‰ä¼šæŸ¥è¯¢æ•°æ®åº“ï¼Œé¿å…ä¸å†™å…¥æ“ä½œå†²çªï¼‰")
                    with col_db_ctrl2:
                        if not data_view_db_enabled:
                            if st.button("ğŸ”“ å¯ç”¨æ•°æ®åº“æŸ¥è¯¢", key="enable_data_view_db"):
                                st.session_state["data_view_db_enabled"] = True
                                st.rerun()
                        else:
                            # ä¸€æ—¦å¯ç”¨å°±ä¸å†æ˜¾ç¤ºæŒ‰é’®ï¼Œä¿æŒå¯ç”¨çŠ¶æ€
                            pass
                    
                    # åªæœ‰åœ¨å¯ç”¨æ•°æ®åº“æŸ¥è¯¢åæ‰æ‰§è¡ŒæŸ¥è¯¢æ“ä½œ
                    if not data_view_db_enabled:
                        st.warning("âš ï¸ è¯·å…ˆç‚¹å‡»ã€Œå¯ç”¨æ•°æ®åº“æŸ¥è¯¢ã€æŒ‰é’®ï¼Œç„¶åæ‰èƒ½æŸ¥è¯¢æ•°æ®åº“æ•°æ®")
                        st.stop()
                    
                    # ä»¥ä¸‹æ˜¯æ‰€æœ‰æ•°æ®åº“æŸ¥è¯¢æ“ä½œï¼Œåªæœ‰åœ¨å¯ç”¨åæ‰ä¼šæ‰§è¡Œ
                    # æŸ¥è¯¢ç±»å‹é€‰æ‹©
                    query_type = st.selectbox(
                        "æŸ¥è¯¢ç±»å‹",
                        ["æŒ‰æ—¥æœŸæŸ¥çœ‹", "æŒ‰è‚¡ç¥¨ä»£ç æŸ¥çœ‹", "Top-Kè‚¡ç¥¨", "åˆ†æ•°èŒƒå›´æŸ¥è¯¢"],
                        key="details_query_type"
                    )
                    
                    # è·å–å¹¶ç¼“å­˜æœ€æ–°æ—¥æœŸï¼ˆå»¶è¿ŸåŠ è½½ï¼Œé¿å…UIå¯åŠ¨æ—¶å»ºç«‹è¿æ¥ï¼‰
                    @st.cache_data
                    def get_latest_details_date():
                        try:
                            dates = query_details_recent_dates(1, db_path)
                            return dates[0] if dates else None
                        except:
                            return None
                    
                    # åªåœ¨éœ€è¦æ˜¾ç¤ºæ—¶æ‰è°ƒç”¨ï¼Œé¿å…UIå¯åŠ¨æ—¶å»ºç«‹è¿æ¥
                    latest_date = None
                    if query_type == "æŒ‰æ—¥æœŸæŸ¥çœ‹":
                        latest_date = get_latest_details_date()
                    
                    if query_type == "æŒ‰æ—¥æœŸæŸ¥çœ‹":
                        # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®é»˜è®¤æ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°æ—¥æœŸ
                        if "details_date_value" not in st.session_state:
                            st.session_state["details_date_value"] = latest_date if latest_date else ""
                        
                        limit_param = st.number_input("è¿”å›è®°å½•æ•°", min_value=1, max_value=1000, value=200, key="details_limit")
                        
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            ref_date = st.text_input(
                                "å‚è€ƒæ—¥æœŸï¼ˆYYYYMMDDï¼Œç•™ç©º=æœ€æ–°ï¼‰",
                                value=st.session_state["details_date_value"],
                                key="details_date"
                            )
                        with col2:
                            st.write("")  # å ä½
                            st.write("")
                            refresh_btn = st.button("åˆ·æ–°", key="details_refresh_btn")
                        
                        # å¤„ç†åˆ·æ–°æˆ–æŸ¥è¯¢
                        date_to_use = ref_date.strip() if ref_date.strip() else latest_date
                        
                        if refresh_btn or date_to_use:
                            try:
                                df = query_details_by_date(date_to_use, limit=limit_param, db_path=db_path)
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    st.info(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½• | æŸ¥è¯¢æ—¥æœŸ: {date_to_use}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                        
                        # æ˜¾ç¤ºæœ€è¿‘çš„æ—¥æœŸåˆ—è¡¨
                        try:
                            recent_dates = query_details_recent_dates(7, db_path)
                            if recent_dates:
                                st.caption(f"æœ€è¿‘çš„äº¤æ˜“æ—¥: {', '.join(recent_dates)}")
                        except Exception as e:
                            pass
                    
                    elif query_type == "æŒ‰è‚¡ç¥¨ä»£ç æŸ¥çœ‹":
                        ts_code = st.text_input("è‚¡ç¥¨ä»£ç ï¼ˆå¦‚000001ï¼‰", key="details_ts_code")
                        limit = st.number_input("è¿”å›è®°å½•æ•°", min_value=1, max_value=100, value=10)
                        
                        if ts_code:
                            try:
                                df = query_details_by_stock(ts_code, limit, db_path)
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                else:
                                    st.warning("æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨çš„æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    
                    elif query_type == "Top-Kè‚¡ç¥¨":
                        # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®é»˜è®¤æ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°æ—¥æœŸ
                        if "details_topk_date_value" not in st.session_state:
                            st.session_state["details_topk_date_value"] = latest_date if latest_date else ""
                        
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            ref_date = st.text_input("å‚è€ƒæ—¥æœŸï¼ˆYYYYMMDDï¼‰", value=st.session_state["details_topk_date_value"], key="details_topk_date")
                        with col2:
                            st.write("")  # å ä½
                            st.write("")
                            refresh_topk_btn = st.button("åˆ·æ–°", key="details_topk_refresh_btn")
                        
                        top_k = st.number_input("Top-K", min_value=1, max_value=500, value=50)
                        
                        date_to_use = ref_date.strip() if ref_date.strip() else latest_date
                        
                        if refresh_topk_btn or date_to_use:
                            try:
                                df = query_details_top_stocks(date_to_use, top_k, db_path)
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    st.info(f"æŸ¥è¯¢æ—¥æœŸ: {date_to_use}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    
                    elif query_type == "åˆ†æ•°èŒƒå›´æŸ¥è¯¢":
                        # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®é»˜è®¤æ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°æ—¥æœŸ
                        if "details_score_date_value" not in st.session_state:
                            st.session_state["details_score_date_value"] = latest_date if latest_date else ""
                        
                        col1_date, col2_date = st.columns([3, 1])
                        with col1_date:
                            ref_date = st.text_input("å‚è€ƒæ—¥æœŸï¼ˆYYYYMMDDï¼‰", value=st.session_state["details_score_date_value"], key="details_score_date")
                        with col2_date:
                            st.write("")  # å ä½
                            st.write("")
                            refresh_score_btn = st.button("åˆ·æ–°", key="details_score_refresh_btn")
                        
                        col1_score, col2_score = st.columns(2)
                        with col1_score:
                            min_score = st.number_input("æœ€ä½åˆ†æ•°", value=50.0, key="details_score_min")
                        with col2_score:
                            max_score = st.number_input("æœ€é«˜åˆ†æ•°", value=100.0, key="details_score_max")
                        
                        date_to_use = ref_date.strip() if ref_date.strip() else latest_date
                        
                        if refresh_score_btn or date_to_use:
                            try:
                                df = query_details_score_range(date_to_use, min_score, max_score, db_path)
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    st.info(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½• | æŸ¥è¯¢æ—¥æœŸ: {date_to_use}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    
                    # æ•°æ®åº“ä¿¡æ¯ï¼ˆç¾åŒ–æ˜¾ç¤ºï¼‰
                    with st.expander("æ•°æ®åº“ä¿¡æ¯"):
                        try:
                            info = get_details_table_info(db_path)
                            # ç¾åŒ–æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
                            if isinstance(info, dict):
                                with st.container(border=True):
                                    for key, value in info.items():
                                        if isinstance(value, (int, float)):
                                            st.metric(key, value)
                                        elif isinstance(value, list):
                                            st.text(f"{key}: {len(value)} é¡¹")
                                            if value and len(value) <= 10:
                                                for item in value:
                                                    st.text(f"  â€¢ {item}")
                                        elif isinstance(value, dict):
                                            st.text(f"{key}:")
                                            for sub_key, sub_value in value.items():
                                                st.text(f"  {sub_key}: {sub_value}")
                                        else:
                                            st.text(f"{key}: {value}")
                            else:
                                st.text(str(info))
                        except Exception as e:
                            st.error(f"è·å–ä¿¡æ¯å¤±è´¥: {e}")
            
            except Exception as e:
                st.error(f"åˆå§‹åŒ–Detailsæ•°æ®åº“è¯»å–å™¨å¤±è´¥: {e}")
                import traceback
                st.text(traceback.format_exc())
        
        else:
            # è‚¡ç¥¨åŸæ•°æ®æŸ¥çœ‹
            from config import DATA_ROOT, UNIFIED_DB_PATH
            
            db_path = os.path.join(DATA_ROOT, UNIFIED_DB_PATH)
            
            if not os.path.exists(db_path):
                st.warning(f"è‚¡ç¥¨æ•°æ®æ•°æ®åº“ä¸å­˜åœ¨: {db_path}")
            else:
                # æŸ¥è¯¢å‚æ•°
                col1, col2 = st.columns(2)
                with col1:
                    asset_type = st.selectbox("èµ„äº§ç±»å‹", ["stock", "index"], index=0)
                    # æ ¹æ®èµ„äº§ç±»å‹è®¾ç½®é»˜è®¤adj
                    default_adj = "ind" if asset_type == "index" else "qfq"
                with col2:
                    adj_type = st.selectbox(
                        "å¤æƒç±»å‹",
                        ["raw", "qfq", "hfq", "ind"],
                        index=["raw", "qfq", "hfq", "ind"].index(default_adj)
                    )
                
                view_mode = st.radio(
                    "æŸ¥çœ‹æ¨¡å¼",
                    ["å•æ—¥æŸ¥çœ‹", "åŒºé—´æŸ¥è¯¢", "å•è‚¡å†å²"],
                    horizontal=True
                )
                
                @st.cache_data
                def get_trade_dates_list():
                    """è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨"""
                    try:
                        dates = get_trade_dates(db_path)
                        return dates
                    except Exception as e:
                        st.error(f"è·å–äº¤æ˜“æ—¥æœŸå¤±è´¥: {e}")
                        return []
                
                # å»¶è¿ŸåŠ è½½äº¤æ˜“æ—¥æœŸ
                if 'trade_dates' not in st.session_state:
                    with st.spinner("æ­£åœ¨åŠ è½½äº¤æ˜“æ—¥æœŸ..."):
                        st.session_state['trade_dates'] = get_trade_dates_list()
                
                if view_mode == "å•æ—¥æŸ¥çœ‹":
                    trade_dates = st.session_state['trade_dates']
                    if trade_dates:
                        selected_date = st.selectbox(
                            "é€‰æ‹©æ—¥æœŸ",
                            trade_dates,
                            index=len(trade_dates)-1 if trade_dates else 0
                        )
                        
                        limit = st.number_input("æ˜¾ç¤ºè¡Œæ•°ï¼ˆ-1ä¸ºå…¨éƒ¨ï¼‰", value=100, min_value=-1, max_value=5000, step=50)
                        if limit == -1:
                            limit = None
                        
                        if st.button("æŸ¥è¯¢", key="btn_query_day"):
                            try:
                                df = query_stock_data(
                                    db_path=db_path,
                                    start_date=selected_date,
                                    end_date=selected_date,
                                    adj_type=adj_type if asset_type != "index" else "ind",
                                    limit=limit
                                )
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    # ç»Ÿè®¡æ€»è¡Œæ•°ï¼ˆå¿½ç•¥limitï¼‰
                                    try:
                                        from database_manager import count_stock_data as _count_stock_data
                                        total_rows = _count_stock_data(
                                            db_path=db_path,
                                            ts_code=None,
                                            start_date=selected_date,
                                            end_date=selected_date,
                                            adj_type=adj_type if asset_type != "index" else "ind"
                                        )
                                    except Exception:
                                        total_rows = len(df)
                                    st.info(f"æ€»è¡Œæ•°: {total_rows} | æœ¬æ¬¡æ˜¾ç¤º: {len(df)}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    else:
                        st.warning("æ— æ³•è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨")
                
                elif view_mode == "åŒºé—´æŸ¥è¯¢":
                    trade_dates = st.session_state['trade_dates']
                    if trade_dates:
                        col1, col2 = st.columns(2)
                        with col1:
                            start_date = st.selectbox("èµ·å§‹æ—¥æœŸ", trade_dates, index=len(trade_dates)-10 if len(trade_dates) >= 10 else 0)
                        with col2:
                            end_date = st.selectbox("ç»“æŸæ—¥æœŸ", trade_dates, index=len(trade_dates)-1)
                        
                        ts_code = st.text_input("è‚¡ç¥¨ä»£ç ï¼ˆç•™ç©º=å…¨å¸‚åœºï¼Œå¦‚000001.SZï¼‰")
                        
                        columns_input = st.text_input("æŒ‡å®šåˆ—ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œç•™ç©º=æ‰€æœ‰åˆ—ï¼‰", placeholder="å¦‚: trade_date,open,high,low,close,vol")
                        columns = [c.strip() for c in columns_input.split(",")] if columns_input else None
                        
                        limit = st.number_input("æ˜¾ç¤ºè¡Œæ•°ï¼ˆ-1ä¸ºå…¨éƒ¨ï¼‰", value=200, min_value=-1, max_value=10000, step=100)
                        if limit == -1:
                            limit = None
                        
                        if st.button("æŸ¥è¯¢", key="btn_query_range"):
                            try:
                                df = query_stock_data(
                                    db_path=db_path,
                                    ts_code=ts_code if ts_code else None,
                                    start_date=start_date,
                                    end_date=end_date,
                                    columns=columns,
                                    adj_type=adj_type if asset_type != "index" else "ind",
                                    limit=limit
                                )
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    # ç»Ÿè®¡æ€»è¡Œæ•°ï¼ˆå¿½ç•¥limitï¼‰
                                    try:
                                        from database_manager import count_stock_data as _count_stock_data
                                        total_rows = _count_stock_data(
                                            db_path=db_path,
                                            ts_code=ts_code if ts_code else None,
                                            start_date=start_date,
                                            end_date=end_date,
                                            adj_type=adj_type if asset_type != "index" else "ind"
                                        )
                                    except Exception:
                                        total_rows = len(df)
                                    st.info(f"æ€»è¡Œæ•°: {total_rows} | æœ¬æ¬¡æ˜¾ç¤º: {len(df)}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    
                    if not trade_dates:
                        st.warning("æ— æ³•è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨")
                
                elif view_mode == "å•è‚¡å†å²":
                    ts_code = st.text_input("è‚¡ç¥¨ä»£ç ï¼ˆå¦‚000001.SZï¼‰", key="single_stock_code")
                    
                    trade_dates = st.session_state.get('trade_dates', [])
                    if not trade_dates:
                        st.warning("æ— æ³•è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨")
                    elif ts_code:
                        col1, col2 = st.columns(2)
                        with col1:
                            start_date = st.selectbox("èµ·å§‹æ—¥æœŸ", trade_dates, index=len(trade_dates)-60 if len(trade_dates) >= 60 else 0, key="single_start")
                        with col2:
                            end_date = st.selectbox("ç»“æŸæ—¥æœŸ", trade_dates, index=len(trade_dates)-1, key="single_end")
                    
                    columns_input = st.text_input("æŒ‡å®šåˆ—ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œç•™ç©º=æ‰€æœ‰åˆ—ï¼‰", placeholder="å¦‚: trade_date,open,high,low,close,vol,kdj_k,kdj_d,rsi", key="single_columns")
                    columns = [c.strip() for c in columns_input.split(",")] if columns_input else None
                    
                    limit = st.number_input("æ˜¾ç¤ºè¡Œæ•°ï¼ˆ-1ä¸ºå…¨éƒ¨ï¼‰", value=-1, min_value=-1, max_value=10000, step=100, key="single_limit")
                    if limit == -1:
                        limit = None
                    
                    if st.button("æŸ¥è¯¢", key="btn_query_single"):
                        if not ts_code:
                            st.error("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
                        else:
                            try:
                                df = query_stock_data(
                                    db_path=db_path,
                                    ts_code=ts_code,
                                    start_date=start_date,
                                    end_date=end_date,
                                    columns=columns,
                                    adj_type=adj_type if asset_type != "index" else "ind",
                                    limit=limit
                                )
                                if not df.empty:
                                    st.dataframe(df, width='stretch')
                                    
                                    # å¦‚æœæœ‰æ”¶ç›˜ä»·æ•°æ®ï¼Œç»˜åˆ¶å›¾è¡¨
                                    if "close" in df.columns and "trade_date" in df.columns:
                                        try:
                                            df_chart = df.copy()
                                            df_chart["trade_date"] = pd.to_datetime(df_chart["trade_date"])
                                            st.line_chart(df_chart.set_index("trade_date")[["close"]])
                                        except Exception as e:
                                            st.warning(f"æ— æ³•ç»˜åˆ¶å›¾è¡¨: {e}")
                                    # ç»Ÿè®¡æ€»è¡Œæ•°ï¼ˆå¿½ç•¥limitï¼‰
                                    try:
                                        from database_manager import count_stock_data as _count_stock_data
                                        total_rows = _count_stock_data(
                                            db_path=db_path,
                                            ts_code=ts_code,
                                            start_date=start_date,
                                            end_date=end_date,
                                            adj_type=adj_type if asset_type != "index" else "ind"
                                        )
                                    except Exception:
                                        total_rows = len(df)
                                    st.info(f"æ€»è¡Œæ•°: {total_rows} | æœ¬æ¬¡æ˜¾ç¤º: {len(df)}")
                                else:
                                    st.warning("æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨çš„æ•°æ®")
                            except Exception as e:
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                
                # æ•°æ®åº“ä¿¡æ¯ï¼ˆç¾åŒ–æ˜¾ç¤ºï¼‰
                with st.expander("æ•°æ®åº“ä¿¡æ¯"):
                    try:
                        info = get_database_info()
                        # ç¾åŒ–æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
                        if isinstance(info, dict):
                            with st.container(border=True):
                                for key, value in info.items():
                                    if isinstance(value, (int, float)):
                                        st.metric(key, value)
                                    elif isinstance(value, list):
                                        st.text(f"{key}: {len(value)} é¡¹")
                                        if value and len(value) <= 10:
                                            for item in value:
                                                st.text(f"  â€¢ {item}")
                                    elif isinstance(value, dict):
                                        st.text(f"{key}:")
                                        for sub_key, sub_value in value.items():
                                            st.text(f"  {sub_key}: {sub_value}")
                                    else:
                                        st.text(f"{key}: {value}")
                        else:
                            st.text(str(info))
                    except Exception as e:
                        st.error(f"è·å–ä¿¡æ¯å¤±è´¥: {e}")

    # ================== æ—¥å¿— ==================
    with tab_logs:
        st.subheader("æ—¥å¿—")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**score.logï¼ˆå°¾éƒ¨ 400 è¡Œï¼‰**")
            st.code(_tail(LOG_DIR / "score.log", 400), language="bash")
        with col2:
            st.markdown("**score_ui.logï¼ˆå°¾éƒ¨ 400 è¡Œï¼‰**")
            st.code(_tail(LOG_DIR / "score_ui.log", 400), language="bash")

    _anchor = st.session_state.pop("scroll_after_rerun", None)
    if _anchor:
        components.html(f"""
        <script>
        (function() {{
        const id = {_anchor!r};
        function go() {{
            const doc = parent.document || document;
            // 1) æ¿€æ´»â€œä¸ªè‚¡è¯¦æƒ…â€é¡µç­¾ï¼ˆæŒ‰é’® role="tab"ï¼Œæ–‡æœ¬ä»¥â€œä¸ªè‚¡è¯¦æƒ…â€å¼€å¤´ï¼‰
            const tabs = doc.querySelectorAll('button[role="tab"]');
            for (const btn of tabs) {{
            if ((btn.innerText || '').trim().startsWith('ä¸ªè‚¡è¯¦æƒ…')) {{ btn.click(); break; }}
            }}
            // 2) æ»šåŠ¨åˆ°é”šç‚¹
            const el = doc.getElementById(id);
            if (el) {{
            el.scrollIntoView({{behavior:'instant', block:'start'}});
            }} else {{
            // å…œåº•ï¼šæŠŠ hash è®¾ç½®ä¸ºé”šç‚¹
            parent.location.hash = id;
            }}
        }}
        // å¤šæ¬¡å°è¯•ï¼Œç­‰å¤–å±‚ DOM ç¨³å®š
        setTimeout(go, 0); setTimeout(go, 200); setTimeout(go, 600);
        }})();
        </script>
        """, height=0)
